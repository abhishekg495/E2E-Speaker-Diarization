{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c591401-e616-45c4-acf0-cb9e44922980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uisrnn\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "249dc7d5-5cfd-4c29-a0c4-412e1eb49268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(value):\n",
    "    \"\"\"A function to convert string to bool value.\"\"\"\n",
    "    if value.lower() in {'yes', 'true', 't', 'y', '1'}:\n",
    "        return True\n",
    "    if value.lower() in {'no', 'false', 'f', 'n', '0'}:\n",
    "        return False\n",
    "    raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "def parse_arguments():\n",
    "    \"\"\"Parse arguments.\n",
    "    \n",
    "    Returns:\n",
    "    A tuple of:\n",
    "    \n",
    "      - `model_args`: model arguments\n",
    "      - `training_args`: training arguments\n",
    "      - `inference_args`: inference arguments\n",
    "    \"\"\"\n",
    "    # model configurations\n",
    "    model_parser = argparse.ArgumentParser(\n",
    "      description='Model configurations.', add_help=False)\n",
    "    \n",
    "    model_parser.add_argument(\n",
    "      '--observation_dim',\n",
    "      default=256,\n",
    "      type=int,\n",
    "      help='The dimension of the embeddings (e.g. d-vectors).')\n",
    "    \n",
    "    model_parser.add_argument(\n",
    "      '--rnn_hidden_size',\n",
    "      default=512,\n",
    "      type=int,\n",
    "      help='The number of nodes for each RNN layer.')\n",
    "    model_parser.add_argument(\n",
    "      '--rnn_depth',\n",
    "      default=1,\n",
    "      type=int,\n",
    "      help='The number of RNN layers.')\n",
    "    model_parser.add_argument(\n",
    "      '--rnn_dropout',\n",
    "      default=0.2,\n",
    "      type=float,\n",
    "      help='The dropout rate for all RNN layers.')\n",
    "    model_parser.add_argument(\n",
    "      '--transition_bias',\n",
    "      default=None,\n",
    "      type=float,\n",
    "      help='The value of p0, corresponding to Eq. (6) in the '\n",
    "           'paper. If the value is given, we will fix to this value. If the '\n",
    "           'value is None, we will estimate it from training data '\n",
    "           'using Eq. (13) in the paper.')\n",
    "    model_parser.add_argument(\n",
    "      '--crp_alpha',\n",
    "      default=1.0,\n",
    "      type=float,\n",
    "      help='The value of alpha for the Chinese restaurant process (CRP), '\n",
    "           'corresponding to Eq. (7) in the paper. In this open source '\n",
    "           'implementation, currently we only support using a given value '\n",
    "           'of crp_alpha.')\n",
    "    model_parser.add_argument(\n",
    "      '--sigma2',\n",
    "      default=None,\n",
    "      type=float,\n",
    "      help='The value of sigma squared, corresponding to Eq. (11) in the '\n",
    "           'paper. If the value is given, we will fix to this value. If the '\n",
    "           'value is None, we will estimate it from training data.')\n",
    "    model_parser.add_argument(\n",
    "      '--verbosity',\n",
    "      default=2,\n",
    "      type=int,\n",
    "      help='How verbose will the logging information be. Higher value '\n",
    "      'represents more verbose information. A general guideline: '\n",
    "      '0 for errors; 1 for finishing important steps; '\n",
    "      '2 for finishing less important steps; 3 or above for debugging '\n",
    "      'information.')\n",
    "    model_parser.add_argument(\n",
    "      '--enable_cuda',\n",
    "      default=True,\n",
    "      type=str2bool,\n",
    "      help='Whether we should use CUDA if it is avaiable. If False, we will '\n",
    "      'always use CPU.')\n",
    "    \n",
    "    # training configurations\n",
    "    training_parser = argparse.ArgumentParser(\n",
    "      description='Training configurations.', add_help=False)\n",
    "    \n",
    "    training_parser.add_argument(\n",
    "      '--optimizer',\n",
    "      '-o',\n",
    "      default='adam',\n",
    "      choices=['adam'],\n",
    "      help='The optimizer for training.')\n",
    "    training_parser.add_argument(\n",
    "      '--learning_rate',\n",
    "      '-l',\n",
    "      default=1e-3,\n",
    "      type=float,\n",
    "      help='The leaning rate for training.')\n",
    "    training_parser.add_argument(\n",
    "      '--train_iteration',\n",
    "      '-t',\n",
    "      default=20000,\n",
    "      type=int,\n",
    "      help='The total number of training iterations.')\n",
    "    training_parser.add_argument(\n",
    "      '--batch_size',\n",
    "      '-b',\n",
    "      default=10,\n",
    "      type=int,\n",
    "      help='The batch size for training.')\n",
    "    training_parser.add_argument(\n",
    "      '--num_permutations',\n",
    "      default=10,\n",
    "      type=int,\n",
    "      help='The number of permutations per utterance sampled in the training '\n",
    "           'data.')\n",
    "    training_parser.add_argument(\n",
    "      '--sigma_alpha',\n",
    "      default=1.0,\n",
    "      type=float,\n",
    "      help='The inverse gamma shape for estimating sigma2. This value is only '\n",
    "           'meaningful when sigma2 is not given, and estimated from data.')\n",
    "    training_parser.add_argument(\n",
    "      '--sigma_beta',\n",
    "      default=1.0,\n",
    "      type=float,\n",
    "      help='The inverse gamma scale for estimating sigma2. This value is only '\n",
    "           'meaningful when sigma2 is not given, and estimated from data.')\n",
    "    training_parser.add_argument(\n",
    "      '--regularization_weight',\n",
    "      '-r',\n",
    "      default=1e-5,\n",
    "      type=float,\n",
    "      help='The network regularization multiplicative.')\n",
    "    training_parser.add_argument(\n",
    "      '--grad_max_norm',\n",
    "      default=5.0,\n",
    "      type=float,\n",
    "      help='Max norm of the gradient.')\n",
    "    training_parser.add_argument(\n",
    "      '--enforce_cluster_id_uniqueness',\n",
    "      default=True,\n",
    "      type=str2bool,\n",
    "      help='Whether to enforce cluster ID uniqueness across different '\n",
    "           'training sequences. Only effective when the first input to fit() '\n",
    "           'is a list of sequences. In general, assume the cluster IDs for two '\n",
    "           'sequences are [a, b] and [a, c]. If the `a` from the two sequences '\n",
    "           'are not the same label, then this arg should be True.')\n",
    "    \n",
    "    # inference configurations\n",
    "    inference_parser = argparse.ArgumentParser(\n",
    "      description='Inference configurations.', add_help=False)\n",
    "    \n",
    "    inference_parser.add_argument(\n",
    "      '--beam_size',\n",
    "      '-s',\n",
    "      default=10,\n",
    "      type=int,\n",
    "      help='The beam search size for inference.')\n",
    "    inference_parser.add_argument(\n",
    "      '--look_ahead',\n",
    "      default=1,\n",
    "      type=int,\n",
    "      help='The number of look ahead steps during inference.')\n",
    "    inference_parser.add_argument(\n",
    "      '--test_iteration',\n",
    "      default=2,\n",
    "      type=int,\n",
    "      help='During inference, we concatenate M duplicates of the test '\n",
    "           'sequence, and run inference on this concatenated sequence. '\n",
    "           'Then we return the inference results on the last duplicate as the '\n",
    "           'final prediction for the test sequence.')\n",
    "    \n",
    "    # a super parser for sanity checks\n",
    "    super_parser = argparse.ArgumentParser(\n",
    "      parents=[model_parser, training_parser, inference_parser])\n",
    "    \n",
    "    \n",
    "    # get arguments\n",
    "    # super_parser.add_argument('-f')\n",
    "    super_parser.parse_known_args()\n",
    "    model_args, _ = model_parser.parse_known_args()\n",
    "    training_args, _ = training_parser.parse_known_args()\n",
    "    inference_args, _ = inference_parser.parse_known_args()\n",
    "    \n",
    "    return (model_args, training_args, inference_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb8dd071-d178-4c0b-be24-c48a0bb7fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args, training_args, inference_args = parse_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecfdad18-9bcc-45c1-945e-e09b623b6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = uisrnn.UISRNN(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdd9c51c-1474-4d45-8167-0906a9fa8ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = np.load(\"./train_sequence.npy\")\n",
    "train_cluster_id = np.load(\"./train_cluster_id.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2823c545-55e8-4ddf-9078-aaf7e5deeae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: transition_bias cannot be correctly estimated from a concatenated sequence; train_sequences will be treated as a single sequence. This can lead to inaccurate estimation of transition_bias. Please, consider estimating transition_bias before concatenating the sequences and passing it as argument.\n",
      "Iter: 0  \tTraining Loss: -289.3582    \n",
      "    Negative Log Likelihood: 5.3444\tSigma2 Prior: -294.7033\tRegularization: 0.0006\n",
      "Iter: 10  \tTraining Loss: -306.3361    \n",
      "    Negative Log Likelihood: 1.9067\tSigma2 Prior: -308.2434\tRegularization: 0.0006\n",
      "Iter: 20  \tTraining Loss: -321.6132    \n",
      "    Negative Log Likelihood: 2.0723\tSigma2 Prior: -323.6861\tRegularization: 0.0006\n",
      "Iter: 30  \tTraining Loss: -339.5320    \n",
      "    Negative Log Likelihood: 2.3738\tSigma2 Prior: -341.9064\tRegularization: 0.0006\n",
      "Iter: 40  \tTraining Loss: -361.5203    \n",
      "    Negative Log Likelihood: 2.8242\tSigma2 Prior: -364.3451\tRegularization: 0.0006\n",
      "Iter: 50  \tTraining Loss: -390.1321    \n",
      "    Negative Log Likelihood: 3.5487\tSigma2 Prior: -393.6815\tRegularization: 0.0006\n",
      "Iter: 60  \tTraining Loss: -431.0535    \n",
      "    Negative Log Likelihood: 4.9328\tSigma2 Prior: -435.9868\tRegularization: 0.0006\n",
      "Iter: 70  \tTraining Loss: -502.1101    \n",
      "    Negative Log Likelihood: 8.8325\tSigma2 Prior: -510.9432\tRegularization: 0.0006\n",
      "Iter: 80  \tTraining Loss: -273.8550    \n",
      "    Negative Log Likelihood: 624.5712\tSigma2 Prior: -898.4268\tRegularization: 0.0006\n",
      "Iter: 90  \tTraining Loss: -671.9794    \n",
      "    Negative Log Likelihood: 66.6040\tSigma2 Prior: -738.5841\tRegularization: 0.0006\n",
      "Iter: 100  \tTraining Loss: -664.6495    \n",
      "    Negative Log Likelihood: 76.0806\tSigma2 Prior: -740.7307\tRegularization: 0.0006\n",
      "Iter: 110  \tTraining Loss: -666.3751    \n",
      "    Negative Log Likelihood: 80.0504\tSigma2 Prior: -746.4261\tRegularization: 0.0006\n",
      "Iter: 120  \tTraining Loss: -670.1193    \n",
      "    Negative Log Likelihood: 83.8074\tSigma2 Prior: -753.9274\tRegularization: 0.0006\n",
      "Iter: 130  \tTraining Loss: -673.0494    \n",
      "    Negative Log Likelihood: 86.7636\tSigma2 Prior: -759.8137\tRegularization: 0.0007\n",
      "Iter: 140  \tTraining Loss: -674.7376    \n",
      "    Negative Log Likelihood: 87.0655\tSigma2 Prior: -761.8038\tRegularization: 0.0007\n",
      "Iter: 150  \tTraining Loss: -676.6608    \n",
      "    Negative Log Likelihood: 88.3368\tSigma2 Prior: -764.9982\tRegularization: 0.0007\n",
      "Iter: 160  \tTraining Loss: -678.7777    \n",
      "    Negative Log Likelihood: 90.0278\tSigma2 Prior: -768.8062\tRegularization: 0.0007\n",
      "Iter: 170  \tTraining Loss: -680.7446    \n",
      "    Negative Log Likelihood: 91.6204\tSigma2 Prior: -772.3657\tRegularization: 0.0007\n",
      "Iter: 180  \tTraining Loss: -681.6794    \n",
      "    Negative Log Likelihood: 92.6573\tSigma2 Prior: -774.3375\tRegularization: 0.0007\n",
      "Iter: 190  \tTraining Loss: -682.6665    \n",
      "    Negative Log Likelihood: 94.4883\tSigma2 Prior: -777.1555\tRegularization: 0.0007\n",
      "Iter: 200  \tTraining Loss: -682.7733    \n",
      "    Negative Log Likelihood: 95.2326\tSigma2 Prior: -778.0067\tRegularization: 0.0007\n",
      "Iter: 210  \tTraining Loss: -683.6575    \n",
      "    Negative Log Likelihood: 94.7298\tSigma2 Prior: -778.3881\tRegularization: 0.0007\n",
      "Iter: 220  \tTraining Loss: -683.8170    \n",
      "    Negative Log Likelihood: 94.9273\tSigma2 Prior: -778.7451\tRegularization: 0.0007\n",
      "Iter: 230  \tTraining Loss: -684.2292    \n",
      "    Negative Log Likelihood: 95.0066\tSigma2 Prior: -779.2366\tRegularization: 0.0008\n",
      "Iter: 240  \tTraining Loss: -684.6335    \n",
      "    Negative Log Likelihood: 94.8491\tSigma2 Prior: -779.4834\tRegularization: 0.0008\n",
      "Iter: 250  \tTraining Loss: -683.8576    \n",
      "    Negative Log Likelihood: 94.9960\tSigma2 Prior: -778.8544\tRegularization: 0.0008\n",
      "Iter: 260  \tTraining Loss: -684.8229    \n",
      "    Negative Log Likelihood: 95.2612\tSigma2 Prior: -780.0849\tRegularization: 0.0008\n",
      "Iter: 270  \tTraining Loss: -685.1172    \n",
      "    Negative Log Likelihood: 95.3278\tSigma2 Prior: -780.4459\tRegularization: 0.0008\n",
      "Iter: 280  \tTraining Loss: -684.9341    \n",
      "    Negative Log Likelihood: 95.5795\tSigma2 Prior: -780.5143\tRegularization: 0.0008\n",
      "Iter: 290  \tTraining Loss: -685.2647    \n",
      "    Negative Log Likelihood: 95.3342\tSigma2 Prior: -780.5997\tRegularization: 0.0008\n",
      "Iter: 300  \tTraining Loss: -685.4164    \n",
      "    Negative Log Likelihood: 95.4604\tSigma2 Prior: -780.8776\tRegularization: 0.0008\n",
      "Iter: 310  \tTraining Loss: -685.6251    \n",
      "    Negative Log Likelihood: 95.2899\tSigma2 Prior: -780.9158\tRegularization: 0.0008\n",
      "Iter: 320  \tTraining Loss: -685.6785    \n",
      "    Negative Log Likelihood: 95.4982\tSigma2 Prior: -781.1776\tRegularization: 0.0008\n",
      "Iter: 330  \tTraining Loss: -685.9315    \n",
      "    Negative Log Likelihood: 95.4572\tSigma2 Prior: -781.3895\tRegularization: 0.0008\n",
      "Iter: 340  \tTraining Loss: -686.1746    \n",
      "    Negative Log Likelihood: 95.7814\tSigma2 Prior: -781.9568\tRegularization: 0.0009\n",
      "Iter: 350  \tTraining Loss: -686.3006    \n",
      "    Negative Log Likelihood: 93.6137\tSigma2 Prior: -779.9152\tRegularization: 0.0009\n",
      "Iter: 360  \tTraining Loss: -685.9791    \n",
      "    Negative Log Likelihood: 96.0969\tSigma2 Prior: -782.0768\tRegularization: 0.0009\n",
      "Iter: 370  \tTraining Loss: -686.5648    \n",
      "    Negative Log Likelihood: 95.9001\tSigma2 Prior: -782.4658\tRegularization: 0.0009\n",
      "Iter: 380  \tTraining Loss: -686.7774    \n",
      "    Negative Log Likelihood: 96.1115\tSigma2 Prior: -782.8898\tRegularization: 0.0009\n",
      "Iter: 390  \tTraining Loss: -686.0726    \n",
      "    Negative Log Likelihood: 96.6362\tSigma2 Prior: -782.7097\tRegularization: 0.0009\n",
      "Iter: 400  \tTraining Loss: -686.6695    \n",
      "    Negative Log Likelihood: 97.1038\tSigma2 Prior: -783.7742\tRegularization: 0.0009\n",
      "Iter: 410  \tTraining Loss: -686.8961    \n",
      "    Negative Log Likelihood: 96.4475\tSigma2 Prior: -783.3445\tRegularization: 0.0009\n",
      "Iter: 420  \tTraining Loss: -686.9729    \n",
      "    Negative Log Likelihood: 96.9091\tSigma2 Prior: -783.8829\tRegularization: 0.0009\n",
      "Iter: 430  \tTraining Loss: -686.7932    \n",
      "    Negative Log Likelihood: 96.8435\tSigma2 Prior: -783.6376\tRegularization: 0.0009\n",
      "Iter: 440  \tTraining Loss: -686.8027    \n",
      "    Negative Log Likelihood: 96.1956\tSigma2 Prior: -782.9992\tRegularization: 0.0009\n",
      "Iter: 450  \tTraining Loss: -686.8797    \n",
      "    Negative Log Likelihood: 96.3487\tSigma2 Prior: -783.2294\tRegularization: 0.0009\n",
      "Iter: 460  \tTraining Loss: -687.3939    \n",
      "    Negative Log Likelihood: 96.6224\tSigma2 Prior: -784.0172\tRegularization: 0.0010\n",
      "Iter: 470  \tTraining Loss: -687.7779    \n",
      "    Negative Log Likelihood: 96.2109\tSigma2 Prior: -783.9897\tRegularization: 0.0010\n",
      "Iter: 480  \tTraining Loss: -687.8428    \n",
      "    Negative Log Likelihood: 96.5606\tSigma2 Prior: -784.4044\tRegularization: 0.0010\n",
      "Iter: 490  \tTraining Loss: -687.9311    \n",
      "    Negative Log Likelihood: 96.6223\tSigma2 Prior: -784.5543\tRegularization: 0.0010\n",
      "Iter: 500  \tTraining Loss: -688.1448    \n",
      "    Negative Log Likelihood: 96.4035\tSigma2 Prior: -784.5493\tRegularization: 0.0010\n",
      "Iter: 510  \tTraining Loss: -688.2777    \n",
      "    Negative Log Likelihood: 96.5476\tSigma2 Prior: -784.8264\tRegularization: 0.0010\n",
      "Iter: 520  \tTraining Loss: -688.2885    \n",
      "    Negative Log Likelihood: 96.6013\tSigma2 Prior: -784.8907\tRegularization: 0.0010\n",
      "Iter: 530  \tTraining Loss: -688.4371    \n",
      "    Negative Log Likelihood: 96.5957\tSigma2 Prior: -785.0338\tRegularization: 0.0010\n",
      "Iter: 540  \tTraining Loss: -688.4636    \n",
      "    Negative Log Likelihood: 96.9281\tSigma2 Prior: -785.3926\tRegularization: 0.0010\n",
      "Iter: 550  \tTraining Loss: -688.6314    \n",
      "    Negative Log Likelihood: 96.6130\tSigma2 Prior: -785.2454\tRegularization: 0.0010\n",
      "Iter: 560  \tTraining Loss: -688.9068    \n",
      "    Negative Log Likelihood: 95.7670\tSigma2 Prior: -784.6748\tRegularization: 0.0010\n",
      "Iter: 570  \tTraining Loss: -688.6733    \n",
      "    Negative Log Likelihood: 96.9286\tSigma2 Prior: -785.6029\tRegularization: 0.0010\n",
      "Iter: 580  \tTraining Loss: -688.6906    \n",
      "    Negative Log Likelihood: 96.2980\tSigma2 Prior: -784.9897\tRegularization: 0.0010\n",
      "Iter: 590  \tTraining Loss: -687.7130    \n",
      "    Negative Log Likelihood: 96.3031\tSigma2 Prior: -784.0170\tRegularization: 0.0010\n",
      "Iter: 600  \tTraining Loss: -687.7926    \n",
      "    Negative Log Likelihood: 96.0663\tSigma2 Prior: -783.8600\tRegularization: 0.0010\n",
      "Iter: 610  \tTraining Loss: -687.7714    \n",
      "    Negative Log Likelihood: 96.3553\tSigma2 Prior: -784.1277\tRegularization: 0.0010\n",
      "Iter: 620  \tTraining Loss: -688.0297    \n",
      "    Negative Log Likelihood: 96.5982\tSigma2 Prior: -784.6290\tRegularization: 0.0010\n",
      "Iter: 630  \tTraining Loss: -687.9765    \n",
      "    Negative Log Likelihood: 96.7860\tSigma2 Prior: -784.7636\tRegularization: 0.0010\n",
      "Iter: 640  \tTraining Loss: -688.2681    \n",
      "    Negative Log Likelihood: 96.3643\tSigma2 Prior: -784.6334\tRegularization: 0.0010\n",
      "Iter: 650  \tTraining Loss: -688.2171    \n",
      "    Negative Log Likelihood: 96.6096\tSigma2 Prior: -784.8278\tRegularization: 0.0010\n",
      "Iter: 660  \tTraining Loss: -688.5422    \n",
      "    Negative Log Likelihood: 96.5475\tSigma2 Prior: -785.0908\tRegularization: 0.0010\n",
      "Iter: 670  \tTraining Loss: -688.5425    \n",
      "    Negative Log Likelihood: 96.7292\tSigma2 Prior: -785.2727\tRegularization: 0.0010\n",
      "Iter: 680  \tTraining Loss: -688.7469    \n",
      "    Negative Log Likelihood: 96.5401\tSigma2 Prior: -785.2880\tRegularization: 0.0010\n",
      "Iter: 690  \tTraining Loss: -688.8692    \n",
      "    Negative Log Likelihood: 96.9176\tSigma2 Prior: -785.7878\tRegularization: 0.0010\n",
      "Iter: 700  \tTraining Loss: -688.8641    \n",
      "    Negative Log Likelihood: 96.7390\tSigma2 Prior: -785.6041\tRegularization: 0.0011\n",
      "Iter: 710  \tTraining Loss: -689.5557    \n",
      "    Negative Log Likelihood: 96.2795\tSigma2 Prior: -785.8363\tRegularization: 0.0011\n",
      "Iter: 720  \tTraining Loss: -688.7445    \n",
      "    Negative Log Likelihood: 96.7073\tSigma2 Prior: -785.4528\tRegularization: 0.0011\n",
      "Iter: 730  \tTraining Loss: -689.0914    \n",
      "    Negative Log Likelihood: 96.9795\tSigma2 Prior: -786.0720\tRegularization: 0.0011\n",
      "Iter: 740  \tTraining Loss: -689.1019    \n",
      "    Negative Log Likelihood: 96.3107\tSigma2 Prior: -785.4136\tRegularization: 0.0011\n",
      "Iter: 750  \tTraining Loss: -688.6367    \n",
      "    Negative Log Likelihood: 96.8026\tSigma2 Prior: -785.4404\tRegularization: 0.0011\n",
      "Iter: 760  \tTraining Loss: -688.8849    \n",
      "    Negative Log Likelihood: 96.7875\tSigma2 Prior: -785.6735\tRegularization: 0.0011\n",
      "Iter: 770  \tTraining Loss: -688.4100    \n",
      "    Negative Log Likelihood: 97.9559\tSigma2 Prior: -786.3669\tRegularization: 0.0011\n",
      "Iter: 780  \tTraining Loss: -688.3683    \n",
      "    Negative Log Likelihood: 97.3464\tSigma2 Prior: -785.7158\tRegularization: 0.0011\n",
      "Iter: 790  \tTraining Loss: -688.9363    \n",
      "    Negative Log Likelihood: 96.4729\tSigma2 Prior: -785.4103\tRegularization: 0.0011\n",
      "Iter: 800  \tTraining Loss: -689.4181    \n",
      "    Negative Log Likelihood: 96.7505\tSigma2 Prior: -786.1697\tRegularization: 0.0011\n",
      "Iter: 810  \tTraining Loss: -688.8162    \n",
      "    Negative Log Likelihood: 97.4128\tSigma2 Prior: -786.2300\tRegularization: 0.0011\n",
      "Iter: 820  \tTraining Loss: -689.3318    \n",
      "    Negative Log Likelihood: 97.4952\tSigma2 Prior: -786.8281\tRegularization: 0.0011\n",
      "Iter: 830  \tTraining Loss: -688.7277    \n",
      "    Negative Log Likelihood: 97.8446\tSigma2 Prior: -786.5735\tRegularization: 0.0011\n",
      "Iter: 840  \tTraining Loss: -687.1058    \n",
      "    Negative Log Likelihood: 97.5669\tSigma2 Prior: -784.6738\tRegularization: 0.0011\n",
      "Iter: 850  \tTraining Loss: -688.5757    \n",
      "    Negative Log Likelihood: 97.1958\tSigma2 Prior: -785.7726\tRegularization: 0.0011\n",
      "Iter: 860  \tTraining Loss: -688.9025    \n",
      "    Negative Log Likelihood: 97.2850\tSigma2 Prior: -786.1885\tRegularization: 0.0011\n",
      "Iter: 870  \tTraining Loss: -689.2900    \n",
      "    Negative Log Likelihood: 96.7321\tSigma2 Prior: -786.0232\tRegularization: 0.0011\n",
      "Iter: 880  \tTraining Loss: -689.1727    \n",
      "    Negative Log Likelihood: 96.6359\tSigma2 Prior: -785.8098\tRegularization: 0.0011\n",
      "Iter: 890  \tTraining Loss: -689.3892    \n",
      "    Negative Log Likelihood: 97.5814\tSigma2 Prior: -786.9717\tRegularization: 0.0011\n",
      "Iter: 900  \tTraining Loss: -690.0011    \n",
      "    Negative Log Likelihood: 96.0584\tSigma2 Prior: -786.0606\tRegularization: 0.0011\n",
      "Iter: 910  \tTraining Loss: -689.9147    \n",
      "    Negative Log Likelihood: 96.6095\tSigma2 Prior: -786.5253\tRegularization: 0.0011\n",
      "Iter: 920  \tTraining Loss: -690.1637    \n",
      "    Negative Log Likelihood: 96.3002\tSigma2 Prior: -786.4650\tRegularization: 0.0011\n",
      "Iter: 930  \tTraining Loss: -689.2094    \n",
      "    Negative Log Likelihood: 97.1234\tSigma2 Prior: -786.3339\tRegularization: 0.0011\n",
      "Iter: 940  \tTraining Loss: -689.5842    \n",
      "    Negative Log Likelihood: 96.5041\tSigma2 Prior: -786.0894\tRegularization: 0.0011\n",
      "Iter: 950  \tTraining Loss: -689.3096    \n",
      "    Negative Log Likelihood: 96.6753\tSigma2 Prior: -785.9861\tRegularization: 0.0011\n",
      "Iter: 960  \tTraining Loss: -688.5988    \n",
      "    Negative Log Likelihood: 98.3760\tSigma2 Prior: -786.9760\tRegularization: 0.0011\n",
      "Iter: 970  \tTraining Loss: -688.4211    \n",
      "    Negative Log Likelihood: 97.0446\tSigma2 Prior: -785.4668\tRegularization: 0.0011\n",
      "Iter: 980  \tTraining Loss: -687.7800    \n",
      "    Negative Log Likelihood: 97.1961\tSigma2 Prior: -784.9772\tRegularization: 0.0011\n",
      "Iter: 990  \tTraining Loss: -687.8595    \n",
      "    Negative Log Likelihood: 95.7829\tSigma2 Prior: -783.6436\tRegularization: 0.0011\n",
      "Iter: 1000  \tTraining Loss: -686.6078    \n",
      "    Negative Log Likelihood: 96.9305\tSigma2 Prior: -783.5396\tRegularization: 0.0011\n",
      "Iter: 1010  \tTraining Loss: -687.8127    \n",
      "    Negative Log Likelihood: 96.1995\tSigma2 Prior: -784.0134\tRegularization: 0.0012\n",
      "Iter: 1020  \tTraining Loss: -687.7555    \n",
      "    Negative Log Likelihood: 96.4272\tSigma2 Prior: -784.1839\tRegularization: 0.0012\n",
      "Iter: 1030  \tTraining Loss: -688.3588    \n",
      "    Negative Log Likelihood: 95.2024\tSigma2 Prior: -783.5624\tRegularization: 0.0012\n",
      "Iter: 1040  \tTraining Loss: -688.0819    \n",
      "    Negative Log Likelihood: 96.0872\tSigma2 Prior: -784.1703\tRegularization: 0.0012\n",
      "Iter: 1050  \tTraining Loss: -688.1963    \n",
      "    Negative Log Likelihood: 96.3316\tSigma2 Prior: -784.5291\tRegularization: 0.0012\n",
      "Iter: 1060  \tTraining Loss: -688.6213    \n",
      "    Negative Log Likelihood: 96.2217\tSigma2 Prior: -784.8442\tRegularization: 0.0012\n",
      "Iter: 1070  \tTraining Loss: -689.0320    \n",
      "    Negative Log Likelihood: 96.6573\tSigma2 Prior: -785.6904\tRegularization: 0.0012\n",
      "Iter: 1080  \tTraining Loss: -689.4020    \n",
      "    Negative Log Likelihood: 97.9090\tSigma2 Prior: -787.3122\tRegularization: 0.0012\n",
      "Iter: 1090  \tTraining Loss: -687.4309    \n",
      "    Negative Log Likelihood: 95.2413\tSigma2 Prior: -782.6734\tRegularization: 0.0012\n",
      "Iter: 1100  \tTraining Loss: -686.5156    \n",
      "    Negative Log Likelihood: 95.7941\tSigma2 Prior: -782.3109\tRegularization: 0.0012\n",
      "Iter: 1110  \tTraining Loss: -686.7215    \n",
      "    Negative Log Likelihood: 94.9291\tSigma2 Prior: -781.6518\tRegularization: 0.0012\n",
      "Iter: 1120  \tTraining Loss: -687.1890    \n",
      "    Negative Log Likelihood: 95.5028\tSigma2 Prior: -782.6929\tRegularization: 0.0012\n",
      "Iter: 1130  \tTraining Loss: -684.9926    \n",
      "    Negative Log Likelihood: 93.3696\tSigma2 Prior: -778.3633\tRegularization: 0.0012\n",
      "Iter: 1140  \tTraining Loss: -685.7808    \n",
      "    Negative Log Likelihood: 94.6591\tSigma2 Prior: -780.4410\tRegularization: 0.0012\n",
      "Iter: 1150  \tTraining Loss: -683.3371    \n",
      "    Negative Log Likelihood: 94.0775\tSigma2 Prior: -777.4158\tRegularization: 0.0012\n",
      "Iter: 1160  \tTraining Loss: -685.8000    \n",
      "    Negative Log Likelihood: 94.3811\tSigma2 Prior: -780.1823\tRegularization: 0.0012\n",
      "Iter: 1170  \tTraining Loss: -684.9076    \n",
      "    Negative Log Likelihood: 93.7403\tSigma2 Prior: -778.6491\tRegularization: 0.0012\n",
      "Iter: 1180  \tTraining Loss: -685.3419    \n",
      "    Negative Log Likelihood: 94.8984\tSigma2 Prior: -780.2415\tRegularization: 0.0012\n",
      "Iter: 1190  \tTraining Loss: -685.2450    \n",
      "    Negative Log Likelihood: 94.4748\tSigma2 Prior: -779.7209\tRegularization: 0.0012\n",
      "Iter: 1200  \tTraining Loss: -685.0220    \n",
      "    Negative Log Likelihood: 94.7967\tSigma2 Prior: -779.8199\tRegularization: 0.0012\n",
      "Iter: 1210  \tTraining Loss: -684.3026    \n",
      "    Negative Log Likelihood: 96.3301\tSigma2 Prior: -780.6339\tRegularization: 0.0012\n",
      "Iter: 1220  \tTraining Loss: -685.3463    \n",
      "    Negative Log Likelihood: 95.6178\tSigma2 Prior: -780.9653\tRegularization: 0.0012\n",
      "Iter: 1230  \tTraining Loss: -685.5322    \n",
      "    Negative Log Likelihood: 94.3130\tSigma2 Prior: -779.8464\tRegularization: 0.0012\n",
      "Iter: 1240  \tTraining Loss: -684.9004    \n",
      "    Negative Log Likelihood: 95.3470\tSigma2 Prior: -780.2487\tRegularization: 0.0012\n",
      "Iter: 1250  \tTraining Loss: -686.0212    \n",
      "    Negative Log Likelihood: 95.0239\tSigma2 Prior: -781.0464\tRegularization: 0.0012\n",
      "Iter: 1260  \tTraining Loss: -685.0906    \n",
      "    Negative Log Likelihood: 93.8104\tSigma2 Prior: -778.9023\tRegularization: 0.0012\n",
      "Iter: 1270  \tTraining Loss: -686.0173    \n",
      "    Negative Log Likelihood: 97.4912\tSigma2 Prior: -783.5098\tRegularization: 0.0012\n",
      "Iter: 1280  \tTraining Loss: -685.1862    \n",
      "    Negative Log Likelihood: 98.3280\tSigma2 Prior: -783.5154\tRegularization: 0.0012\n",
      "Iter: 1290  \tTraining Loss: -687.0931    \n",
      "    Negative Log Likelihood: 95.8778\tSigma2 Prior: -782.9721\tRegularization: 0.0012\n",
      "Iter: 1300  \tTraining Loss: -688.4210    \n",
      "    Negative Log Likelihood: 95.1001\tSigma2 Prior: -783.5223\tRegularization: 0.0012\n",
      "Iter: 1310  \tTraining Loss: -688.4181    \n",
      "    Negative Log Likelihood: 95.9967\tSigma2 Prior: -784.4160\tRegularization: 0.0012\n",
      "Iter: 1320  \tTraining Loss: -688.4476    \n",
      "    Negative Log Likelihood: 94.8537\tSigma2 Prior: -783.3025\tRegularization: 0.0012\n",
      "Iter: 1330  \tTraining Loss: -688.8324    \n",
      "    Negative Log Likelihood: 95.2489\tSigma2 Prior: -784.0825\tRegularization: 0.0012\n",
      "Iter: 1340  \tTraining Loss: -688.0507    \n",
      "    Negative Log Likelihood: 97.4191\tSigma2 Prior: -785.4709\tRegularization: 0.0012\n",
      "Iter: 1350  \tTraining Loss: -688.0427    \n",
      "    Negative Log Likelihood: 96.2722\tSigma2 Prior: -784.3160\tRegularization: 0.0012\n",
      "Iter: 1360  \tTraining Loss: -687.8636    \n",
      "    Negative Log Likelihood: 98.8947\tSigma2 Prior: -786.7596\tRegularization: 0.0012\n",
      "Iter: 1370  \tTraining Loss: -687.9390    \n",
      "    Negative Log Likelihood: 95.8643\tSigma2 Prior: -783.8044\tRegularization: 0.0012\n",
      "Iter: 1380  \tTraining Loss: -686.5719    \n",
      "    Negative Log Likelihood: 96.1845\tSigma2 Prior: -782.7577\tRegularization: 0.0012\n",
      "Iter: 1390  \tTraining Loss: -688.3685    \n",
      "    Negative Log Likelihood: 95.7379\tSigma2 Prior: -784.1077\tRegularization: 0.0012\n",
      "Iter: 1400  \tTraining Loss: -684.8790    \n",
      "    Negative Log Likelihood: 100.2652\tSigma2 Prior: -785.1455\tRegularization: 0.0012\n",
      "Iter: 1410  \tTraining Loss: -687.6039    \n",
      "    Negative Log Likelihood: 97.0926\tSigma2 Prior: -784.6978\tRegularization: 0.0012\n",
      "Iter: 1420  \tTraining Loss: -687.8777    \n",
      "    Negative Log Likelihood: 96.7367\tSigma2 Prior: -784.6156\tRegularization: 0.0012\n",
      "Iter: 1430  \tTraining Loss: -688.2799    \n",
      "    Negative Log Likelihood: 96.0245\tSigma2 Prior: -784.3056\tRegularization: 0.0013\n",
      "Iter: 1440  \tTraining Loss: -688.1387    \n",
      "    Negative Log Likelihood: 96.2982\tSigma2 Prior: -784.4382\tRegularization: 0.0013\n",
      "Iter: 1450  \tTraining Loss: -689.0855    \n",
      "    Negative Log Likelihood: 95.9010\tSigma2 Prior: -784.9878\tRegularization: 0.0013\n",
      "Iter: 1460  \tTraining Loss: -688.7606    \n",
      "    Negative Log Likelihood: 96.0262\tSigma2 Prior: -784.7881\tRegularization: 0.0013\n",
      "Iter: 1470  \tTraining Loss: -688.5811    \n",
      "    Negative Log Likelihood: 96.5689\tSigma2 Prior: -785.1512\tRegularization: 0.0013\n",
      "Iter: 1480  \tTraining Loss: -689.1351    \n",
      "    Negative Log Likelihood: 96.5945\tSigma2 Prior: -785.7309\tRegularization: 0.0013\n",
      "Iter: 1490  \tTraining Loss: -689.2862    \n",
      "    Negative Log Likelihood: 95.7523\tSigma2 Prior: -785.0398\tRegularization: 0.0013\n",
      "Iter: 1500  \tTraining Loss: -688.9894    \n",
      "    Negative Log Likelihood: 96.4292\tSigma2 Prior: -785.4199\tRegularization: 0.0013\n",
      "Iter: 1510  \tTraining Loss: -689.4588    \n",
      "    Negative Log Likelihood: 95.6477\tSigma2 Prior: -785.1078\tRegularization: 0.0013\n",
      "Iter: 1520  \tTraining Loss: -689.5139    \n",
      "    Negative Log Likelihood: 96.4481\tSigma2 Prior: -785.9633\tRegularization: 0.0013\n",
      "Iter: 1530  \tTraining Loss: -690.0455    \n",
      "    Negative Log Likelihood: 94.7771\tSigma2 Prior: -784.8239\tRegularization: 0.0013\n",
      "Iter: 1540  \tTraining Loss: -690.7381    \n",
      "    Negative Log Likelihood: 93.6570\tSigma2 Prior: -784.3964\tRegularization: 0.0013\n",
      "Iter: 1550  \tTraining Loss: -690.0522    \n",
      "    Negative Log Likelihood: 92.7542\tSigma2 Prior: -782.8077\tRegularization: 0.0013\n",
      "Iter: 1560  \tTraining Loss: -689.7524    \n",
      "    Negative Log Likelihood: 93.1481\tSigma2 Prior: -782.9019\tRegularization: 0.0013\n",
      "Iter: 1570  \tTraining Loss: -687.1540    \n",
      "    Negative Log Likelihood: 97.7183\tSigma2 Prior: -784.8735\tRegularization: 0.0013\n",
      "Iter: 1580  \tTraining Loss: -686.2282    \n",
      "    Negative Log Likelihood: 97.1890\tSigma2 Prior: -783.4185\tRegularization: 0.0013\n",
      "Iter: 1590  \tTraining Loss: -686.4213    \n",
      "    Negative Log Likelihood: 96.5178\tSigma2 Prior: -782.9404\tRegularization: 0.0013\n",
      "Iter: 1600  \tTraining Loss: -685.3864    \n",
      "    Negative Log Likelihood: 93.9717\tSigma2 Prior: -779.3593\tRegularization: 0.0013\n",
      "Iter: 1610  \tTraining Loss: -685.1744    \n",
      "    Negative Log Likelihood: 93.1088\tSigma2 Prior: -778.2845\tRegularization: 0.0013\n",
      "Iter: 1620  \tTraining Loss: -684.5598    \n",
      "    Negative Log Likelihood: 93.8204\tSigma2 Prior: -778.3815\tRegularization: 0.0013\n",
      "Iter: 1630  \tTraining Loss: -685.2890    \n",
      "    Negative Log Likelihood: 93.7832\tSigma2 Prior: -779.0734\tRegularization: 0.0013\n",
      "Iter: 1640  \tTraining Loss: -684.1909    \n",
      "    Negative Log Likelihood: 93.1974\tSigma2 Prior: -777.3896\tRegularization: 0.0013\n",
      "Iter: 1650  \tTraining Loss: -684.6274    \n",
      "    Negative Log Likelihood: 93.0099\tSigma2 Prior: -777.6385\tRegularization: 0.0013\n",
      "Iter: 1660  \tTraining Loss: -685.7225    \n",
      "    Negative Log Likelihood: 92.1620\tSigma2 Prior: -777.8857\tRegularization: 0.0013\n",
      "Iter: 1670  \tTraining Loss: -685.4414    \n",
      "    Negative Log Likelihood: 93.8186\tSigma2 Prior: -779.2614\tRegularization: 0.0013\n",
      "Iter: 1680  \tTraining Loss: -687.3713    \n",
      "    Negative Log Likelihood: 93.3331\tSigma2 Prior: -780.7057\tRegularization: 0.0013\n",
      "Iter: 1690  \tTraining Loss: -687.1674    \n",
      "    Negative Log Likelihood: 92.0334\tSigma2 Prior: -779.2020\tRegularization: 0.0013\n",
      "Iter: 1700  \tTraining Loss: -687.0433    \n",
      "    Negative Log Likelihood: 95.6927\tSigma2 Prior: -782.7373\tRegularization: 0.0013\n",
      "Iter: 1710  \tTraining Loss: -686.6962    \n",
      "    Negative Log Likelihood: 90.8500\tSigma2 Prior: -777.5475\tRegularization: 0.0013\n",
      "Iter: 1720  \tTraining Loss: -686.1349    \n",
      "    Negative Log Likelihood: 95.3022\tSigma2 Prior: -781.4384\tRegularization: 0.0013\n",
      "Iter: 1730  \tTraining Loss: -684.7565    \n",
      "    Negative Log Likelihood: 92.7351\tSigma2 Prior: -777.4929\tRegularization: 0.0013\n",
      "Iter: 1740  \tTraining Loss: -662.0411    \n",
      "    Negative Log Likelihood: 112.8768\tSigma2 Prior: -774.9192\tRegularization: 0.0013\n",
      "Iter: 1750  \tTraining Loss: -681.7822    \n",
      "    Negative Log Likelihood: 89.3301\tSigma2 Prior: -771.1136\tRegularization: 0.0013\n",
      "Iter: 1760  \tTraining Loss: -680.0565    \n",
      "    Negative Log Likelihood: 92.5854\tSigma2 Prior: -772.6432\tRegularization: 0.0013\n",
      "Iter: 1770  \tTraining Loss: -677.2426    \n",
      "    Negative Log Likelihood: 90.6324\tSigma2 Prior: -767.8763\tRegularization: 0.0013\n",
      "Iter: 1780  \tTraining Loss: -678.8492    \n",
      "    Negative Log Likelihood: 88.1201\tSigma2 Prior: -766.9706\tRegularization: 0.0013\n",
      "Iter: 1790  \tTraining Loss: -677.9870    \n",
      "    Negative Log Likelihood: 88.9616\tSigma2 Prior: -766.9500\tRegularization: 0.0013\n",
      "Iter: 1800  \tTraining Loss: -676.2167    \n",
      "    Negative Log Likelihood: 90.0474\tSigma2 Prior: -766.2654\tRegularization: 0.0013\n",
      "Iter: 1810  \tTraining Loss: -676.9448    \n",
      "    Negative Log Likelihood: 89.9586\tSigma2 Prior: -766.9047\tRegularization: 0.0013\n",
      "Iter: 1820  \tTraining Loss: -677.1922    \n",
      "    Negative Log Likelihood: 88.9019\tSigma2 Prior: -766.0955\tRegularization: 0.0013\n",
      "Iter: 1830  \tTraining Loss: -678.3806    \n",
      "    Negative Log Likelihood: 89.7680\tSigma2 Prior: -768.1498\tRegularization: 0.0013\n",
      "Iter: 1840  \tTraining Loss: -679.0762    \n",
      "    Negative Log Likelihood: 89.9981\tSigma2 Prior: -769.0756\tRegularization: 0.0013\n",
      "Iter: 1850  \tTraining Loss: -680.0007    \n",
      "    Negative Log Likelihood: 91.0009\tSigma2 Prior: -771.0029\tRegularization: 0.0013\n",
      "Iter: 1860  \tTraining Loss: -681.2452    \n",
      "    Negative Log Likelihood: 91.1069\tSigma2 Prior: -772.3534\tRegularization: 0.0013\n",
      "Iter: 1870  \tTraining Loss: -682.1786    \n",
      "    Negative Log Likelihood: 91.0327\tSigma2 Prior: -773.2127\tRegularization: 0.0013\n",
      "Iter: 1880  \tTraining Loss: -682.7221    \n",
      "    Negative Log Likelihood: 91.3725\tSigma2 Prior: -774.0959\tRegularization: 0.0013\n",
      "Iter: 1890  \tTraining Loss: -683.0588    \n",
      "    Negative Log Likelihood: 90.0979\tSigma2 Prior: -773.1580\tRegularization: 0.0013\n",
      "Iter: 1900  \tTraining Loss: -683.3010    \n",
      "    Negative Log Likelihood: 91.3431\tSigma2 Prior: -774.6454\tRegularization: 0.0013\n",
      "Iter: 1910  \tTraining Loss: -683.2675    \n",
      "    Negative Log Likelihood: 92.7286\tSigma2 Prior: -775.9974\tRegularization: 0.0013\n",
      "Iter: 1920  \tTraining Loss: -681.1725    \n",
      "    Negative Log Likelihood: 95.2969\tSigma2 Prior: -776.4708\tRegularization: 0.0013\n",
      "Iter: 1930  \tTraining Loss: -682.0893    \n",
      "    Negative Log Likelihood: 91.6941\tSigma2 Prior: -773.7847\tRegularization: 0.0013\n",
      "Iter: 1940  \tTraining Loss: -681.7214    \n",
      "    Negative Log Likelihood: 90.5324\tSigma2 Prior: -772.2551\tRegularization: 0.0013\n",
      "Iter: 1950  \tTraining Loss: -677.1860    \n",
      "    Negative Log Likelihood: 93.0874\tSigma2 Prior: -770.2747\tRegularization: 0.0013\n",
      "Iter: 1960  \tTraining Loss: -679.3568    \n",
      "    Negative Log Likelihood: 90.2965\tSigma2 Prior: -769.6546\tRegularization: 0.0013\n",
      "Iter: 1970  \tTraining Loss: -679.8129    \n",
      "    Negative Log Likelihood: 91.2948\tSigma2 Prior: -771.1091\tRegularization: 0.0013\n",
      "Iter: 1980  \tTraining Loss: -681.3839    \n",
      "    Negative Log Likelihood: 89.0923\tSigma2 Prior: -770.4776\tRegularization: 0.0013\n",
      "Iter: 1990  \tTraining Loss: -679.5547    \n",
      "    Negative Log Likelihood: 92.2093\tSigma2 Prior: -771.7653\tRegularization: 0.0013\n",
      "Iter: 2000  \tTraining Loss: -676.7026    \n",
      "    Negative Log Likelihood: 91.0011\tSigma2 Prior: -767.7050\tRegularization: 0.0013\n",
      "Iter: 2010  \tTraining Loss: -678.2059    \n",
      "    Negative Log Likelihood: 85.7610\tSigma2 Prior: -763.9682\tRegularization: 0.0013\n",
      "Iter: 2020  \tTraining Loss: -677.9812    \n",
      "    Negative Log Likelihood: 89.7254\tSigma2 Prior: -767.7079\tRegularization: 0.0013\n",
      "Iter: 2030  \tTraining Loss: -675.3921    \n",
      "    Negative Log Likelihood: 87.9594\tSigma2 Prior: -763.3528\tRegularization: 0.0014\n",
      "Iter: 2040  \tTraining Loss: -676.2424    \n",
      "    Negative Log Likelihood: 88.9384\tSigma2 Prior: -765.1822\tRegularization: 0.0014\n",
      "Iter: 2050  \tTraining Loss: -675.0092    \n",
      "    Negative Log Likelihood: 87.5396\tSigma2 Prior: -762.5501\tRegularization: 0.0014\n",
      "Iter: 2060  \tTraining Loss: -673.4160    \n",
      "    Negative Log Likelihood: 93.1203\tSigma2 Prior: -766.5377\tRegularization: 0.0014\n",
      "Iter: 2070  \tTraining Loss: -674.3473    \n",
      "    Negative Log Likelihood: 89.9641\tSigma2 Prior: -764.3127\tRegularization: 0.0014\n",
      "Iter: 2080  \tTraining Loss: -677.1646    \n",
      "    Negative Log Likelihood: 91.9395\tSigma2 Prior: -769.1055\tRegularization: 0.0014\n",
      "Iter: 2090  \tTraining Loss: -678.7137    \n",
      "    Negative Log Likelihood: 91.6259\tSigma2 Prior: -770.3409\tRegularization: 0.0014\n",
      "Iter: 2100  \tTraining Loss: -680.2802    \n",
      "    Negative Log Likelihood: 88.9611\tSigma2 Prior: -769.2427\tRegularization: 0.0014\n",
      "Iter: 2110  \tTraining Loss: -677.5165    \n",
      "    Negative Log Likelihood: 89.6079\tSigma2 Prior: -767.1258\tRegularization: 0.0014\n",
      "Iter: 2120  \tTraining Loss: -679.3440    \n",
      "    Negative Log Likelihood: 82.9847\tSigma2 Prior: -762.3301\tRegularization: 0.0014\n",
      "Iter: 2130  \tTraining Loss: -678.8162    \n",
      "    Negative Log Likelihood: 89.8780\tSigma2 Prior: -768.6955\tRegularization: 0.0014\n",
      "Iter: 2140  \tTraining Loss: -677.4093    \n",
      "    Negative Log Likelihood: 90.0204\tSigma2 Prior: -767.4310\tRegularization: 0.0014\n",
      "Iter: 2150  \tTraining Loss: -677.1804    \n",
      "    Negative Log Likelihood: 88.5361\tSigma2 Prior: -765.7178\tRegularization: 0.0014\n",
      "Iter: 2160  \tTraining Loss: -672.3210    \n",
      "    Negative Log Likelihood: 100.0042\tSigma2 Prior: -772.3266\tRegularization: 0.0014\n",
      "Iter: 2170  \tTraining Loss: -678.7870    \n",
      "    Negative Log Likelihood: 89.6792\tSigma2 Prior: -768.4676\tRegularization: 0.0014\n",
      "Iter: 2180  \tTraining Loss: -678.5066    \n",
      "    Negative Log Likelihood: 92.1804\tSigma2 Prior: -770.6883\tRegularization: 0.0014\n",
      "Iter: 2190  \tTraining Loss: -677.7259    \n",
      "    Negative Log Likelihood: 90.9801\tSigma2 Prior: -768.7073\tRegularization: 0.0014\n",
      "Iter: 2200  \tTraining Loss: -678.5024    \n",
      "    Negative Log Likelihood: 92.1074\tSigma2 Prior: -770.6111\tRegularization: 0.0014\n",
      "Iter: 2210  \tTraining Loss: -680.1614    \n",
      "    Negative Log Likelihood: 87.8267\tSigma2 Prior: -767.9895\tRegularization: 0.0014\n",
      "Iter: 2220  \tTraining Loss: -678.7484    \n",
      "    Negative Log Likelihood: 88.1307\tSigma2 Prior: -766.8804\tRegularization: 0.0014\n",
      "Iter: 2230  \tTraining Loss: -680.6000    \n",
      "    Negative Log Likelihood: 88.5583\tSigma2 Prior: -769.1597\tRegularization: 0.0014\n",
      "Iter: 2240  \tTraining Loss: -679.9316    \n",
      "    Negative Log Likelihood: 90.6119\tSigma2 Prior: -770.5449\tRegularization: 0.0014\n",
      "Iter: 2250  \tTraining Loss: -675.2429    \n",
      "    Negative Log Likelihood: 91.1095\tSigma2 Prior: -766.3538\tRegularization: 0.0014\n",
      "Iter: 2260  \tTraining Loss: -678.9664    \n",
      "    Negative Log Likelihood: 91.7247\tSigma2 Prior: -770.6925\tRegularization: 0.0014\n",
      "Iter: 2270  \tTraining Loss: -680.4219    \n",
      "    Negative Log Likelihood: 90.1915\tSigma2 Prior: -770.6148\tRegularization: 0.0014\n",
      "Iter: 2280  \tTraining Loss: -681.4905    \n",
      "    Negative Log Likelihood: 91.7149\tSigma2 Prior: -773.2069\tRegularization: 0.0014\n",
      "Iter: 2290  \tTraining Loss: -682.2552    \n",
      "    Negative Log Likelihood: 90.0792\tSigma2 Prior: -772.3358\tRegularization: 0.0014\n",
      "Iter: 2300  \tTraining Loss: -682.1377    \n",
      "    Negative Log Likelihood: 89.7045\tSigma2 Prior: -771.8436\tRegularization: 0.0014\n",
      "Iter: 2310  \tTraining Loss: -682.9815    \n",
      "    Negative Log Likelihood: 89.7325\tSigma2 Prior: -772.7153\tRegularization: 0.0014\n",
      "Iter: 2320  \tTraining Loss: -683.5424    \n",
      "    Negative Log Likelihood: 90.4503\tSigma2 Prior: -773.9941\tRegularization: 0.0014\n",
      "Iter: 2330  \tTraining Loss: -684.0272    \n",
      "    Negative Log Likelihood: 91.8578\tSigma2 Prior: -775.8864\tRegularization: 0.0014\n",
      "Iter: 2340  \tTraining Loss: -684.4793    \n",
      "    Negative Log Likelihood: 92.2568\tSigma2 Prior: -776.7375\tRegularization: 0.0014\n",
      "Iter: 2350  \tTraining Loss: -684.9473    \n",
      "    Negative Log Likelihood: 91.9054\tSigma2 Prior: -776.8541\tRegularization: 0.0014\n",
      "Iter: 2360  \tTraining Loss: -685.3793    \n",
      "    Negative Log Likelihood: 93.0882\tSigma2 Prior: -778.4689\tRegularization: 0.0014\n",
      "Iter: 2370  \tTraining Loss: -685.4453    \n",
      "    Negative Log Likelihood: 91.9820\tSigma2 Prior: -777.4288\tRegularization: 0.0014\n",
      "Iter: 2380  \tTraining Loss: -685.2155    \n",
      "    Negative Log Likelihood: 92.1285\tSigma2 Prior: -777.3454\tRegularization: 0.0014\n",
      "Iter: 2390  \tTraining Loss: -685.5375    \n",
      "    Negative Log Likelihood: 92.5459\tSigma2 Prior: -778.0847\tRegularization: 0.0014\n",
      "Iter: 2400  \tTraining Loss: -685.9724    \n",
      "    Negative Log Likelihood: 93.8152\tSigma2 Prior: -779.7890\tRegularization: 0.0014\n",
      "Iter: 2410  \tTraining Loss: -686.5182    \n",
      "    Negative Log Likelihood: 92.1791\tSigma2 Prior: -778.6988\tRegularization: 0.0014\n",
      "Iter: 2420  \tTraining Loss: -687.1086    \n",
      "    Negative Log Likelihood: 91.3520\tSigma2 Prior: -778.4620\tRegularization: 0.0014\n",
      "Iter: 2430  \tTraining Loss: -683.2141    \n",
      "    Negative Log Likelihood: 90.3238\tSigma2 Prior: -773.5392\tRegularization: 0.0014\n",
      "Iter: 2440  \tTraining Loss: -684.7394    \n",
      "    Negative Log Likelihood: 91.7426\tSigma2 Prior: -776.4834\tRegularization: 0.0014\n",
      "Iter: 2450  \tTraining Loss: -682.5405    \n",
      "    Negative Log Likelihood: 94.8841\tSigma2 Prior: -777.4260\tRegularization: 0.0014\n",
      "Iter: 2460  \tTraining Loss: -684.0621    \n",
      "    Negative Log Likelihood: 92.8592\tSigma2 Prior: -776.9227\tRegularization: 0.0014\n",
      "Iter: 2470  \tTraining Loss: -684.9570    \n",
      "    Negative Log Likelihood: 94.9966\tSigma2 Prior: -779.9550\tRegularization: 0.0014\n",
      "Iter: 2480  \tTraining Loss: -685.6748    \n",
      "    Negative Log Likelihood: 91.8923\tSigma2 Prior: -777.5685\tRegularization: 0.0014\n",
      "Iter: 2490  \tTraining Loss: -685.7526    \n",
      "    Negative Log Likelihood: 92.9390\tSigma2 Prior: -778.6930\tRegularization: 0.0014\n",
      "Iter: 2500  \tTraining Loss: -685.6263    \n",
      "    Negative Log Likelihood: 93.7064\tSigma2 Prior: -779.3341\tRegularization: 0.0014\n",
      "Iter: 2510  \tTraining Loss: -685.6520    \n",
      "    Negative Log Likelihood: 93.7451\tSigma2 Prior: -779.3985\tRegularization: 0.0014\n",
      "Iter: 2520  \tTraining Loss: -686.3934    \n",
      "    Negative Log Likelihood: 94.3247\tSigma2 Prior: -780.7195\tRegularization: 0.0014\n",
      "Iter: 2530  \tTraining Loss: -686.5042    \n",
      "    Negative Log Likelihood: 93.5957\tSigma2 Prior: -780.1014\tRegularization: 0.0014\n",
      "Iter: 2540  \tTraining Loss: -686.9675    \n",
      "    Negative Log Likelihood: 93.3577\tSigma2 Prior: -780.3267\tRegularization: 0.0014\n",
      "Iter: 2550  \tTraining Loss: -686.8052    \n",
      "    Negative Log Likelihood: 94.0087\tSigma2 Prior: -780.8153\tRegularization: 0.0014\n",
      "Iter: 2560  \tTraining Loss: -686.8897    \n",
      "    Negative Log Likelihood: 92.7617\tSigma2 Prior: -779.6528\tRegularization: 0.0014\n",
      "Iter: 2570  \tTraining Loss: -683.5795    \n",
      "    Negative Log Likelihood: 95.1041\tSigma2 Prior: -778.6850\tRegularization: 0.0014\n",
      "Iter: 2580  \tTraining Loss: -684.8371    \n",
      "    Negative Log Likelihood: 93.1370\tSigma2 Prior: -777.9755\tRegularization: 0.0014\n",
      "Iter: 2590  \tTraining Loss: -686.1549    \n",
      "    Negative Log Likelihood: 90.9675\tSigma2 Prior: -777.1238\tRegularization: 0.0014\n",
      "Iter: 2600  \tTraining Loss: -685.0100    \n",
      "    Negative Log Likelihood: 91.5195\tSigma2 Prior: -776.5309\tRegularization: 0.0014\n",
      "Iter: 2610  \tTraining Loss: -684.9281    \n",
      "    Negative Log Likelihood: 93.1398\tSigma2 Prior: -778.0693\tRegularization: 0.0014\n",
      "Iter: 2620  \tTraining Loss: -685.7755    \n",
      "    Negative Log Likelihood: 89.9173\tSigma2 Prior: -775.6942\tRegularization: 0.0014\n",
      "Iter: 2630  \tTraining Loss: -683.1244    \n",
      "    Negative Log Likelihood: 94.5735\tSigma2 Prior: -777.6993\tRegularization: 0.0014\n",
      "Iter: 2640  \tTraining Loss: -685.7521    \n",
      "    Negative Log Likelihood: 90.1833\tSigma2 Prior: -775.9368\tRegularization: 0.0014\n",
      "Iter: 2650  \tTraining Loss: -681.2361    \n",
      "    Negative Log Likelihood: 91.2388\tSigma2 Prior: -772.4763\tRegularization: 0.0014\n",
      "Iter: 2660  \tTraining Loss: -683.1605    \n",
      "    Negative Log Likelihood: 88.4625\tSigma2 Prior: -771.6244\tRegularization: 0.0014\n",
      "Iter: 2670  \tTraining Loss: -676.6414    \n",
      "    Negative Log Likelihood: 90.2154\tSigma2 Prior: -766.8582\tRegularization: 0.0014\n",
      "Iter: 2680  \tTraining Loss: -677.6424    \n",
      "    Negative Log Likelihood: 89.2419\tSigma2 Prior: -766.8857\tRegularization: 0.0014\n",
      "Iter: 2690  \tTraining Loss: -678.0546    \n",
      "    Negative Log Likelihood: 89.5779\tSigma2 Prior: -767.6339\tRegularization: 0.0014\n",
      "Iter: 2700  \tTraining Loss: -676.4715    \n",
      "    Negative Log Likelihood: 89.3653\tSigma2 Prior: -765.8383\tRegularization: 0.0014\n",
      "Iter: 2710  \tTraining Loss: -675.6088    \n",
      "    Negative Log Likelihood: 90.9246\tSigma2 Prior: -766.5349\tRegularization: 0.0014\n",
      "Iter: 2720  \tTraining Loss: -676.5129    \n",
      "    Negative Log Likelihood: 87.5772\tSigma2 Prior: -764.0917\tRegularization: 0.0014\n",
      "Iter: 2730  \tTraining Loss: -676.1966    \n",
      "    Negative Log Likelihood: 89.1133\tSigma2 Prior: -765.3114\tRegularization: 0.0014\n",
      "Iter: 2740  \tTraining Loss: -676.3989    \n",
      "    Negative Log Likelihood: 89.0551\tSigma2 Prior: -765.4554\tRegularization: 0.0014\n",
      "Iter: 2750  \tTraining Loss: -678.5950    \n",
      "    Negative Log Likelihood: 87.5550\tSigma2 Prior: -766.1514\tRegularization: 0.0014\n",
      "Iter: 2760  \tTraining Loss: -676.1031    \n",
      "    Negative Log Likelihood: 93.9626\tSigma2 Prior: -770.0673\tRegularization: 0.0014\n",
      "Iter: 2770  \tTraining Loss: -678.3638    \n",
      "    Negative Log Likelihood: 90.2076\tSigma2 Prior: -768.5728\tRegularization: 0.0014\n",
      "Iter: 2780  \tTraining Loss: -680.1991    \n",
      "    Negative Log Likelihood: 86.8263\tSigma2 Prior: -767.0269\tRegularization: 0.0014\n",
      "Iter: 2790  \tTraining Loss: -678.9106    \n",
      "    Negative Log Likelihood: 82.0298\tSigma2 Prior: -760.9418\tRegularization: 0.0014\n",
      "Iter: 2800  \tTraining Loss: -675.3690    \n",
      "    Negative Log Likelihood: 94.0075\tSigma2 Prior: -769.3779\tRegularization: 0.0014\n",
      "Iter: 2810  \tTraining Loss: -679.3247    \n",
      "    Negative Log Likelihood: 85.7653\tSigma2 Prior: -765.0915\tRegularization: 0.0014\n",
      "Iter: 2820  \tTraining Loss: -680.3590    \n",
      "    Negative Log Likelihood: 90.8639\tSigma2 Prior: -771.2244\tRegularization: 0.0014\n",
      "Iter: 2830  \tTraining Loss: -681.3362    \n",
      "    Negative Log Likelihood: 88.6851\tSigma2 Prior: -770.0228\tRegularization: 0.0014\n",
      "Iter: 2840  \tTraining Loss: -679.3386    \n",
      "    Negative Log Likelihood: 91.2490\tSigma2 Prior: -770.5891\tRegularization: 0.0015\n",
      "Iter: 2850  \tTraining Loss: -678.0612    \n",
      "    Negative Log Likelihood: 88.7107\tSigma2 Prior: -766.7734\tRegularization: 0.0015\n",
      "Iter: 2860  \tTraining Loss: -678.1786    \n",
      "    Negative Log Likelihood: 85.8455\tSigma2 Prior: -764.0256\tRegularization: 0.0015\n",
      "Iter: 2870  \tTraining Loss: -679.7704    \n",
      "    Negative Log Likelihood: 89.4642\tSigma2 Prior: -769.2360\tRegularization: 0.0015\n",
      "Iter: 2880  \tTraining Loss: -679.8391    \n",
      "    Negative Log Likelihood: 90.1417\tSigma2 Prior: -769.9823\tRegularization: 0.0015\n",
      "Iter: 2890  \tTraining Loss: -679.8085    \n",
      "    Negative Log Likelihood: 89.3796\tSigma2 Prior: -769.1896\tRegularization: 0.0015\n",
      "Iter: 2900  \tTraining Loss: -680.6425    \n",
      "    Negative Log Likelihood: 88.9611\tSigma2 Prior: -769.6050\tRegularization: 0.0015\n",
      "Iter: 2910  \tTraining Loss: -680.7140    \n",
      "    Negative Log Likelihood: 88.0554\tSigma2 Prior: -768.7709\tRegularization: 0.0015\n",
      "Iter: 2920  \tTraining Loss: -680.6585    \n",
      "    Negative Log Likelihood: 90.0395\tSigma2 Prior: -770.6995\tRegularization: 0.0015\n",
      "Iter: 2930  \tTraining Loss: -680.8953    \n",
      "    Negative Log Likelihood: 90.4317\tSigma2 Prior: -771.3285\tRegularization: 0.0015\n",
      "Iter: 2940  \tTraining Loss: -680.8046    \n",
      "    Negative Log Likelihood: 88.9254\tSigma2 Prior: -769.7315\tRegularization: 0.0015\n",
      "Iter: 2950  \tTraining Loss: -681.0454    \n",
      "    Negative Log Likelihood: 90.7889\tSigma2 Prior: -771.8358\tRegularization: 0.0015\n",
      "Iter: 2960  \tTraining Loss: -680.6147    \n",
      "    Negative Log Likelihood: 90.4283\tSigma2 Prior: -771.0446\tRegularization: 0.0015\n",
      "Iter: 2970  \tTraining Loss: -681.5178    \n",
      "    Negative Log Likelihood: 89.9691\tSigma2 Prior: -771.4884\tRegularization: 0.0015\n",
      "Iter: 2980  \tTraining Loss: -681.3383    \n",
      "    Negative Log Likelihood: 90.9340\tSigma2 Prior: -772.2737\tRegularization: 0.0015\n",
      "Iter: 2990  \tTraining Loss: -682.5533    \n",
      "    Negative Log Likelihood: 91.3479\tSigma2 Prior: -773.9026\tRegularization: 0.0015\n",
      "Iter: 3000  \tTraining Loss: -680.5582    \n",
      "    Negative Log Likelihood: 89.7223\tSigma2 Prior: -770.2819\tRegularization: 0.0015\n",
      "Iter: 3010  \tTraining Loss: -680.7687    \n",
      "    Negative Log Likelihood: 91.2541\tSigma2 Prior: -772.0244\tRegularization: 0.0015\n",
      "Iter: 3020  \tTraining Loss: -681.5881    \n",
      "    Negative Log Likelihood: 91.4664\tSigma2 Prior: -773.0560\tRegularization: 0.0015\n",
      "Iter: 3030  \tTraining Loss: -682.2096    \n",
      "    Negative Log Likelihood: 90.7291\tSigma2 Prior: -772.9402\tRegularization: 0.0015\n",
      "Iter: 3040  \tTraining Loss: -682.4485    \n",
      "    Negative Log Likelihood: 91.3444\tSigma2 Prior: -773.7944\tRegularization: 0.0015\n",
      "Iter: 3050  \tTraining Loss: -682.8172    \n",
      "    Negative Log Likelihood: 90.2735\tSigma2 Prior: -773.0921\tRegularization: 0.0015\n",
      "Iter: 3060  \tTraining Loss: -682.9355    \n",
      "    Negative Log Likelihood: 90.8389\tSigma2 Prior: -773.7759\tRegularization: 0.0015\n",
      "Iter: 3070  \tTraining Loss: -682.9999    \n",
      "    Negative Log Likelihood: 89.9405\tSigma2 Prior: -772.9418\tRegularization: 0.0015\n",
      "Iter: 3080  \tTraining Loss: -683.0239    \n",
      "    Negative Log Likelihood: 90.1474\tSigma2 Prior: -773.1728\tRegularization: 0.0015\n",
      "Iter: 3090  \tTraining Loss: -681.9223    \n",
      "    Negative Log Likelihood: 91.4508\tSigma2 Prior: -773.3745\tRegularization: 0.0015\n",
      "Iter: 3100  \tTraining Loss: -683.7542    \n",
      "    Negative Log Likelihood: 87.4982\tSigma2 Prior: -771.2538\tRegularization: 0.0015\n",
      "Iter: 3110  \tTraining Loss: -681.9599    \n",
      "    Negative Log Likelihood: 90.0459\tSigma2 Prior: -772.0073\tRegularization: 0.0015\n",
      "Iter: 3120  \tTraining Loss: -683.1078    \n",
      "    Negative Log Likelihood: 90.5682\tSigma2 Prior: -773.6775\tRegularization: 0.0015\n",
      "Iter: 3130  \tTraining Loss: -682.3776    \n",
      "    Negative Log Likelihood: 91.4016\tSigma2 Prior: -773.7806\tRegularization: 0.0015\n",
      "Iter: 3140  \tTraining Loss: -679.8860    \n",
      "    Negative Log Likelihood: 89.8777\tSigma2 Prior: -769.7653\tRegularization: 0.0015\n",
      "Iter: 3150  \tTraining Loss: -682.2209    \n",
      "    Negative Log Likelihood: 86.4955\tSigma2 Prior: -768.7178\tRegularization: 0.0015\n",
      "Iter: 3160  \tTraining Loss: -681.4501    \n",
      "    Negative Log Likelihood: 90.2478\tSigma2 Prior: -771.6995\tRegularization: 0.0015\n",
      "Iter: 3170  \tTraining Loss: -681.3602    \n",
      "    Negative Log Likelihood: 89.4448\tSigma2 Prior: -770.8064\tRegularization: 0.0015\n",
      "Iter: 3180  \tTraining Loss: -676.1208    \n",
      "    Negative Log Likelihood: 79.5302\tSigma2 Prior: -755.6525\tRegularization: 0.0015\n",
      "Iter: 3190  \tTraining Loss: -678.0222    \n",
      "    Negative Log Likelihood: 85.2655\tSigma2 Prior: -763.2892\tRegularization: 0.0015\n",
      "Iter: 3200  \tTraining Loss: -679.1172    \n",
      "    Negative Log Likelihood: 87.5402\tSigma2 Prior: -766.6589\tRegularization: 0.0015\n",
      "Iter: 3210  \tTraining Loss: -678.4816    \n",
      "    Negative Log Likelihood: 88.7157\tSigma2 Prior: -767.1987\tRegularization: 0.0015\n",
      "Iter: 3220  \tTraining Loss: -678.2542    \n",
      "    Negative Log Likelihood: 91.6741\tSigma2 Prior: -769.9298\tRegularization: 0.0015\n",
      "Iter: 3230  \tTraining Loss: -679.3521    \n",
      "    Negative Log Likelihood: 89.6573\tSigma2 Prior: -769.0109\tRegularization: 0.0015\n",
      "Iter: 3240  \tTraining Loss: -680.1274    \n",
      "    Negative Log Likelihood: 88.9246\tSigma2 Prior: -769.0535\tRegularization: 0.0015\n",
      "Iter: 3250  \tTraining Loss: -679.0641    \n",
      "    Negative Log Likelihood: 91.3681\tSigma2 Prior: -770.4337\tRegularization: 0.0015\n",
      "Iter: 3260  \tTraining Loss: -680.7090    \n",
      "    Negative Log Likelihood: 86.8012\tSigma2 Prior: -767.5116\tRegularization: 0.0015\n",
      "Iter: 3270  \tTraining Loss: -676.7916    \n",
      "    Negative Log Likelihood: 94.6540\tSigma2 Prior: -771.4471\tRegularization: 0.0015\n",
      "Iter: 3280  \tTraining Loss: -681.3602    \n",
      "    Negative Log Likelihood: 86.8546\tSigma2 Prior: -768.2162\tRegularization: 0.0015\n",
      "Iter: 3290  \tTraining Loss: -680.0798    \n",
      "    Negative Log Likelihood: 89.3739\tSigma2 Prior: -769.4552\tRegularization: 0.0015\n",
      "Iter: 3300  \tTraining Loss: -681.5391    \n",
      "    Negative Log Likelihood: 89.0048\tSigma2 Prior: -770.5454\tRegularization: 0.0015\n",
      "Iter: 3310  \tTraining Loss: -680.4231    \n",
      "    Negative Log Likelihood: 91.1780\tSigma2 Prior: -771.6027\tRegularization: 0.0015\n",
      "Iter: 3320  \tTraining Loss: -679.6382    \n",
      "    Negative Log Likelihood: 90.1835\tSigma2 Prior: -769.8232\tRegularization: 0.0015\n",
      "Iter: 3330  \tTraining Loss: -680.9451    \n",
      "    Negative Log Likelihood: 90.0427\tSigma2 Prior: -770.9893\tRegularization: 0.0015\n",
      "Iter: 3340  \tTraining Loss: -678.1046    \n",
      "    Negative Log Likelihood: 85.2355\tSigma2 Prior: -763.3416\tRegularization: 0.0015\n",
      "Iter: 3350  \tTraining Loss: -678.7489    \n",
      "    Negative Log Likelihood: 92.6690\tSigma2 Prior: -771.4194\tRegularization: 0.0015\n",
      "Iter: 3360  \tTraining Loss: -681.3928    \n",
      "    Negative Log Likelihood: 87.8029\tSigma2 Prior: -769.1971\tRegularization: 0.0015\n",
      "Iter: 3370  \tTraining Loss: -674.4609    \n",
      "    Negative Log Likelihood: 95.1080\tSigma2 Prior: -769.5704\tRegularization: 0.0015\n",
      "Iter: 3380  \tTraining Loss: -677.9283    \n",
      "    Negative Log Likelihood: 86.1726\tSigma2 Prior: -764.1025\tRegularization: 0.0015\n",
      "Iter: 3390  \tTraining Loss: -677.3483    \n",
      "    Negative Log Likelihood: 89.2803\tSigma2 Prior: -766.6302\tRegularization: 0.0015\n",
      "Iter: 3400  \tTraining Loss: -679.2151    \n",
      "    Negative Log Likelihood: 89.3119\tSigma2 Prior: -768.5286\tRegularization: 0.0015\n",
      "Iter: 3410  \tTraining Loss: -677.2495    \n",
      "    Negative Log Likelihood: 91.7948\tSigma2 Prior: -769.0458\tRegularization: 0.0015\n",
      "Iter: 3420  \tTraining Loss: -677.9404    \n",
      "    Negative Log Likelihood: 86.4810\tSigma2 Prior: -764.4229\tRegularization: 0.0015\n",
      "Iter: 3430  \tTraining Loss: -678.5262    \n",
      "    Negative Log Likelihood: 89.4030\tSigma2 Prior: -767.9308\tRegularization: 0.0015\n",
      "Iter: 3440  \tTraining Loss: -677.8196    \n",
      "    Negative Log Likelihood: 90.4565\tSigma2 Prior: -768.2776\tRegularization: 0.0015\n",
      "Iter: 3450  \tTraining Loss: -677.2789    \n",
      "    Negative Log Likelihood: 80.9771\tSigma2 Prior: -758.2575\tRegularization: 0.0015\n",
      "Iter: 3460  \tTraining Loss: -676.9888    \n",
      "    Negative Log Likelihood: 89.5892\tSigma2 Prior: -766.5795\tRegularization: 0.0015\n",
      "Iter: 3470  \tTraining Loss: -676.7750    \n",
      "    Negative Log Likelihood: 87.6302\tSigma2 Prior: -764.4067\tRegularization: 0.0015\n",
      "Iter: 3480  \tTraining Loss: -677.0954    \n",
      "    Negative Log Likelihood: 87.4099\tSigma2 Prior: -764.5068\tRegularization: 0.0015\n",
      "Iter: 3490  \tTraining Loss: -676.2227    \n",
      "    Negative Log Likelihood: 89.5270\tSigma2 Prior: -765.7512\tRegularization: 0.0015\n",
      "Iter: 3500  \tTraining Loss: -676.8117    \n",
      "    Negative Log Likelihood: 87.4742\tSigma2 Prior: -764.2874\tRegularization: 0.0015\n",
      "Iter: 3510  \tTraining Loss: -678.3780    \n",
      "    Negative Log Likelihood: 88.3186\tSigma2 Prior: -766.6981\tRegularization: 0.0015\n",
      "Iter: 3520  \tTraining Loss: -677.1753    \n",
      "    Negative Log Likelihood: 87.9629\tSigma2 Prior: -765.1397\tRegularization: 0.0015\n",
      "Iter: 3530  \tTraining Loss: -677.4124    \n",
      "    Negative Log Likelihood: 87.5289\tSigma2 Prior: -764.9428\tRegularization: 0.0015\n",
      "Iter: 3540  \tTraining Loss: -678.0187    \n",
      "    Negative Log Likelihood: 87.6883\tSigma2 Prior: -765.7086\tRegularization: 0.0015\n",
      "Iter: 3550  \tTraining Loss: -678.7363    \n",
      "    Negative Log Likelihood: 86.8271\tSigma2 Prior: -765.5648\tRegularization: 0.0015\n",
      "Iter: 3560  \tTraining Loss: -679.3892    \n",
      "    Negative Log Likelihood: 87.4353\tSigma2 Prior: -766.8260\tRegularization: 0.0015\n",
      "Iter: 3570  \tTraining Loss: -678.7719    \n",
      "    Negative Log Likelihood: 86.6691\tSigma2 Prior: -765.4425\tRegularization: 0.0015\n",
      "Iter: 3580  \tTraining Loss: -678.6579    \n",
      "    Negative Log Likelihood: 85.6819\tSigma2 Prior: -764.3413\tRegularization: 0.0015\n",
      "Iter: 3590  \tTraining Loss: -679.2572    \n",
      "    Negative Log Likelihood: 89.3784\tSigma2 Prior: -768.6371\tRegularization: 0.0015\n",
      "Iter: 3600  \tTraining Loss: -679.2819    \n",
      "    Negative Log Likelihood: 87.6253\tSigma2 Prior: -766.9088\tRegularization: 0.0015\n",
      "Iter: 3610  \tTraining Loss: -680.3738    \n",
      "    Negative Log Likelihood: 87.5842\tSigma2 Prior: -767.9595\tRegularization: 0.0015\n",
      "Iter: 3620  \tTraining Loss: -681.0632    \n",
      "    Negative Log Likelihood: 86.1076\tSigma2 Prior: -767.1723\tRegularization: 0.0015\n",
      "Iter: 3630  \tTraining Loss: -678.7184    \n",
      "    Negative Log Likelihood: 87.8853\tSigma2 Prior: -766.6053\tRegularization: 0.0015\n",
      "Iter: 3640  \tTraining Loss: -677.0209    \n",
      "    Negative Log Likelihood: 83.0291\tSigma2 Prior: -760.0516\tRegularization: 0.0015\n",
      "Iter: 3650  \tTraining Loss: -678.6005    \n",
      "    Negative Log Likelihood: 90.1044\tSigma2 Prior: -768.7065\tRegularization: 0.0015\n",
      "Iter: 3660  \tTraining Loss: -677.4404    \n",
      "    Negative Log Likelihood: 91.8064\tSigma2 Prior: -769.2483\tRegularization: 0.0015\n",
      "Iter: 3670  \tTraining Loss: -680.0503    \n",
      "    Negative Log Likelihood: 87.6267\tSigma2 Prior: -767.6785\tRegularization: 0.0015\n",
      "Iter: 3680  \tTraining Loss: -678.7892    \n",
      "    Negative Log Likelihood: 89.3603\tSigma2 Prior: -768.1511\tRegularization: 0.0015\n",
      "Iter: 3690  \tTraining Loss: -678.5089    \n",
      "    Negative Log Likelihood: 89.6458\tSigma2 Prior: -768.1562\tRegularization: 0.0015\n",
      "Iter: 3700  \tTraining Loss: -679.7012    \n",
      "    Negative Log Likelihood: 89.1029\tSigma2 Prior: -768.8057\tRegularization: 0.0015\n",
      "Iter: 3710  \tTraining Loss: -679.7421    \n",
      "    Negative Log Likelihood: 87.2761\tSigma2 Prior: -767.0197\tRegularization: 0.0015\n",
      "Iter: 3720  \tTraining Loss: -679.9582    \n",
      "    Negative Log Likelihood: 88.6544\tSigma2 Prior: -768.6141\tRegularization: 0.0015\n",
      "Iter: 3730  \tTraining Loss: -679.1994    \n",
      "    Negative Log Likelihood: 89.9427\tSigma2 Prior: -769.1437\tRegularization: 0.0015\n",
      "Iter: 3740  \tTraining Loss: -680.0181    \n",
      "    Negative Log Likelihood: 87.2554\tSigma2 Prior: -767.2750\tRegularization: 0.0015\n",
      "Iter: 3750  \tTraining Loss: -680.1394    \n",
      "    Negative Log Likelihood: 88.1218\tSigma2 Prior: -768.2627\tRegularization: 0.0015\n",
      "Iter: 3760  \tTraining Loss: -679.5003    \n",
      "    Negative Log Likelihood: 89.4832\tSigma2 Prior: -768.9850\tRegularization: 0.0015\n",
      "Iter: 3770  \tTraining Loss: -679.7609    \n",
      "    Negative Log Likelihood: 88.0769\tSigma2 Prior: -767.8393\tRegularization: 0.0015\n",
      "Iter: 3780  \tTraining Loss: -679.9472    \n",
      "    Negative Log Likelihood: 88.7343\tSigma2 Prior: -768.6830\tRegularization: 0.0015\n",
      "Iter: 3790  \tTraining Loss: -679.5956    \n",
      "    Negative Log Likelihood: 89.5178\tSigma2 Prior: -769.1149\tRegularization: 0.0015\n",
      "Iter: 3800  \tTraining Loss: -681.6102    \n",
      "    Negative Log Likelihood: 86.2347\tSigma2 Prior: -767.8464\tRegularization: 0.0015\n",
      "Iter: 3810  \tTraining Loss: -679.6086    \n",
      "    Negative Log Likelihood: 90.1960\tSigma2 Prior: -769.8062\tRegularization: 0.0015\n",
      "Iter: 3820  \tTraining Loss: -682.1748    \n",
      "    Negative Log Likelihood: 87.6066\tSigma2 Prior: -769.7829\tRegularization: 0.0015\n",
      "Iter: 3830  \tTraining Loss: -676.3722    \n",
      "    Negative Log Likelihood: 89.7789\tSigma2 Prior: -766.1526\tRegularization: 0.0015\n",
      "Iter: 3840  \tTraining Loss: -680.9395    \n",
      "    Negative Log Likelihood: 86.3537\tSigma2 Prior: -767.2947\tRegularization: 0.0015\n",
      "Iter: 3850  \tTraining Loss: -681.7795    \n",
      "    Negative Log Likelihood: 85.9532\tSigma2 Prior: -767.7343\tRegularization: 0.0015\n",
      "Iter: 3860  \tTraining Loss: -680.7393    \n",
      "    Negative Log Likelihood: 85.4382\tSigma2 Prior: -766.1790\tRegularization: 0.0015\n",
      "Iter: 3870  \tTraining Loss: -678.6865    \n",
      "    Negative Log Likelihood: 81.4277\tSigma2 Prior: -760.1157\tRegularization: 0.0015\n",
      "Iter: 3880  \tTraining Loss: -678.5466    \n",
      "    Negative Log Likelihood: 85.7101\tSigma2 Prior: -764.2582\tRegularization: 0.0015\n",
      "Iter: 3890  \tTraining Loss: -674.4781    \n",
      "    Negative Log Likelihood: 98.9500\tSigma2 Prior: -773.4297\tRegularization: 0.0015\n",
      "Iter: 3900  \tTraining Loss: -677.2195    \n",
      "    Negative Log Likelihood: 87.4520\tSigma2 Prior: -764.6730\tRegularization: 0.0015\n",
      "Iter: 3910  \tTraining Loss: -677.7972    \n",
      "    Negative Log Likelihood: 88.0750\tSigma2 Prior: -765.8737\tRegularization: 0.0015\n",
      "Iter: 3920  \tTraining Loss: -679.1239    \n",
      "    Negative Log Likelihood: 89.5053\tSigma2 Prior: -768.6307\tRegularization: 0.0015\n",
      "Iter: 3930  \tTraining Loss: -679.1096    \n",
      "    Negative Log Likelihood: 86.6981\tSigma2 Prior: -765.8092\tRegularization: 0.0015\n",
      "Iter: 3940  \tTraining Loss: -678.8173    \n",
      "    Negative Log Likelihood: 88.5562\tSigma2 Prior: -767.3751\tRegularization: 0.0016\n",
      "Iter: 3950  \tTraining Loss: -679.4459    \n",
      "    Negative Log Likelihood: 88.5010\tSigma2 Prior: -767.9485\tRegularization: 0.0016\n",
      "Iter: 3960  \tTraining Loss: -680.3115    \n",
      "    Negative Log Likelihood: 87.7893\tSigma2 Prior: -768.1023\tRegularization: 0.0016\n",
      "Iter: 3970  \tTraining Loss: -680.0873    \n",
      "    Negative Log Likelihood: 89.4799\tSigma2 Prior: -769.5687\tRegularization: 0.0016\n",
      "Iter: 3980  \tTraining Loss: -679.9423    \n",
      "    Negative Log Likelihood: 87.9909\tSigma2 Prior: -767.9347\tRegularization: 0.0016\n",
      "Iter: 3990  \tTraining Loss: -681.0301    \n",
      "    Negative Log Likelihood: 87.1614\tSigma2 Prior: -768.1930\tRegularization: 0.0016\n",
      "Iter: 4000  \tTraining Loss: -681.4046    \n",
      "    Negative Log Likelihood: 88.6556\tSigma2 Prior: -770.0617\tRegularization: 0.0016\n",
      "Iter: 4010  \tTraining Loss: -682.4781    \n",
      "    Negative Log Likelihood: 87.8176\tSigma2 Prior: -770.2972\tRegularization: 0.0016\n",
      "Iter: 4020  \tTraining Loss: -680.7637    \n",
      "    Negative Log Likelihood: 88.7117\tSigma2 Prior: -769.4769\tRegularization: 0.0016\n",
      "Iter: 4030  \tTraining Loss: -680.8191    \n",
      "    Negative Log Likelihood: 80.0173\tSigma2 Prior: -760.8380\tRegularization: 0.0016\n",
      "Iter: 4040  \tTraining Loss: -679.9108    \n",
      "    Negative Log Likelihood: 85.1989\tSigma2 Prior: -765.1113\tRegularization: 0.0016\n",
      "Iter: 4050  \tTraining Loss: -677.4294    \n",
      "    Negative Log Likelihood: 87.6281\tSigma2 Prior: -765.0591\tRegularization: 0.0016\n",
      "Iter: 4060  \tTraining Loss: -672.9591    \n",
      "    Negative Log Likelihood: 84.6680\tSigma2 Prior: -757.6287\tRegularization: 0.0016\n",
      "Iter: 4070  \tTraining Loss: -676.2537    \n",
      "    Negative Log Likelihood: 85.2716\tSigma2 Prior: -761.5268\tRegularization: 0.0016\n",
      "Iter: 4080  \tTraining Loss: -676.2211    \n",
      "    Negative Log Likelihood: 86.3156\tSigma2 Prior: -762.5382\tRegularization: 0.0016\n",
      "Iter: 4090  \tTraining Loss: -677.4792    \n",
      "    Negative Log Likelihood: 84.3508\tSigma2 Prior: -761.8315\tRegularization: 0.0016\n",
      "Iter: 4100  \tTraining Loss: -676.6170    \n",
      "    Negative Log Likelihood: 84.6960\tSigma2 Prior: -761.3146\tRegularization: 0.0016\n",
      "Iter: 4110  \tTraining Loss: -262.8153    \n",
      "    Negative Log Likelihood: 482.1921\tSigma2 Prior: -745.0090\tRegularization: 0.0016\n",
      "Iter: 4120  \tTraining Loss: -673.9033    \n",
      "    Negative Log Likelihood: 86.6922\tSigma2 Prior: -760.5970\tRegularization: 0.0016\n",
      "Iter: 4130  \tTraining Loss: -674.4024    \n",
      "    Negative Log Likelihood: 86.9359\tSigma2 Prior: -761.3399\tRegularization: 0.0016\n",
      "Iter: 4140  \tTraining Loss: -674.6342    \n",
      "    Negative Log Likelihood: 83.5594\tSigma2 Prior: -758.1952\tRegularization: 0.0016\n",
      "Iter: 4150  \tTraining Loss: -675.7293    \n",
      "    Negative Log Likelihood: 84.5735\tSigma2 Prior: -760.3044\tRegularization: 0.0016\n",
      "Iter: 4160  \tTraining Loss: -677.2626    \n",
      "    Negative Log Likelihood: 84.7845\tSigma2 Prior: -762.0486\tRegularization: 0.0016\n",
      "Iter: 4170  \tTraining Loss: -675.1117    \n",
      "    Negative Log Likelihood: 87.0390\tSigma2 Prior: -762.1523\tRegularization: 0.0016\n",
      "Iter: 4180  \tTraining Loss: -676.8588    \n",
      "    Negative Log Likelihood: 85.8680\tSigma2 Prior: -762.7284\tRegularization: 0.0016\n",
      "Iter: 4190  \tTraining Loss: -676.4138    \n",
      "    Negative Log Likelihood: 83.4934\tSigma2 Prior: -759.9088\tRegularization: 0.0016\n",
      "Iter: 4200  \tTraining Loss: -674.3766    \n",
      "    Negative Log Likelihood: 82.2183\tSigma2 Prior: -756.5965\tRegularization: 0.0016\n",
      "Iter: 4210  \tTraining Loss: -668.0251    \n",
      "    Negative Log Likelihood: 72.2087\tSigma2 Prior: -740.2354\tRegularization: 0.0016\n",
      "Iter: 4220  \tTraining Loss: -669.0015    \n",
      "    Negative Log Likelihood: 83.7238\tSigma2 Prior: -752.7269\tRegularization: 0.0016\n",
      "Iter: 4230  \tTraining Loss: -668.0543    \n",
      "    Negative Log Likelihood: 83.6812\tSigma2 Prior: -751.7370\tRegularization: 0.0016\n",
      "Iter: 4240  \tTraining Loss: -671.5505    \n",
      "    Negative Log Likelihood: 83.4621\tSigma2 Prior: -755.0143\tRegularization: 0.0016\n",
      "Iter: 4250  \tTraining Loss: -669.0504    \n",
      "    Negative Log Likelihood: 83.1657\tSigma2 Prior: -752.2177\tRegularization: 0.0016\n",
      "Iter: 4260  \tTraining Loss: -671.1480    \n",
      "    Negative Log Likelihood: 80.8091\tSigma2 Prior: -751.9587\tRegularization: 0.0016\n",
      "Iter: 4270  \tTraining Loss: -671.3255    \n",
      "    Negative Log Likelihood: 81.8252\tSigma2 Prior: -753.1523\tRegularization: 0.0016\n",
      "Iter: 4280  \tTraining Loss: -670.4912    \n",
      "    Negative Log Likelihood: 83.0547\tSigma2 Prior: -753.5475\tRegularization: 0.0016\n",
      "Iter: 4290  \tTraining Loss: -668.8167    \n",
      "    Negative Log Likelihood: 83.9988\tSigma2 Prior: -752.8170\tRegularization: 0.0016\n",
      "Iter: 4300  \tTraining Loss: -672.7271    \n",
      "    Negative Log Likelihood: 81.1747\tSigma2 Prior: -753.9033\tRegularization: 0.0016\n",
      "Iter: 4310  \tTraining Loss: -672.6290    \n",
      "    Negative Log Likelihood: 82.8914\tSigma2 Prior: -755.5220\tRegularization: 0.0016\n",
      "Iter: 4320  \tTraining Loss: -673.9215    \n",
      "    Negative Log Likelihood: 84.4245\tSigma2 Prior: -758.3476\tRegularization: 0.0016\n",
      "Iter: 4330  \tTraining Loss: -674.2527    \n",
      "    Negative Log Likelihood: 86.0646\tSigma2 Prior: -760.3188\tRegularization: 0.0016\n",
      "Iter: 4340  \tTraining Loss: -675.6095    \n",
      "    Negative Log Likelihood: 83.7810\tSigma2 Prior: -759.3922\tRegularization: 0.0016\n",
      "Iter: 4350  \tTraining Loss: -675.0175    \n",
      "    Negative Log Likelihood: 81.6067\tSigma2 Prior: -756.6258\tRegularization: 0.0016\n",
      "Iter: 4360  \tTraining Loss: -674.6623    \n",
      "    Negative Log Likelihood: 80.4855\tSigma2 Prior: -755.1494\tRegularization: 0.0016\n",
      "Iter: 4370  \tTraining Loss: -674.0617    \n",
      "    Negative Log Likelihood: 85.9387\tSigma2 Prior: -760.0020\tRegularization: 0.0016\n",
      "Iter: 4380  \tTraining Loss: -673.6250    \n",
      "    Negative Log Likelihood: 85.0485\tSigma2 Prior: -758.6750\tRegularization: 0.0016\n",
      "Iter: 4390  \tTraining Loss: -672.9326    \n",
      "    Negative Log Likelihood: 87.3909\tSigma2 Prior: -760.3251\tRegularization: 0.0016\n",
      "Iter: 4400  \tTraining Loss: -675.1948    \n",
      "    Negative Log Likelihood: 84.9331\tSigma2 Prior: -760.1296\tRegularization: 0.0016\n",
      "Iter: 4410  \tTraining Loss: -676.0578    \n",
      "    Negative Log Likelihood: 85.7859\tSigma2 Prior: -761.8453\tRegularization: 0.0016\n",
      "Iter: 4420  \tTraining Loss: -676.5154    \n",
      "    Negative Log Likelihood: 85.5321\tSigma2 Prior: -762.0492\tRegularization: 0.0016\n",
      "Iter: 4430  \tTraining Loss: -676.3254    \n",
      "    Negative Log Likelihood: 83.1916\tSigma2 Prior: -759.5186\tRegularization: 0.0016\n",
      "Iter: 4440  \tTraining Loss: -676.7048    \n",
      "    Negative Log Likelihood: 85.3168\tSigma2 Prior: -762.0233\tRegularization: 0.0016\n",
      "Iter: 4450  \tTraining Loss: -677.4370    \n",
      "    Negative Log Likelihood: 86.8613\tSigma2 Prior: -764.2998\tRegularization: 0.0016\n",
      "Iter: 4460  \tTraining Loss: -678.2617    \n",
      "    Negative Log Likelihood: 85.7161\tSigma2 Prior: -763.9794\tRegularization: 0.0016\n",
      "Iter: 4470  \tTraining Loss: -677.6115    \n",
      "    Negative Log Likelihood: 86.7236\tSigma2 Prior: -764.3367\tRegularization: 0.0016\n",
      "Iter: 4480  \tTraining Loss: -678.3230    \n",
      "    Negative Log Likelihood: 86.6404\tSigma2 Prior: -764.9650\tRegularization: 0.0016\n",
      "Iter: 4490  \tTraining Loss: -679.4853    \n",
      "    Negative Log Likelihood: 83.8963\tSigma2 Prior: -763.3831\tRegularization: 0.0016\n",
      "Iter: 4500  \tTraining Loss: -674.3530    \n",
      "    Negative Log Likelihood: 84.2703\tSigma2 Prior: -758.6248\tRegularization: 0.0016\n",
      "Iter: 4510  \tTraining Loss: -676.4979    \n",
      "    Negative Log Likelihood: 87.1605\tSigma2 Prior: -763.6600\tRegularization: 0.0016\n",
      "Iter: 4520  \tTraining Loss: -677.6745    \n",
      "    Negative Log Likelihood: 85.3238\tSigma2 Prior: -762.9998\tRegularization: 0.0016\n",
      "Iter: 4530  \tTraining Loss: -678.3073    \n",
      "    Negative Log Likelihood: 85.3471\tSigma2 Prior: -763.6560\tRegularization: 0.0016\n",
      "Iter: 4540  \tTraining Loss: -676.4959    \n",
      "    Negative Log Likelihood: 90.1101\tSigma2 Prior: -766.6075\tRegularization: 0.0016\n",
      "Iter: 4550  \tTraining Loss: -678.8699    \n",
      "    Negative Log Likelihood: 86.9175\tSigma2 Prior: -765.7889\tRegularization: 0.0016\n",
      "Iter: 4560  \tTraining Loss: -679.0134    \n",
      "    Negative Log Likelihood: 85.6206\tSigma2 Prior: -764.6356\tRegularization: 0.0016\n",
      "Iter: 4570  \tTraining Loss: -679.2516    \n",
      "    Negative Log Likelihood: 83.6996\tSigma2 Prior: -762.9529\tRegularization: 0.0016\n",
      "Iter: 4580  \tTraining Loss: -676.4553    \n",
      "    Negative Log Likelihood: 88.8987\tSigma2 Prior: -765.3557\tRegularization: 0.0016\n",
      "Iter: 4590  \tTraining Loss: -677.4744    \n",
      "    Negative Log Likelihood: 85.4088\tSigma2 Prior: -762.8848\tRegularization: 0.0016\n",
      "Iter: 4600  \tTraining Loss: -677.5925    \n",
      "    Negative Log Likelihood: 84.7804\tSigma2 Prior: -762.3745\tRegularization: 0.0016\n",
      "Iter: 4610  \tTraining Loss: -679.8242    \n",
      "    Negative Log Likelihood: 83.9534\tSigma2 Prior: -763.7792\tRegularization: 0.0016\n",
      "Iter: 4620  \tTraining Loss: -678.7093    \n",
      "    Negative Log Likelihood: 87.3460\tSigma2 Prior: -766.0569\tRegularization: 0.0016\n",
      "Iter: 4630  \tTraining Loss: -679.0021    \n",
      "    Negative Log Likelihood: 87.3528\tSigma2 Prior: -766.3566\tRegularization: 0.0016\n",
      "Iter: 4640  \tTraining Loss: -678.6800    \n",
      "    Negative Log Likelihood: 87.8587\tSigma2 Prior: -766.5403\tRegularization: 0.0016\n",
      "Iter: 4650  \tTraining Loss: -679.7795    \n",
      "    Negative Log Likelihood: 88.4459\tSigma2 Prior: -768.2270\tRegularization: 0.0016\n",
      "Iter: 4660  \tTraining Loss: -679.5906    \n",
      "    Negative Log Likelihood: 89.9636\tSigma2 Prior: -769.5558\tRegularization: 0.0016\n",
      "Iter: 4670  \tTraining Loss: -680.4864    \n",
      "    Negative Log Likelihood: 89.0350\tSigma2 Prior: -769.5229\tRegularization: 0.0016\n",
      "Iter: 4680  \tTraining Loss: -682.3995    \n",
      "    Negative Log Likelihood: 88.4863\tSigma2 Prior: -770.8873\tRegularization: 0.0016\n",
      "Iter: 4690  \tTraining Loss: -682.6443    \n",
      "    Negative Log Likelihood: 86.9183\tSigma2 Prior: -769.5642\tRegularization: 0.0016\n",
      "Iter: 4700  \tTraining Loss: -682.3484    \n",
      "    Negative Log Likelihood: 88.6293\tSigma2 Prior: -770.9793\tRegularization: 0.0016\n",
      "Iter: 4710  \tTraining Loss: -683.1827    \n",
      "    Negative Log Likelihood: 88.2271\tSigma2 Prior: -771.4113\tRegularization: 0.0016\n",
      "Iter: 4720  \tTraining Loss: -682.6183    \n",
      "    Negative Log Likelihood: 87.0820\tSigma2 Prior: -769.7019\tRegularization: 0.0016\n",
      "Iter: 4730  \tTraining Loss: -683.1525    \n",
      "    Negative Log Likelihood: 87.2691\tSigma2 Prior: -770.4232\tRegularization: 0.0016\n",
      "Iter: 4740  \tTraining Loss: -682.8166    \n",
      "    Negative Log Likelihood: 89.4176\tSigma2 Prior: -772.2358\tRegularization: 0.0016\n",
      "Iter: 4750  \tTraining Loss: -683.7603    \n",
      "    Negative Log Likelihood: 87.3752\tSigma2 Prior: -771.1371\tRegularization: 0.0016\n",
      "Iter: 4760  \tTraining Loss: -684.3463    \n",
      "    Negative Log Likelihood: 88.0814\tSigma2 Prior: -772.4293\tRegularization: 0.0016\n",
      "Iter: 4770  \tTraining Loss: -681.6008    \n",
      "    Negative Log Likelihood: 92.6786\tSigma2 Prior: -774.2810\tRegularization: 0.0016\n",
      "Iter: 4780  \tTraining Loss: -680.1383    \n",
      "    Negative Log Likelihood: 89.9381\tSigma2 Prior: -770.0780\tRegularization: 0.0016\n",
      "Iter: 4790  \tTraining Loss: -679.6992    \n",
      "    Negative Log Likelihood: 90.6901\tSigma2 Prior: -770.3909\tRegularization: 0.0016\n",
      "Iter: 4800  \tTraining Loss: -679.5385    \n",
      "    Negative Log Likelihood: 93.6075\tSigma2 Prior: -773.1476\tRegularization: 0.0016\n",
      "Iter: 4810  \tTraining Loss: -681.1141    \n",
      "    Negative Log Likelihood: 88.9375\tSigma2 Prior: -770.0532\tRegularization: 0.0016\n",
      "Iter: 4820  \tTraining Loss: -681.0641    \n",
      "    Negative Log Likelihood: 91.7580\tSigma2 Prior: -772.8237\tRegularization: 0.0016\n",
      "Iter: 4830  \tTraining Loss: -681.4314    \n",
      "    Negative Log Likelihood: 91.6136\tSigma2 Prior: -773.0466\tRegularization: 0.0016\n",
      "Iter: 4840  \tTraining Loss: -682.3081    \n",
      "    Negative Log Likelihood: 91.0525\tSigma2 Prior: -773.3621\tRegularization: 0.0016\n",
      "Iter: 4850  \tTraining Loss: -683.3154    \n",
      "    Negative Log Likelihood: 88.2018\tSigma2 Prior: -771.5188\tRegularization: 0.0016\n",
      "Iter: 4860  \tTraining Loss: -683.8584    \n",
      "    Negative Log Likelihood: 88.8221\tSigma2 Prior: -772.6821\tRegularization: 0.0016\n",
      "Iter: 4870  \tTraining Loss: -683.7354    \n",
      "    Negative Log Likelihood: 88.6004\tSigma2 Prior: -772.3373\tRegularization: 0.0016\n",
      "Iter: 4880  \tTraining Loss: -684.0468    \n",
      "    Negative Log Likelihood: 85.4728\tSigma2 Prior: -769.5212\tRegularization: 0.0016\n",
      "Iter: 4890  \tTraining Loss: -683.4543    \n",
      "    Negative Log Likelihood: 90.0427\tSigma2 Prior: -773.4986\tRegularization: 0.0016\n",
      "Iter: 4900  \tTraining Loss: -684.3804    \n",
      "    Negative Log Likelihood: 90.3327\tSigma2 Prior: -774.7147\tRegularization: 0.0016\n",
      "Iter: 4910  \tTraining Loss: -683.3125    \n",
      "    Negative Log Likelihood: 88.3967\tSigma2 Prior: -771.7109\tRegularization: 0.0016\n",
      "Iter: 4920  \tTraining Loss: -684.8434    \n",
      "    Negative Log Likelihood: 88.6244\tSigma2 Prior: -773.4695\tRegularization: 0.0016\n",
      "Iter: 4930  \tTraining Loss: -679.1668    \n",
      "    Negative Log Likelihood: 92.5713\tSigma2 Prior: -771.7397\tRegularization: 0.0016\n",
      "Iter: 4940  \tTraining Loss: -683.2195    \n",
      "    Negative Log Likelihood: 90.5022\tSigma2 Prior: -773.7234\tRegularization: 0.0016\n",
      "Iter: 4950  \tTraining Loss: -685.1256    \n",
      "    Negative Log Likelihood: 87.5554\tSigma2 Prior: -772.6826\tRegularization: 0.0016\n",
      "Iter: 4960  \tTraining Loss: -682.4102    \n",
      "    Negative Log Likelihood: 87.4482\tSigma2 Prior: -769.8600\tRegularization: 0.0016\n",
      "Iter: 4970  \tTraining Loss: -683.9805    \n",
      "    Negative Log Likelihood: 87.7892\tSigma2 Prior: -771.7714\tRegularization: 0.0016\n",
      "Iter: 4980  \tTraining Loss: -684.6549    \n",
      "    Negative Log Likelihood: 85.8778\tSigma2 Prior: -770.5343\tRegularization: 0.0016\n",
      "Iter: 4990  \tTraining Loss: -684.7408    \n",
      "    Negative Log Likelihood: 87.1135\tSigma2 Prior: -771.8560\tRegularization: 0.0016\n",
      "Iter: 5000  \tTraining Loss: -682.4768    \n",
      "    Negative Log Likelihood: 85.6667\tSigma2 Prior: -768.1451\tRegularization: 0.0016\n",
      "Iter: 5010  \tTraining Loss: -681.2377    \n",
      "    Negative Log Likelihood: 86.3298\tSigma2 Prior: -767.5692\tRegularization: 0.0016\n",
      "Iter: 5020  \tTraining Loss: -680.4034    \n",
      "    Negative Log Likelihood: 89.0229\tSigma2 Prior: -769.4279\tRegularization: 0.0016\n",
      "Iter: 5030  \tTraining Loss: -676.2422    \n",
      "    Negative Log Likelihood: 90.2954\tSigma2 Prior: -766.5392\tRegularization: 0.0016\n",
      "Iter: 5040  \tTraining Loss: -680.4319    \n",
      "    Negative Log Likelihood: 83.1748\tSigma2 Prior: -763.6083\tRegularization: 0.0016\n",
      "Iter: 5050  \tTraining Loss: -680.1342    \n",
      "    Negative Log Likelihood: 91.5160\tSigma2 Prior: -771.6519\tRegularization: 0.0016\n",
      "Iter: 5060  \tTraining Loss: -682.4333    \n",
      "    Negative Log Likelihood: 86.7878\tSigma2 Prior: -769.2227\tRegularization: 0.0016\n",
      "Iter: 5070  \tTraining Loss: -682.7213    \n",
      "    Negative Log Likelihood: 88.5804\tSigma2 Prior: -771.3033\tRegularization: 0.0016\n",
      "Iter: 5080  \tTraining Loss: -684.3019    \n",
      "    Negative Log Likelihood: 87.4870\tSigma2 Prior: -771.7905\tRegularization: 0.0016\n",
      "Iter: 5090  \tTraining Loss: -684.5295    \n",
      "    Negative Log Likelihood: 88.4169\tSigma2 Prior: -772.9481\tRegularization: 0.0016\n",
      "Iter: 5100  \tTraining Loss: -685.0974    \n",
      "    Negative Log Likelihood: 88.1658\tSigma2 Prior: -773.2648\tRegularization: 0.0016\n",
      "Iter: 5110  \tTraining Loss: -685.7930    \n",
      "    Negative Log Likelihood: 87.5505\tSigma2 Prior: -773.3452\tRegularization: 0.0016\n",
      "Iter: 5120  \tTraining Loss: -685.6720    \n",
      "    Negative Log Likelihood: 88.8275\tSigma2 Prior: -774.5012\tRegularization: 0.0016\n",
      "Iter: 5130  \tTraining Loss: -685.7689    \n",
      "    Negative Log Likelihood: 89.6737\tSigma2 Prior: -775.4442\tRegularization: 0.0016\n",
      "Iter: 5140  \tTraining Loss: -686.6123    \n",
      "    Negative Log Likelihood: 88.9902\tSigma2 Prior: -775.6041\tRegularization: 0.0016\n",
      "Iter: 5150  \tTraining Loss: -686.6317    \n",
      "    Negative Log Likelihood: 90.4840\tSigma2 Prior: -777.1173\tRegularization: 0.0016\n",
      "Iter: 5160  \tTraining Loss: -687.5638    \n",
      "    Negative Log Likelihood: 88.8635\tSigma2 Prior: -776.4289\tRegularization: 0.0016\n",
      "Iter: 5170  \tTraining Loss: -688.0518    \n",
      "    Negative Log Likelihood: 89.9221\tSigma2 Prior: -777.9755\tRegularization: 0.0016\n",
      "Iter: 5180  \tTraining Loss: -688.4424    \n",
      "    Negative Log Likelihood: 89.0159\tSigma2 Prior: -777.4600\tRegularization: 0.0016\n",
      "Iter: 5190  \tTraining Loss: -688.5915    \n",
      "    Negative Log Likelihood: 88.8982\tSigma2 Prior: -777.4914\tRegularization: 0.0016\n",
      "Iter: 5200  \tTraining Loss: -689.7768    \n",
      "    Negative Log Likelihood: 89.5826\tSigma2 Prior: -779.3610\tRegularization: 0.0016\n",
      "Iter: 5210  \tTraining Loss: -690.9549    \n",
      "    Negative Log Likelihood: 89.7640\tSigma2 Prior: -780.7206\tRegularization: 0.0016\n",
      "Iter: 5220  \tTraining Loss: -686.6075    \n",
      "    Negative Log Likelihood: 90.6703\tSigma2 Prior: -777.2795\tRegularization: 0.0016\n",
      "Iter: 5230  \tTraining Loss: -684.8453    \n",
      "    Negative Log Likelihood: 96.4292\tSigma2 Prior: -781.2761\tRegularization: 0.0016\n",
      "Iter: 5240  \tTraining Loss: -688.8537    \n",
      "    Negative Log Likelihood: 88.6728\tSigma2 Prior: -777.5281\tRegularization: 0.0016\n",
      "Iter: 5250  \tTraining Loss: -689.2018    \n",
      "    Negative Log Likelihood: 88.8495\tSigma2 Prior: -778.0529\tRegularization: 0.0016\n",
      "Iter: 5260  \tTraining Loss: -687.9563    \n",
      "    Negative Log Likelihood: 93.2690\tSigma2 Prior: -781.2269\tRegularization: 0.0016\n",
      "Iter: 5270  \tTraining Loss: -687.6073    \n",
      "    Negative Log Likelihood: 92.4096\tSigma2 Prior: -780.0185\tRegularization: 0.0016\n",
      "Iter: 5280  \tTraining Loss: -688.7908    \n",
      "    Negative Log Likelihood: 90.7393\tSigma2 Prior: -779.5317\tRegularization: 0.0016\n",
      "Iter: 5290  \tTraining Loss: -688.5840    \n",
      "    Negative Log Likelihood: 93.6753\tSigma2 Prior: -782.2609\tRegularization: 0.0016\n",
      "Iter: 5300  \tTraining Loss: -689.3992    \n",
      "    Negative Log Likelihood: 90.2092\tSigma2 Prior: -779.6100\tRegularization: 0.0016\n",
      "Iter: 5310  \tTraining Loss: -689.6442    \n",
      "    Negative Log Likelihood: 89.8588\tSigma2 Prior: -779.5046\tRegularization: 0.0016\n",
      "Iter: 5320  \tTraining Loss: -689.4509    \n",
      "    Negative Log Likelihood: 90.5292\tSigma2 Prior: -779.9818\tRegularization: 0.0016\n",
      "Iter: 5330  \tTraining Loss: -689.0152    \n",
      "    Negative Log Likelihood: 92.3024\tSigma2 Prior: -781.3193\tRegularization: 0.0016\n",
      "Iter: 5340  \tTraining Loss: -690.8248    \n",
      "    Negative Log Likelihood: 87.6066\tSigma2 Prior: -778.4331\tRegularization: 0.0016\n",
      "Iter: 5350  \tTraining Loss: -690.9993    \n",
      "    Negative Log Likelihood: 85.9130\tSigma2 Prior: -776.9139\tRegularization: 0.0016\n",
      "Iter: 5360  \tTraining Loss: -688.4405    \n",
      "    Negative Log Likelihood: 89.5560\tSigma2 Prior: -777.9981\tRegularization: 0.0016\n",
      "Iter: 5370  \tTraining Loss: -685.9431    \n",
      "    Negative Log Likelihood: 95.8322\tSigma2 Prior: -781.7769\tRegularization: 0.0016\n",
      "Iter: 5380  \tTraining Loss: -688.0100    \n",
      "    Negative Log Likelihood: 90.1694\tSigma2 Prior: -778.1810\tRegularization: 0.0016\n",
      "Iter: 5390  \tTraining Loss: -688.8715    \n",
      "    Negative Log Likelihood: 90.0180\tSigma2 Prior: -778.8911\tRegularization: 0.0016\n",
      "Iter: 5400  \tTraining Loss: -690.1946    \n",
      "    Negative Log Likelihood: 89.0272\tSigma2 Prior: -779.2234\tRegularization: 0.0016\n",
      "Iter: 5410  \tTraining Loss: -688.7797    \n",
      "    Negative Log Likelihood: 90.0899\tSigma2 Prior: -778.8713\tRegularization: 0.0016\n",
      "Iter: 5420  \tTraining Loss: -688.2690    \n",
      "    Negative Log Likelihood: 94.1674\tSigma2 Prior: -782.4380\tRegularization: 0.0016\n",
      "Iter: 5430  \tTraining Loss: -690.4374    \n",
      "    Negative Log Likelihood: 89.7266\tSigma2 Prior: -780.1657\tRegularization: 0.0017\n",
      "Iter: 5440  \tTraining Loss: -690.4850    \n",
      "    Negative Log Likelihood: 89.7274\tSigma2 Prior: -780.2141\tRegularization: 0.0017\n",
      "Iter: 5450  \tTraining Loss: -688.8392    \n",
      "    Negative Log Likelihood: 94.8091\tSigma2 Prior: -783.6500\tRegularization: 0.0017\n",
      "Iter: 5460  \tTraining Loss: -690.7906    \n",
      "    Negative Log Likelihood: 88.3949\tSigma2 Prior: -779.1871\tRegularization: 0.0017\n",
      "Iter: 5470  \tTraining Loss: -688.3657    \n",
      "    Negative Log Likelihood: 93.5719\tSigma2 Prior: -781.9392\tRegularization: 0.0017\n",
      "Iter: 5480  \tTraining Loss: -691.8402    \n",
      "    Negative Log Likelihood: 87.1224\tSigma2 Prior: -778.9643\tRegularization: 0.0017\n",
      "Iter: 5490  \tTraining Loss: -691.6484    \n",
      "    Negative Log Likelihood: 90.1149\tSigma2 Prior: -781.7650\tRegularization: 0.0017\n",
      "Iter: 5500  \tTraining Loss: -686.0358    \n",
      "    Negative Log Likelihood: 87.5542\tSigma2 Prior: -773.5916\tRegularization: 0.0017\n",
      "Iter: 5510  \tTraining Loss: -687.8489    \n",
      "    Negative Log Likelihood: 86.7714\tSigma2 Prior: -774.6219\tRegularization: 0.0017\n",
      "Iter: 5520  \tTraining Loss: -687.7338    \n",
      "    Negative Log Likelihood: 93.0950\tSigma2 Prior: -780.8304\tRegularization: 0.0017\n",
      "Iter: 5530  \tTraining Loss: -688.5240    \n",
      "    Negative Log Likelihood: 93.6448\tSigma2 Prior: -782.1705\tRegularization: 0.0017\n",
      "Iter: 5540  \tTraining Loss: -689.4762    \n",
      "    Negative Log Likelihood: 90.4836\tSigma2 Prior: -779.9614\tRegularization: 0.0017\n",
      "Iter: 5550  \tTraining Loss: -690.6530    \n",
      "    Negative Log Likelihood: 89.5975\tSigma2 Prior: -780.2522\tRegularization: 0.0017\n",
      "Iter: 5560  \tTraining Loss: -690.8708    \n",
      "    Negative Log Likelihood: 90.7904\tSigma2 Prior: -781.6629\tRegularization: 0.0017\n",
      "Iter: 5570  \tTraining Loss: -690.1006    \n",
      "    Negative Log Likelihood: 91.5953\tSigma2 Prior: -781.6976\tRegularization: 0.0017\n",
      "Iter: 5580  \tTraining Loss: -690.4211    \n",
      "    Negative Log Likelihood: 90.4505\tSigma2 Prior: -780.8732\tRegularization: 0.0017\n",
      "Iter: 5590  \tTraining Loss: -690.5381    \n",
      "    Negative Log Likelihood: 90.3504\tSigma2 Prior: -780.8901\tRegularization: 0.0017\n",
      "Iter: 5600  \tTraining Loss: -691.0586    \n",
      "    Negative Log Likelihood: 92.5575\tSigma2 Prior: -783.6177\tRegularization: 0.0017\n",
      "Iter: 5610  \tTraining Loss: -690.5992    \n",
      "    Negative Log Likelihood: 91.2221\tSigma2 Prior: -781.8229\tRegularization: 0.0017\n",
      "Iter: 5620  \tTraining Loss: -690.4573    \n",
      "    Negative Log Likelihood: 92.0121\tSigma2 Prior: -782.4711\tRegularization: 0.0017\n",
      "Iter: 5630  \tTraining Loss: -686.8661    \n",
      "    Negative Log Likelihood: 93.1513\tSigma2 Prior: -780.0190\tRegularization: 0.0017\n",
      "Iter: 5640  \tTraining Loss: -690.4727    \n",
      "    Negative Log Likelihood: 89.8532\tSigma2 Prior: -780.3276\tRegularization: 0.0017\n",
      "Iter: 5650  \tTraining Loss: -688.8083    \n",
      "    Negative Log Likelihood: 83.2825\tSigma2 Prior: -772.0925\tRegularization: 0.0017\n",
      "Iter: 5660  \tTraining Loss: -690.8616    \n",
      "    Negative Log Likelihood: 89.2447\tSigma2 Prior: -780.1078\tRegularization: 0.0017\n",
      "Iter: 5670  \tTraining Loss: -685.7919    \n",
      "    Negative Log Likelihood: 92.2975\tSigma2 Prior: -778.0911\tRegularization: 0.0017\n",
      "Iter: 5680  \tTraining Loss: -690.9251    \n",
      "    Negative Log Likelihood: 86.6918\tSigma2 Prior: -777.6186\tRegularization: 0.0017\n",
      "Iter: 5690  \tTraining Loss: -689.0422    \n",
      "    Negative Log Likelihood: 90.0381\tSigma2 Prior: -779.0820\tRegularization: 0.0017\n",
      "Iter: 5700  \tTraining Loss: -689.3448    \n",
      "    Negative Log Likelihood: 91.2877\tSigma2 Prior: -780.6342\tRegularization: 0.0017\n",
      "Iter: 5710  \tTraining Loss: -689.9409    \n",
      "    Negative Log Likelihood: 91.5777\tSigma2 Prior: -781.5202\tRegularization: 0.0017\n",
      "Iter: 5720  \tTraining Loss: -689.1094    \n",
      "    Negative Log Likelihood: 91.6996\tSigma2 Prior: -780.8107\tRegularization: 0.0017\n",
      "Iter: 5730  \tTraining Loss: -689.7001    \n",
      "    Negative Log Likelihood: 91.9661\tSigma2 Prior: -781.6678\tRegularization: 0.0017\n",
      "Iter: 5740  \tTraining Loss: -690.9119    \n",
      "    Negative Log Likelihood: 91.1302\tSigma2 Prior: -782.0438\tRegularization: 0.0017\n",
      "Iter: 5750  \tTraining Loss: -690.5557    \n",
      "    Negative Log Likelihood: 90.3560\tSigma2 Prior: -780.9134\tRegularization: 0.0017\n",
      "Iter: 5760  \tTraining Loss: -689.6931    \n",
      "    Negative Log Likelihood: 90.0714\tSigma2 Prior: -779.7661\tRegularization: 0.0017\n",
      "Iter: 5770  \tTraining Loss: -691.2679    \n",
      "    Negative Log Likelihood: 90.8066\tSigma2 Prior: -782.0762\tRegularization: 0.0017\n",
      "Iter: 5780  \tTraining Loss: -691.5469    \n",
      "    Negative Log Likelihood: 89.6905\tSigma2 Prior: -781.2391\tRegularization: 0.0017\n",
      "Iter: 5790  \tTraining Loss: -691.5753    \n",
      "    Negative Log Likelihood: 89.7660\tSigma2 Prior: -781.3430\tRegularization: 0.0017\n",
      "Iter: 5800  \tTraining Loss: -691.2999    \n",
      "    Negative Log Likelihood: 90.1080\tSigma2 Prior: -781.4095\tRegularization: 0.0017\n",
      "Iter: 5810  \tTraining Loss: -693.2584    \n",
      "    Negative Log Likelihood: 88.8225\tSigma2 Prior: -782.0825\tRegularization: 0.0017\n",
      "Iter: 5820  \tTraining Loss: -692.0746    \n",
      "    Negative Log Likelihood: 91.0892\tSigma2 Prior: -783.1655\tRegularization: 0.0017\n",
      "Iter: 5830  \tTraining Loss: -686.6898    \n",
      "    Negative Log Likelihood: 93.3624\tSigma2 Prior: -780.0539\tRegularization: 0.0017\n",
      "Iter: 5840  \tTraining Loss: -689.6229    \n",
      "    Negative Log Likelihood: 87.4317\tSigma2 Prior: -777.0562\tRegularization: 0.0017\n",
      "Iter: 5850  \tTraining Loss: -689.3399    \n",
      "    Negative Log Likelihood: 90.2506\tSigma2 Prior: -779.5922\tRegularization: 0.0017\n",
      "Iter: 5860  \tTraining Loss: -688.4338    \n",
      "    Negative Log Likelihood: 86.5839\tSigma2 Prior: -775.0194\tRegularization: 0.0017\n",
      "Iter: 5870  \tTraining Loss: -680.4197    \n",
      "    Negative Log Likelihood: 90.4577\tSigma2 Prior: -770.8791\tRegularization: 0.0017\n",
      "Iter: 5880  \tTraining Loss: -687.3170    \n",
      "    Negative Log Likelihood: 84.1869\tSigma2 Prior: -771.5055\tRegularization: 0.0017\n",
      "Iter: 5890  \tTraining Loss: -688.7738    \n",
      "    Negative Log Likelihood: 92.4148\tSigma2 Prior: -781.1902\tRegularization: 0.0017\n",
      "Iter: 5900  \tTraining Loss: -688.2905    \n",
      "    Negative Log Likelihood: 91.3596\tSigma2 Prior: -779.6519\tRegularization: 0.0017\n",
      "Iter: 5910  \tTraining Loss: -689.1523    \n",
      "    Negative Log Likelihood: 88.5688\tSigma2 Prior: -777.7228\tRegularization: 0.0017\n",
      "Iter: 5920  \tTraining Loss: -689.5991    \n",
      "    Negative Log Likelihood: 89.7834\tSigma2 Prior: -779.3842\tRegularization: 0.0017\n",
      "Iter: 5930  \tTraining Loss: -686.9096    \n",
      "    Negative Log Likelihood: 94.0579\tSigma2 Prior: -780.9692\tRegularization: 0.0017\n",
      "Iter: 5940  \tTraining Loss: -687.7624    \n",
      "    Negative Log Likelihood: 85.5542\tSigma2 Prior: -773.3183\tRegularization: 0.0017\n",
      "Iter: 5950  \tTraining Loss: -684.1670    \n",
      "    Negative Log Likelihood: 92.5323\tSigma2 Prior: -776.7010\tRegularization: 0.0017\n",
      "Iter: 5960  \tTraining Loss: -689.4756    \n",
      "    Negative Log Likelihood: 89.8107\tSigma2 Prior: -779.2880\tRegularization: 0.0017\n",
      "Iter: 5970  \tTraining Loss: -684.6917    \n",
      "    Negative Log Likelihood: 89.6046\tSigma2 Prior: -774.2980\tRegularization: 0.0017\n",
      "Iter: 5980  \tTraining Loss: -687.5516    \n",
      "    Negative Log Likelihood: 85.2629\tSigma2 Prior: -772.8162\tRegularization: 0.0017\n",
      "Iter: 5990  \tTraining Loss: -687.7968    \n",
      "    Negative Log Likelihood: 89.2134\tSigma2 Prior: -777.0120\tRegularization: 0.0017\n",
      "Iter: 6000  \tTraining Loss: -687.6277    \n",
      "    Negative Log Likelihood: 89.1579\tSigma2 Prior: -776.7873\tRegularization: 0.0017\n",
      "Iter: 6010  \tTraining Loss: -687.6053    \n",
      "    Negative Log Likelihood: 87.4146\tSigma2 Prior: -775.0215\tRegularization: 0.0017\n",
      "Iter: 6020  \tTraining Loss: -686.8704    \n",
      "    Negative Log Likelihood: 88.0442\tSigma2 Prior: -774.9163\tRegularization: 0.0017\n",
      "Iter: 6030  \tTraining Loss: -686.5193    \n",
      "    Negative Log Likelihood: 89.0080\tSigma2 Prior: -775.5290\tRegularization: 0.0017\n",
      "Iter: 6040  \tTraining Loss: -686.5871    \n",
      "    Negative Log Likelihood: 87.4731\tSigma2 Prior: -774.0620\tRegularization: 0.0017\n",
      "Iter: 6050  \tTraining Loss: -687.6812    \n",
      "    Negative Log Likelihood: 88.7340\tSigma2 Prior: -776.4169\tRegularization: 0.0017\n",
      "Iter: 6060  \tTraining Loss: -686.6270    \n",
      "    Negative Log Likelihood: 87.9012\tSigma2 Prior: -774.5298\tRegularization: 0.0017\n",
      "Iter: 6070  \tTraining Loss: -686.7678    \n",
      "    Negative Log Likelihood: 88.7713\tSigma2 Prior: -775.5408\tRegularization: 0.0017\n",
      "Iter: 6080  \tTraining Loss: -686.9911    \n",
      "    Negative Log Likelihood: 88.6963\tSigma2 Prior: -775.6891\tRegularization: 0.0017\n",
      "Iter: 6090  \tTraining Loss: -686.0726    \n",
      "    Negative Log Likelihood: 87.4128\tSigma2 Prior: -773.4871\tRegularization: 0.0017\n",
      "Iter: 6100  \tTraining Loss: -687.1801    \n",
      "    Negative Log Likelihood: 86.0313\tSigma2 Prior: -773.2131\tRegularization: 0.0017\n",
      "Iter: 6110  \tTraining Loss: -687.0974    \n",
      "    Negative Log Likelihood: 89.0632\tSigma2 Prior: -776.1622\tRegularization: 0.0017\n",
      "Iter: 6120  \tTraining Loss: -686.0093    \n",
      "    Negative Log Likelihood: 88.0028\tSigma2 Prior: -774.0138\tRegularization: 0.0017\n",
      "Iter: 6130  \tTraining Loss: -684.9393    \n",
      "    Negative Log Likelihood: 90.8750\tSigma2 Prior: -775.8159\tRegularization: 0.0017\n",
      "Iter: 6140  \tTraining Loss: -685.1375    \n",
      "    Negative Log Likelihood: 88.4771\tSigma2 Prior: -773.6163\tRegularization: 0.0017\n",
      "Iter: 6150  \tTraining Loss: -685.1675    \n",
      "    Negative Log Likelihood: 89.9349\tSigma2 Prior: -775.1041\tRegularization: 0.0017\n",
      "Iter: 6160  \tTraining Loss: -685.1757    \n",
      "    Negative Log Likelihood: 91.6726\tSigma2 Prior: -776.8500\tRegularization: 0.0017\n",
      "Iter: 6170  \tTraining Loss: -685.4111    \n",
      "    Negative Log Likelihood: 90.6327\tSigma2 Prior: -776.0454\tRegularization: 0.0017\n",
      "Iter: 6180  \tTraining Loss: -685.7787    \n",
      "    Negative Log Likelihood: 88.8317\tSigma2 Prior: -774.6121\tRegularization: 0.0017\n",
      "Iter: 6190  \tTraining Loss: -687.2433    \n",
      "    Negative Log Likelihood: 87.7945\tSigma2 Prior: -775.0396\tRegularization: 0.0017\n",
      "Iter: 6200  \tTraining Loss: -688.0004    \n",
      "    Negative Log Likelihood: 90.7826\tSigma2 Prior: -778.7847\tRegularization: 0.0017\n",
      "Iter: 6210  \tTraining Loss: -683.9833    \n",
      "    Negative Log Likelihood: 90.7760\tSigma2 Prior: -774.7610\tRegularization: 0.0017\n",
      "Iter: 6220  \tTraining Loss: -667.8732    \n",
      "    Negative Log Likelihood: 91.0797\tSigma2 Prior: -758.9547\tRegularization: 0.0017\n",
      "Iter: 6230  \tTraining Loss: -680.5667    \n",
      "    Negative Log Likelihood: 82.5065\tSigma2 Prior: -763.0749\tRegularization: 0.0017\n",
      "Iter: 6240  \tTraining Loss: -681.6351    \n",
      "    Negative Log Likelihood: 82.0129\tSigma2 Prior: -763.6497\tRegularization: 0.0017\n",
      "Iter: 6250  \tTraining Loss: -682.7342    \n",
      "    Negative Log Likelihood: 84.5951\tSigma2 Prior: -767.3309\tRegularization: 0.0017\n",
      "Iter: 6260  \tTraining Loss: -681.5052    \n",
      "    Negative Log Likelihood: 83.5646\tSigma2 Prior: -765.0716\tRegularization: 0.0017\n",
      "Iter: 6270  \tTraining Loss: -681.5577    \n",
      "    Negative Log Likelihood: 87.3981\tSigma2 Prior: -768.9576\tRegularization: 0.0017\n",
      "Iter: 6280  \tTraining Loss: -682.4816    \n",
      "    Negative Log Likelihood: 84.8893\tSigma2 Prior: -767.3726\tRegularization: 0.0017\n",
      "Iter: 6290  \tTraining Loss: -683.5844    \n",
      "    Negative Log Likelihood: 84.9112\tSigma2 Prior: -768.4973\tRegularization: 0.0017\n",
      "Iter: 6300  \tTraining Loss: -682.1956    \n",
      "    Negative Log Likelihood: 87.2673\tSigma2 Prior: -769.4645\tRegularization: 0.0017\n",
      "Iter: 6310  \tTraining Loss: -681.2367    \n",
      "    Negative Log Likelihood: 83.7313\tSigma2 Prior: -764.9697\tRegularization: 0.0017\n",
      "Iter: 6320  \tTraining Loss: -682.7289    \n",
      "    Negative Log Likelihood: 85.3420\tSigma2 Prior: -768.0727\tRegularization: 0.0017\n",
      "Iter: 6330  \tTraining Loss: -682.3114    \n",
      "    Negative Log Likelihood: 86.7550\tSigma2 Prior: -769.0681\tRegularization: 0.0017\n",
      "Iter: 6340  \tTraining Loss: -682.7573    \n",
      "    Negative Log Likelihood: 85.4524\tSigma2 Prior: -768.2114\tRegularization: 0.0017\n",
      "Iter: 6350  \tTraining Loss: -684.3019    \n",
      "    Negative Log Likelihood: 86.0998\tSigma2 Prior: -770.4034\tRegularization: 0.0017\n",
      "Iter: 6360  \tTraining Loss: -685.4132    \n",
      "    Negative Log Likelihood: 87.3206\tSigma2 Prior: -772.7355\tRegularization: 0.0017\n",
      "Iter: 6370  \tTraining Loss: -683.3929    \n",
      "    Negative Log Likelihood: 87.3868\tSigma2 Prior: -770.7815\tRegularization: 0.0017\n",
      "Iter: 6380  \tTraining Loss: -685.3685    \n",
      "    Negative Log Likelihood: 86.6295\tSigma2 Prior: -771.9997\tRegularization: 0.0017\n",
      "Iter: 6390  \tTraining Loss: -685.5716    \n",
      "    Negative Log Likelihood: 87.6193\tSigma2 Prior: -773.1926\tRegularization: 0.0017\n",
      "Iter: 6400  \tTraining Loss: -685.0381    \n",
      "    Negative Log Likelihood: 87.4388\tSigma2 Prior: -772.4787\tRegularization: 0.0017\n",
      "Iter: 6410  \tTraining Loss: -686.9996    \n",
      "    Negative Log Likelihood: 85.5219\tSigma2 Prior: -772.5233\tRegularization: 0.0017\n",
      "Iter: 6420  \tTraining Loss: -687.5698    \n",
      "    Negative Log Likelihood: 86.7568\tSigma2 Prior: -774.3283\tRegularization: 0.0017\n",
      "Iter: 6430  \tTraining Loss: -687.6518    \n",
      "    Negative Log Likelihood: 87.5786\tSigma2 Prior: -775.2321\tRegularization: 0.0017\n",
      "Iter: 6440  \tTraining Loss: -689.9567    \n",
      "    Negative Log Likelihood: 89.2014\tSigma2 Prior: -779.1599\tRegularization: 0.0017\n",
      "Iter: 6450  \tTraining Loss: -689.3203    \n",
      "    Negative Log Likelihood: 90.4514\tSigma2 Prior: -779.7734\tRegularization: 0.0017\n",
      "Iter: 6460  \tTraining Loss: -692.5403    \n",
      "    Negative Log Likelihood: 88.1513\tSigma2 Prior: -780.6934\tRegularization: 0.0017\n",
      "Iter: 6470  \tTraining Loss: -687.4057    \n",
      "    Negative Log Likelihood: 89.8674\tSigma2 Prior: -777.2748\tRegularization: 0.0017\n",
      "Iter: 6480  \tTraining Loss: -683.9932    \n",
      "    Negative Log Likelihood: 92.8413\tSigma2 Prior: -776.8362\tRegularization: 0.0017\n",
      "Iter: 6490  \tTraining Loss: -687.4134    \n",
      "    Negative Log Likelihood: 87.5721\tSigma2 Prior: -774.9872\tRegularization: 0.0017\n",
      "Iter: 6500  \tTraining Loss: -689.4045    \n",
      "    Negative Log Likelihood: 87.0859\tSigma2 Prior: -776.4922\tRegularization: 0.0017\n",
      "Iter: 6510  \tTraining Loss: -687.9025    \n",
      "    Negative Log Likelihood: 90.4133\tSigma2 Prior: -778.3174\tRegularization: 0.0017\n",
      "Iter: 6520  \tTraining Loss: -689.2002    \n",
      "    Negative Log Likelihood: 92.1734\tSigma2 Prior: -781.3753\tRegularization: 0.0017\n",
      "Iter: 6530  \tTraining Loss: -690.0947    \n",
      "    Negative Log Likelihood: 90.1918\tSigma2 Prior: -780.2883\tRegularization: 0.0017\n",
      "Iter: 6540  \tTraining Loss: -690.3674    \n",
      "    Negative Log Likelihood: 89.0452\tSigma2 Prior: -779.4142\tRegularization: 0.0017\n",
      "Iter: 6550  \tTraining Loss: -690.1548    \n",
      "    Negative Log Likelihood: 90.3611\tSigma2 Prior: -780.5176\tRegularization: 0.0017\n",
      "Iter: 6560  \tTraining Loss: -690.0626    \n",
      "    Negative Log Likelihood: 91.6843\tSigma2 Prior: -781.7486\tRegularization: 0.0017\n",
      "Iter: 6570  \tTraining Loss: -689.5263    \n",
      "    Negative Log Likelihood: 91.3690\tSigma2 Prior: -780.8970\tRegularization: 0.0017\n",
      "Iter: 6580  \tTraining Loss: -690.1381    \n",
      "    Negative Log Likelihood: 90.2112\tSigma2 Prior: -780.3510\tRegularization: 0.0017\n",
      "Iter: 6590  \tTraining Loss: -690.5227    \n",
      "    Negative Log Likelihood: 92.1115\tSigma2 Prior: -782.6359\tRegularization: 0.0017\n",
      "Iter: 6600  \tTraining Loss: -689.8283    \n",
      "    Negative Log Likelihood: 92.3676\tSigma2 Prior: -782.1976\tRegularization: 0.0017\n",
      "Iter: 6610  \tTraining Loss: -690.4924    \n",
      "    Negative Log Likelihood: 91.2209\tSigma2 Prior: -781.7150\tRegularization: 0.0017\n",
      "Iter: 6620  \tTraining Loss: -690.6642    \n",
      "    Negative Log Likelihood: 91.1376\tSigma2 Prior: -781.8035\tRegularization: 0.0017\n",
      "Iter: 6630  \tTraining Loss: -690.7090    \n",
      "    Negative Log Likelihood: 89.8689\tSigma2 Prior: -780.5796\tRegularization: 0.0017\n",
      "Iter: 6640  \tTraining Loss: -691.4990    \n",
      "    Negative Log Likelihood: 90.1457\tSigma2 Prior: -781.6464\tRegularization: 0.0017\n",
      "Iter: 6650  \tTraining Loss: -689.7058    \n",
      "    Negative Log Likelihood: 93.4704\tSigma2 Prior: -783.1779\tRegularization: 0.0017\n",
      "Iter: 6660  \tTraining Loss: -691.0126    \n",
      "    Negative Log Likelihood: 89.3954\tSigma2 Prior: -780.4097\tRegularization: 0.0017\n",
      "Iter: 6670  \tTraining Loss: -689.0267    \n",
      "    Negative Log Likelihood: 92.0463\tSigma2 Prior: -781.0747\tRegularization: 0.0017\n",
      "Iter: 6680  \tTraining Loss: -689.8377    \n",
      "    Negative Log Likelihood: 87.8857\tSigma2 Prior: -777.7252\tRegularization: 0.0017\n",
      "Iter: 6690  \tTraining Loss: -692.3016    \n",
      "    Negative Log Likelihood: 88.3144\tSigma2 Prior: -780.6177\tRegularization: 0.0017\n",
      "Iter: 6700  \tTraining Loss: -692.4686    \n",
      "    Negative Log Likelihood: 90.0858\tSigma2 Prior: -782.5562\tRegularization: 0.0017\n",
      "Iter: 6710  \tTraining Loss: -690.4495    \n",
      "    Negative Log Likelihood: 90.8111\tSigma2 Prior: -781.2623\tRegularization: 0.0017\n",
      "Iter: 6720  \tTraining Loss: -691.6533    \n",
      "    Negative Log Likelihood: 88.8526\tSigma2 Prior: -780.5076\tRegularization: 0.0017\n",
      "Iter: 6730  \tTraining Loss: -689.8680    \n",
      "    Negative Log Likelihood: 87.3821\tSigma2 Prior: -777.2518\tRegularization: 0.0017\n",
      "Iter: 6740  \tTraining Loss: -687.2266    \n",
      "    Negative Log Likelihood: 88.1442\tSigma2 Prior: -775.3726\tRegularization: 0.0017\n",
      "Iter: 6750  \tTraining Loss: -687.6768    \n",
      "    Negative Log Likelihood: 87.9918\tSigma2 Prior: -775.6703\tRegularization: 0.0017\n",
      "Iter: 6760  \tTraining Loss: -686.6187    \n",
      "    Negative Log Likelihood: 90.6549\tSigma2 Prior: -777.2753\tRegularization: 0.0017\n",
      "Iter: 6770  \tTraining Loss: -686.6664    \n",
      "    Negative Log Likelihood: 82.6190\tSigma2 Prior: -769.2870\tRegularization: 0.0017\n",
      "Iter: 6780  \tTraining Loss: -686.8415    \n",
      "    Negative Log Likelihood: 87.8085\tSigma2 Prior: -774.6517\tRegularization: 0.0017\n",
      "Iter: 6790  \tTraining Loss: -683.1549    \n",
      "    Negative Log Likelihood: 91.8532\tSigma2 Prior: -775.0099\tRegularization: 0.0017\n",
      "Iter: 6800  \tTraining Loss: -686.0601    \n",
      "    Negative Log Likelihood: 84.8187\tSigma2 Prior: -770.8804\tRegularization: 0.0017\n",
      "Iter: 6810  \tTraining Loss: -685.0036    \n",
      "    Negative Log Likelihood: 85.9843\tSigma2 Prior: -770.9896\tRegularization: 0.0017\n",
      "Iter: 6820  \tTraining Loss: -685.4399    \n",
      "    Negative Log Likelihood: 89.3085\tSigma2 Prior: -774.7501\tRegularization: 0.0017\n",
      "Iter: 6830  \tTraining Loss: -686.5909    \n",
      "    Negative Log Likelihood: 86.2701\tSigma2 Prior: -772.8627\tRegularization: 0.0017\n",
      "Iter: 6840  \tTraining Loss: -684.3812    \n",
      "    Negative Log Likelihood: 85.1936\tSigma2 Prior: -769.5766\tRegularization: 0.0017\n",
      "Iter: 6850  \tTraining Loss: -684.7923    \n",
      "    Negative Log Likelihood: 85.0963\tSigma2 Prior: -769.8903\tRegularization: 0.0017\n",
      "Iter: 6860  \tTraining Loss: -685.1310    \n",
      "    Negative Log Likelihood: 86.3051\tSigma2 Prior: -771.4378\tRegularization: 0.0017\n",
      "Iter: 6870  \tTraining Loss: -685.3036    \n",
      "    Negative Log Likelihood: 85.3468\tSigma2 Prior: -770.6521\tRegularization: 0.0017\n",
      "Iter: 6880  \tTraining Loss: -685.2119    \n",
      "    Negative Log Likelihood: 86.1861\tSigma2 Prior: -771.3997\tRegularization: 0.0017\n",
      "Iter: 6890  \tTraining Loss: -685.1364    \n",
      "    Negative Log Likelihood: 85.4508\tSigma2 Prior: -770.5889\tRegularization: 0.0017\n",
      "Iter: 6900  \tTraining Loss: -685.1560    \n",
      "    Negative Log Likelihood: 85.3730\tSigma2 Prior: -770.5308\tRegularization: 0.0017\n",
      "Iter: 6910  \tTraining Loss: -684.5917    \n",
      "    Negative Log Likelihood: 88.1549\tSigma2 Prior: -772.7484\tRegularization: 0.0017\n",
      "Iter: 6920  \tTraining Loss: -684.8318    \n",
      "    Negative Log Likelihood: 86.2445\tSigma2 Prior: -771.0780\tRegularization: 0.0017\n",
      "Iter: 6930  \tTraining Loss: -685.7957    \n",
      "    Negative Log Likelihood: 86.6870\tSigma2 Prior: -772.4843\tRegularization: 0.0017\n",
      "Iter: 6940  \tTraining Loss: -686.5070    \n",
      "    Negative Log Likelihood: 87.3266\tSigma2 Prior: -773.8353\tRegularization: 0.0017\n",
      "Iter: 6950  \tTraining Loss: -686.5965    \n",
      "    Negative Log Likelihood: 86.6754\tSigma2 Prior: -773.2736\tRegularization: 0.0017\n",
      "Iter: 6960  \tTraining Loss: -688.1700    \n",
      "    Negative Log Likelihood: 86.8607\tSigma2 Prior: -775.0324\tRegularization: 0.0017\n",
      "Iter: 6970  \tTraining Loss: -688.5204    \n",
      "    Negative Log Likelihood: 87.2967\tSigma2 Prior: -775.8188\tRegularization: 0.0017\n",
      "Iter: 6980  \tTraining Loss: -688.2181    \n",
      "    Negative Log Likelihood: 88.6807\tSigma2 Prior: -776.9005\tRegularization: 0.0017\n",
      "Iter: 6990  \tTraining Loss: -684.3729    \n",
      "    Negative Log Likelihood: 91.6833\tSigma2 Prior: -776.0578\tRegularization: 0.0017\n",
      "Iter: 7000  \tTraining Loss: -684.9859    \n",
      "    Negative Log Likelihood: 89.5606\tSigma2 Prior: -774.5482\tRegularization: 0.0017\n",
      "Iter: 7010  \tTraining Loss: -679.5342    \n",
      "    Negative Log Likelihood: 86.2891\tSigma2 Prior: -765.8251\tRegularization: 0.0017\n",
      "Iter: 7020  \tTraining Loss: -681.3538    \n",
      "    Negative Log Likelihood: 82.8107\tSigma2 Prior: -764.1662\tRegularization: 0.0017\n",
      "Iter: 7030  \tTraining Loss: -678.2119    \n",
      "    Negative Log Likelihood: 81.9391\tSigma2 Prior: -760.1526\tRegularization: 0.0017\n",
      "Iter: 7040  \tTraining Loss: -671.1638    \n",
      "    Negative Log Likelihood: 79.1566\tSigma2 Prior: -750.3221\tRegularization: 0.0017\n",
      "Iter: 7050  \tTraining Loss: -670.4319    \n",
      "    Negative Log Likelihood: 85.4100\tSigma2 Prior: -755.8437\tRegularization: 0.0017\n",
      "Iter: 7060  \tTraining Loss: -660.5521    \n",
      "    Negative Log Likelihood: 89.2642\tSigma2 Prior: -749.8181\tRegularization: 0.0017\n",
      "Iter: 7070  \tTraining Loss: -672.7205    \n",
      "    Negative Log Likelihood: 77.6583\tSigma2 Prior: -750.3806\tRegularization: 0.0017\n",
      "Iter: 7080  \tTraining Loss: -674.5646    \n",
      "    Negative Log Likelihood: 82.7516\tSigma2 Prior: -757.3180\tRegularization: 0.0017\n",
      "Iter: 7090  \tTraining Loss: -674.0502    \n",
      "    Negative Log Likelihood: 84.7643\tSigma2 Prior: -758.8163\tRegularization: 0.0017\n",
      "Iter: 7100  \tTraining Loss: -678.4103    \n",
      "    Negative Log Likelihood: 82.9598\tSigma2 Prior: -761.3719\tRegularization: 0.0017\n",
      "Iter: 7110  \tTraining Loss: -678.9142    \n",
      "    Negative Log Likelihood: 84.5588\tSigma2 Prior: -763.4747\tRegularization: 0.0017\n",
      "Iter: 7120  \tTraining Loss: -680.8851    \n",
      "    Negative Log Likelihood: 85.9695\tSigma2 Prior: -766.8563\tRegularization: 0.0017\n",
      "Iter: 7130  \tTraining Loss: -681.0113    \n",
      "    Negative Log Likelihood: 86.3445\tSigma2 Prior: -767.3575\tRegularization: 0.0017\n",
      "Iter: 7140  \tTraining Loss: -683.0867    \n",
      "    Negative Log Likelihood: 85.1512\tSigma2 Prior: -768.2397\tRegularization: 0.0017\n",
      "Iter: 7150  \tTraining Loss: -683.2544    \n",
      "    Negative Log Likelihood: 85.5238\tSigma2 Prior: -768.7800\tRegularization: 0.0017\n",
      "Iter: 7160  \tTraining Loss: -683.5611    \n",
      "    Negative Log Likelihood: 86.9768\tSigma2 Prior: -770.5397\tRegularization: 0.0017\n",
      "Iter: 7170  \tTraining Loss: -683.7618    \n",
      "    Negative Log Likelihood: 86.8189\tSigma2 Prior: -770.5824\tRegularization: 0.0017\n",
      "Iter: 7180  \tTraining Loss: -684.1927    \n",
      "    Negative Log Likelihood: 86.6524\tSigma2 Prior: -770.8469\tRegularization: 0.0017\n",
      "Iter: 7190  \tTraining Loss: -685.1159    \n",
      "    Negative Log Likelihood: 86.2317\tSigma2 Prior: -771.3494\tRegularization: 0.0018\n",
      "Iter: 7200  \tTraining Loss: -685.1187    \n",
      "    Negative Log Likelihood: 87.1536\tSigma2 Prior: -772.2740\tRegularization: 0.0018\n",
      "Iter: 7210  \tTraining Loss: -685.3730    \n",
      "    Negative Log Likelihood: 87.2624\tSigma2 Prior: -772.6371\tRegularization: 0.0018\n",
      "Iter: 7220  \tTraining Loss: -685.9328    \n",
      "    Negative Log Likelihood: 87.1457\tSigma2 Prior: -773.0803\tRegularization: 0.0018\n",
      "Iter: 7230  \tTraining Loss: -687.7878    \n",
      "    Negative Log Likelihood: 88.6184\tSigma2 Prior: -776.4080\tRegularization: 0.0018\n",
      "Iter: 7240  \tTraining Loss: -686.5355    \n",
      "    Negative Log Likelihood: 84.5342\tSigma2 Prior: -771.0715\tRegularization: 0.0018\n",
      "Iter: 7250  \tTraining Loss: -682.7149    \n",
      "    Negative Log Likelihood: 92.1845\tSigma2 Prior: -774.9012\tRegularization: 0.0018\n",
      "Iter: 7260  \tTraining Loss: -682.3145    \n",
      "    Negative Log Likelihood: 90.2289\tSigma2 Prior: -772.5452\tRegularization: 0.0018\n",
      "Iter: 7270  \tTraining Loss: -687.5441    \n",
      "    Negative Log Likelihood: 87.1946\tSigma2 Prior: -774.7404\tRegularization: 0.0018\n",
      "Iter: 7280  \tTraining Loss: -683.3346    \n",
      "    Negative Log Likelihood: 84.0219\tSigma2 Prior: -767.3583\tRegularization: 0.0018\n",
      "Iter: 7290  \tTraining Loss: -684.8380    \n",
      "    Negative Log Likelihood: 85.6278\tSigma2 Prior: -770.4675\tRegularization: 0.0018\n",
      "Iter: 7300  \tTraining Loss: -686.0804    \n",
      "    Negative Log Likelihood: 88.7083\tSigma2 Prior: -774.7905\tRegularization: 0.0018\n",
      "Iter: 7310  \tTraining Loss: -686.6110    \n",
      "    Negative Log Likelihood: 85.0284\tSigma2 Prior: -771.6412\tRegularization: 0.0018\n",
      "Iter: 7320  \tTraining Loss: -686.1248    \n",
      "    Negative Log Likelihood: 86.0733\tSigma2 Prior: -772.1998\tRegularization: 0.0018\n",
      "Iter: 7330  \tTraining Loss: -685.8398    \n",
      "    Negative Log Likelihood: 88.9053\tSigma2 Prior: -774.7469\tRegularization: 0.0018\n",
      "Iter: 7340  \tTraining Loss: -686.3959    \n",
      "    Negative Log Likelihood: 87.7751\tSigma2 Prior: -774.1728\tRegularization: 0.0018\n",
      "Iter: 7350  \tTraining Loss: -686.1935    \n",
      "    Negative Log Likelihood: 86.9199\tSigma2 Prior: -773.1152\tRegularization: 0.0018\n",
      "Iter: 7360  \tTraining Loss: -686.4245    \n",
      "    Negative Log Likelihood: 89.0744\tSigma2 Prior: -775.5007\tRegularization: 0.0018\n",
      "Iter: 7370  \tTraining Loss: -687.6031    \n",
      "    Negative Log Likelihood: 88.6960\tSigma2 Prior: -776.3009\tRegularization: 0.0018\n",
      "Iter: 7380  \tTraining Loss: -687.2722    \n",
      "    Negative Log Likelihood: 89.2185\tSigma2 Prior: -776.4925\tRegularization: 0.0018\n",
      "Iter: 7390  \tTraining Loss: -687.6915    \n",
      "    Negative Log Likelihood: 87.4273\tSigma2 Prior: -775.1207\tRegularization: 0.0018\n",
      "Iter: 7400  \tTraining Loss: -688.3535    \n",
      "    Negative Log Likelihood: 85.6902\tSigma2 Prior: -774.0454\tRegularization: 0.0018\n",
      "Iter: 7410  \tTraining Loss: -687.5899    \n",
      "    Negative Log Likelihood: 89.0274\tSigma2 Prior: -776.6190\tRegularization: 0.0018\n",
      "Iter: 7420  \tTraining Loss: -686.2404    \n",
      "    Negative Log Likelihood: 92.2715\tSigma2 Prior: -778.5137\tRegularization: 0.0018\n",
      "Iter: 7430  \tTraining Loss: -686.2342    \n",
      "    Negative Log Likelihood: 90.4913\tSigma2 Prior: -776.7272\tRegularization: 0.0018\n",
      "Iter: 7440  \tTraining Loss: -685.2802    \n",
      "    Negative Log Likelihood: 91.4623\tSigma2 Prior: -776.7442\tRegularization: 0.0018\n",
      "Iter: 7450  \tTraining Loss: -687.9031    \n",
      "    Negative Log Likelihood: 85.2713\tSigma2 Prior: -773.1761\tRegularization: 0.0018\n",
      "Iter: 7460  \tTraining Loss: -688.2682    \n",
      "    Negative Log Likelihood: 86.2449\tSigma2 Prior: -774.5150\tRegularization: 0.0018\n",
      "Iter: 7470  \tTraining Loss: -683.9145    \n",
      "    Negative Log Likelihood: 85.9132\tSigma2 Prior: -769.8295\tRegularization: 0.0018\n",
      "Iter: 7480  \tTraining Loss: -687.0470    \n",
      "    Negative Log Likelihood: 82.0033\tSigma2 Prior: -769.0521\tRegularization: 0.0018\n",
      "Iter: 7490  \tTraining Loss: -689.1131    \n",
      "    Negative Log Likelihood: 87.8514\tSigma2 Prior: -776.9663\tRegularization: 0.0018\n",
      "Iter: 7500  \tTraining Loss: -685.9134    \n",
      "    Negative Log Likelihood: 95.6588\tSigma2 Prior: -781.5739\tRegularization: 0.0018\n",
      "Iter: 7510  \tTraining Loss: -688.1061    \n",
      "    Negative Log Likelihood: 90.2149\tSigma2 Prior: -778.3228\tRegularization: 0.0018\n",
      "Iter: 7520  \tTraining Loss: -690.4000    \n",
      "    Negative Log Likelihood: 86.3057\tSigma2 Prior: -776.7075\tRegularization: 0.0018\n",
      "Iter: 7530  \tTraining Loss: -681.7952    \n",
      "    Negative Log Likelihood: 87.9186\tSigma2 Prior: -769.7155\tRegularization: 0.0018\n",
      "Iter: 7540  \tTraining Loss: -683.5815    \n",
      "    Negative Log Likelihood: 91.3044\tSigma2 Prior: -774.8876\tRegularization: 0.0018\n",
      "Iter: 7550  \tTraining Loss: -683.3343    \n",
      "    Negative Log Likelihood: 86.8805\tSigma2 Prior: -770.2166\tRegularization: 0.0018\n",
      "Iter: 7560  \tTraining Loss: -686.0178    \n",
      "    Negative Log Likelihood: 88.3518\tSigma2 Prior: -774.3713\tRegularization: 0.0018\n",
      "Iter: 7570  \tTraining Loss: -686.5172    \n",
      "    Negative Log Likelihood: 88.8347\tSigma2 Prior: -775.3537\tRegularization: 0.0018\n",
      "Iter: 7580  \tTraining Loss: -687.5258    \n",
      "    Negative Log Likelihood: 87.5380\tSigma2 Prior: -775.0656\tRegularization: 0.0018\n",
      "Iter: 7590  \tTraining Loss: -687.4296    \n",
      "    Negative Log Likelihood: 87.9657\tSigma2 Prior: -775.3971\tRegularization: 0.0018\n",
      "Iter: 7600  \tTraining Loss: -687.3589    \n",
      "    Negative Log Likelihood: 88.3749\tSigma2 Prior: -775.7357\tRegularization: 0.0018\n",
      "Iter: 7610  \tTraining Loss: -687.7701    \n",
      "    Negative Log Likelihood: 87.2645\tSigma2 Prior: -775.0364\tRegularization: 0.0018\n",
      "Iter: 7620  \tTraining Loss: -688.1971    \n",
      "    Negative Log Likelihood: 86.5666\tSigma2 Prior: -774.7654\tRegularization: 0.0018\n",
      "Iter: 7630  \tTraining Loss: -687.9840    \n",
      "    Negative Log Likelihood: 86.4758\tSigma2 Prior: -774.4616\tRegularization: 0.0018\n",
      "Iter: 7640  \tTraining Loss: -688.2525    \n",
      "    Negative Log Likelihood: 84.9004\tSigma2 Prior: -773.1547\tRegularization: 0.0018\n",
      "Iter: 7650  \tTraining Loss: -688.5235    \n",
      "    Negative Log Likelihood: 87.3904\tSigma2 Prior: -775.9156\tRegularization: 0.0018\n",
      "Iter: 7660  \tTraining Loss: -688.0684    \n",
      "    Negative Log Likelihood: 86.7559\tSigma2 Prior: -774.8261\tRegularization: 0.0018\n",
      "Iter: 7670  \tTraining Loss: -688.7573    \n",
      "    Negative Log Likelihood: 87.1063\tSigma2 Prior: -775.8654\tRegularization: 0.0018\n",
      "Iter: 7680  \tTraining Loss: -688.5538    \n",
      "    Negative Log Likelihood: 88.9989\tSigma2 Prior: -777.5544\tRegularization: 0.0018\n",
      "Iter: 7690  \tTraining Loss: -688.6658    \n",
      "    Negative Log Likelihood: 86.7638\tSigma2 Prior: -775.4313\tRegularization: 0.0018\n",
      "Iter: 7700  \tTraining Loss: -689.6156    \n",
      "    Negative Log Likelihood: 87.3512\tSigma2 Prior: -776.9686\tRegularization: 0.0018\n",
      "Iter: 7710  \tTraining Loss: -689.1472    \n",
      "    Negative Log Likelihood: 88.8447\tSigma2 Prior: -777.9937\tRegularization: 0.0018\n",
      "Iter: 7720  \tTraining Loss: -689.0882    \n",
      "    Negative Log Likelihood: 87.5421\tSigma2 Prior: -776.6320\tRegularization: 0.0018\n",
      "Iter: 7730  \tTraining Loss: -688.1836    \n",
      "    Negative Log Likelihood: 86.8072\tSigma2 Prior: -774.9926\tRegularization: 0.0018\n",
      "Iter: 7740  \tTraining Loss: -689.2769    \n",
      "    Negative Log Likelihood: 85.5541\tSigma2 Prior: -774.8328\tRegularization: 0.0018\n",
      "Iter: 7750  \tTraining Loss: -691.1627    \n",
      "    Negative Log Likelihood: 85.3461\tSigma2 Prior: -776.5106\tRegularization: 0.0018\n",
      "Iter: 7760  \tTraining Loss: -691.2506    \n",
      "    Negative Log Likelihood: 87.3942\tSigma2 Prior: -778.6466\tRegularization: 0.0018\n",
      "Iter: 7770  \tTraining Loss: -686.4810    \n",
      "    Negative Log Likelihood: 79.8362\tSigma2 Prior: -766.3190\tRegularization: 0.0018\n",
      "Iter: 7780  \tTraining Loss: -683.4733    \n",
      "    Negative Log Likelihood: 87.3414\tSigma2 Prior: -770.8165\tRegularization: 0.0018\n",
      "Iter: 7790  \tTraining Loss: -686.2158    \n",
      "    Negative Log Likelihood: 90.2967\tSigma2 Prior: -776.5143\tRegularization: 0.0018\n",
      "Iter: 7800  \tTraining Loss: -687.2989    \n",
      "    Negative Log Likelihood: 92.2922\tSigma2 Prior: -779.5928\tRegularization: 0.0018\n",
      "Iter: 7810  \tTraining Loss: -689.0714    \n",
      "    Negative Log Likelihood: 88.7626\tSigma2 Prior: -777.8358\tRegularization: 0.0018\n",
      "Iter: 7820  \tTraining Loss: -689.8555    \n",
      "    Negative Log Likelihood: 89.9063\tSigma2 Prior: -779.7636\tRegularization: 0.0018\n",
      "Iter: 7830  \tTraining Loss: -689.4548    \n",
      "    Negative Log Likelihood: 90.2639\tSigma2 Prior: -779.7205\tRegularization: 0.0018\n",
      "Iter: 7840  \tTraining Loss: -691.0720    \n",
      "    Negative Log Likelihood: 86.5223\tSigma2 Prior: -777.5961\tRegularization: 0.0018\n",
      "Iter: 7850  \tTraining Loss: -690.9819    \n",
      "    Negative Log Likelihood: 89.8375\tSigma2 Prior: -780.8211\tRegularization: 0.0018\n",
      "Iter: 7860  \tTraining Loss: -690.3191    \n",
      "    Negative Log Likelihood: 91.5494\tSigma2 Prior: -781.8703\tRegularization: 0.0018\n",
      "Iter: 7870  \tTraining Loss: -690.5335    \n",
      "    Negative Log Likelihood: 88.5332\tSigma2 Prior: -779.0685\tRegularization: 0.0018\n",
      "Iter: 7880  \tTraining Loss: -690.9545    \n",
      "    Negative Log Likelihood: 89.2063\tSigma2 Prior: -780.1625\tRegularization: 0.0018\n",
      "Iter: 7890  \tTraining Loss: -690.2553    \n",
      "    Negative Log Likelihood: 90.3376\tSigma2 Prior: -780.5947\tRegularization: 0.0018\n",
      "Iter: 7900  \tTraining Loss: -692.1688    \n",
      "    Negative Log Likelihood: 86.5812\tSigma2 Prior: -778.7518\tRegularization: 0.0018\n",
      "Iter: 7910  \tTraining Loss: -689.8832    \n",
      "    Negative Log Likelihood: 93.3725\tSigma2 Prior: -783.2574\tRegularization: 0.0018\n",
      "Iter: 7920  \tTraining Loss: -692.4062    \n",
      "    Negative Log Likelihood: 88.7958\tSigma2 Prior: -781.2037\tRegularization: 0.0018\n",
      "Iter: 7930  \tTraining Loss: -689.4278    \n",
      "    Negative Log Likelihood: 92.7613\tSigma2 Prior: -782.1909\tRegularization: 0.0018\n",
      "Iter: 7940  \tTraining Loss: -692.3958    \n",
      "    Negative Log Likelihood: 86.2111\tSigma2 Prior: -778.6086\tRegularization: 0.0018\n",
      "Iter: 7950  \tTraining Loss: -687.8257    \n",
      "    Negative Log Likelihood: 89.0293\tSigma2 Prior: -776.8568\tRegularization: 0.0018\n",
      "Iter: 7960  \tTraining Loss: -686.9229    \n",
      "    Negative Log Likelihood: 92.6068\tSigma2 Prior: -779.5315\tRegularization: 0.0018\n",
      "Iter: 7970  \tTraining Loss: -691.6281    \n",
      "    Negative Log Likelihood: 90.6955\tSigma2 Prior: -782.3253\tRegularization: 0.0018\n",
      "Iter: 7980  \tTraining Loss: -691.4724    \n",
      "    Negative Log Likelihood: 88.8412\tSigma2 Prior: -780.3154\tRegularization: 0.0018\n",
      "Iter: 7990  \tTraining Loss: -693.7861    \n",
      "    Negative Log Likelihood: 88.0907\tSigma2 Prior: -781.8785\tRegularization: 0.0018\n",
      "Iter: 8000  \tTraining Loss: -692.2624    \n",
      "    Negative Log Likelihood: 89.5983\tSigma2 Prior: -781.8624\tRegularization: 0.0018\n",
      "Iter: 8010  \tTraining Loss: -685.9424    \n",
      "    Negative Log Likelihood: 92.2161\tSigma2 Prior: -778.1603\tRegularization: 0.0018\n",
      "Iter: 8020  \tTraining Loss: -691.2589    \n",
      "    Negative Log Likelihood: 89.9974\tSigma2 Prior: -781.2580\tRegularization: 0.0018\n",
      "Iter: 8030  \tTraining Loss: -688.4552    \n",
      "    Negative Log Likelihood: 87.6034\tSigma2 Prior: -776.0604\tRegularization: 0.0018\n",
      "Iter: 8040  \tTraining Loss: -686.6282    \n",
      "    Negative Log Likelihood: 85.6985\tSigma2 Prior: -772.3286\tRegularization: 0.0018\n",
      "Iter: 8050  \tTraining Loss: -689.7380    \n",
      "    Negative Log Likelihood: 86.5574\tSigma2 Prior: -776.2972\tRegularization: 0.0018\n",
      "Iter: 8060  \tTraining Loss: -686.2947    \n",
      "    Negative Log Likelihood: 91.7749\tSigma2 Prior: -778.0714\tRegularization: 0.0018\n",
      "Iter: 8070  \tTraining Loss: -688.3124    \n",
      "    Negative Log Likelihood: 88.8491\tSigma2 Prior: -777.1633\tRegularization: 0.0018\n",
      "Iter: 8080  \tTraining Loss: -689.0420    \n",
      "    Negative Log Likelihood: 87.1403\tSigma2 Prior: -776.1840\tRegularization: 0.0018\n",
      "Iter: 8090  \tTraining Loss: -688.4092    \n",
      "    Negative Log Likelihood: 89.2402\tSigma2 Prior: -777.6512\tRegularization: 0.0018\n",
      "Iter: 8100  \tTraining Loss: -689.7886    \n",
      "    Negative Log Likelihood: 87.4338\tSigma2 Prior: -777.2241\tRegularization: 0.0018\n",
      "Iter: 8110  \tTraining Loss: -688.4382    \n",
      "    Negative Log Likelihood: 89.6409\tSigma2 Prior: -778.0808\tRegularization: 0.0018\n",
      "Iter: 8120  \tTraining Loss: -689.4481    \n",
      "    Negative Log Likelihood: 87.6005\tSigma2 Prior: -777.0504\tRegularization: 0.0018\n",
      "Iter: 8130  \tTraining Loss: -691.0139    \n",
      "    Negative Log Likelihood: 85.5104\tSigma2 Prior: -776.5261\tRegularization: 0.0018\n",
      "Iter: 8140  \tTraining Loss: -687.4245    \n",
      "    Negative Log Likelihood: 94.1173\tSigma2 Prior: -781.5436\tRegularization: 0.0018\n",
      "Iter: 8150  \tTraining Loss: -688.4212    \n",
      "    Negative Log Likelihood: 89.8990\tSigma2 Prior: -778.3220\tRegularization: 0.0018\n",
      "Iter: 8160  \tTraining Loss: -689.7101    \n",
      "    Negative Log Likelihood: 83.8259\tSigma2 Prior: -773.5378\tRegularization: 0.0018\n",
      "Iter: 8170  \tTraining Loss: -692.4411    \n",
      "    Negative Log Likelihood: 89.0628\tSigma2 Prior: -781.5057\tRegularization: 0.0018\n",
      "Iter: 8180  \tTraining Loss: -691.1960    \n",
      "    Negative Log Likelihood: 85.7859\tSigma2 Prior: -776.9837\tRegularization: 0.0018\n",
      "Iter: 8190  \tTraining Loss: -689.2088    \n",
      "    Negative Log Likelihood: 92.1156\tSigma2 Prior: -781.3262\tRegularization: 0.0018\n",
      "Iter: 8200  \tTraining Loss: -686.8652    \n",
      "    Negative Log Likelihood: 94.7429\tSigma2 Prior: -781.6099\tRegularization: 0.0018\n",
      "Iter: 8210  \tTraining Loss: -687.0999    \n",
      "    Negative Log Likelihood: 86.6656\tSigma2 Prior: -773.7672\tRegularization: 0.0018\n",
      "Iter: 8220  \tTraining Loss: -687.4033    \n",
      "    Negative Log Likelihood: 87.1141\tSigma2 Prior: -774.5191\tRegularization: 0.0018\n",
      "Iter: 8230  \tTraining Loss: -690.1677    \n",
      "    Negative Log Likelihood: 81.7696\tSigma2 Prior: -771.9391\tRegularization: 0.0018\n",
      "Iter: 8240  \tTraining Loss: -690.4150    \n",
      "    Negative Log Likelihood: 86.0961\tSigma2 Prior: -776.5129\tRegularization: 0.0018\n",
      "Iter: 8250  \tTraining Loss: -688.0161    \n",
      "    Negative Log Likelihood: 89.6945\tSigma2 Prior: -777.7124\tRegularization: 0.0018\n",
      "Iter: 8260  \tTraining Loss: -687.5235    \n",
      "    Negative Log Likelihood: 90.6040\tSigma2 Prior: -778.1293\tRegularization: 0.0018\n",
      "Iter: 8270  \tTraining Loss: -688.5163    \n",
      "    Negative Log Likelihood: 86.5911\tSigma2 Prior: -775.1092\tRegularization: 0.0018\n",
      "Iter: 8280  \tTraining Loss: -688.1619    \n",
      "    Negative Log Likelihood: 87.7438\tSigma2 Prior: -775.9075\tRegularization: 0.0018\n",
      "Iter: 8290  \tTraining Loss: -689.2837    \n",
      "    Negative Log Likelihood: 86.2259\tSigma2 Prior: -775.5114\tRegularization: 0.0018\n",
      "Iter: 8300  \tTraining Loss: -688.3104    \n",
      "    Negative Log Likelihood: 89.2584\tSigma2 Prior: -777.5707\tRegularization: 0.0018\n",
      "Iter: 8310  \tTraining Loss: -688.4487    \n",
      "    Negative Log Likelihood: 87.8246\tSigma2 Prior: -776.2751\tRegularization: 0.0018\n",
      "Iter: 8320  \tTraining Loss: -688.4072    \n",
      "    Negative Log Likelihood: 88.4727\tSigma2 Prior: -776.8817\tRegularization: 0.0018\n",
      "Iter: 8330  \tTraining Loss: -687.9037    \n",
      "    Negative Log Likelihood: 89.4412\tSigma2 Prior: -777.3468\tRegularization: 0.0018\n",
      "Iter: 8340  \tTraining Loss: -687.4819    \n",
      "    Negative Log Likelihood: 88.4895\tSigma2 Prior: -775.9733\tRegularization: 0.0018\n",
      "Iter: 8350  \tTraining Loss: -688.2838    \n",
      "    Negative Log Likelihood: 88.3781\tSigma2 Prior: -776.6638\tRegularization: 0.0018\n",
      "Iter: 8360  \tTraining Loss: -688.1967    \n",
      "    Negative Log Likelihood: 90.0611\tSigma2 Prior: -778.2596\tRegularization: 0.0018\n",
      "Iter: 8370  \tTraining Loss: -688.6227    \n",
      "    Negative Log Likelihood: 87.7076\tSigma2 Prior: -776.3322\tRegularization: 0.0018\n",
      "Iter: 8380  \tTraining Loss: -688.9359    \n",
      "    Negative Log Likelihood: 87.1870\tSigma2 Prior: -776.1247\tRegularization: 0.0018\n",
      "Iter: 8390  \tTraining Loss: -688.4651    \n",
      "    Negative Log Likelihood: 89.3446\tSigma2 Prior: -777.8116\tRegularization: 0.0018\n",
      "Iter: 8400  \tTraining Loss: -688.6588    \n",
      "    Negative Log Likelihood: 89.8787\tSigma2 Prior: -778.5394\tRegularization: 0.0018\n",
      "Iter: 8410  \tTraining Loss: -687.1324    \n",
      "    Negative Log Likelihood: 89.9551\tSigma2 Prior: -777.0893\tRegularization: 0.0018\n",
      "Iter: 8420  \tTraining Loss: -689.4260    \n",
      "    Negative Log Likelihood: 85.8226\tSigma2 Prior: -775.2505\tRegularization: 0.0018\n",
      "Iter: 8430  \tTraining Loss: -689.4032    \n",
      "    Negative Log Likelihood: 86.0517\tSigma2 Prior: -775.4567\tRegularization: 0.0018\n",
      "Iter: 8440  \tTraining Loss: -690.3053    \n",
      "    Negative Log Likelihood: 86.9401\tSigma2 Prior: -777.2472\tRegularization: 0.0018\n",
      "Iter: 8450  \tTraining Loss: -690.2407    \n",
      "    Negative Log Likelihood: 89.0022\tSigma2 Prior: -779.2447\tRegularization: 0.0018\n",
      "Iter: 8460  \tTraining Loss: -690.3741    \n",
      "    Negative Log Likelihood: 85.0913\tSigma2 Prior: -775.4673\tRegularization: 0.0018\n",
      "Iter: 8470  \tTraining Loss: -691.9033    \n",
      "    Negative Log Likelihood: 89.6263\tSigma2 Prior: -781.5314\tRegularization: 0.0018\n",
      "Iter: 8480  \tTraining Loss: -692.1127    \n",
      "    Negative Log Likelihood: 87.9188\tSigma2 Prior: -780.0333\tRegularization: 0.0018\n",
      "Iter: 8490  \tTraining Loss: -692.6027    \n",
      "    Negative Log Likelihood: 87.5108\tSigma2 Prior: -780.1154\tRegularization: 0.0018\n",
      "Iter: 8500  \tTraining Loss: -686.4838    \n",
      "    Negative Log Likelihood: 90.8936\tSigma2 Prior: -777.3793\tRegularization: 0.0018\n",
      "Iter: 8510  \tTraining Loss: -687.5107    \n",
      "    Negative Log Likelihood: 82.0299\tSigma2 Prior: -769.5424\tRegularization: 0.0018\n",
      "Iter: 8520  \tTraining Loss: -684.0378    \n",
      "    Negative Log Likelihood: 85.9813\tSigma2 Prior: -770.0209\tRegularization: 0.0018\n",
      "Iter: 8530  \tTraining Loss: -684.5951    \n",
      "    Negative Log Likelihood: 88.4605\tSigma2 Prior: -773.0574\tRegularization: 0.0018\n",
      "Iter: 8540  \tTraining Loss: -684.4605    \n",
      "    Negative Log Likelihood: 91.9908\tSigma2 Prior: -776.4532\tRegularization: 0.0018\n",
      "Iter: 8550  \tTraining Loss: -685.7687    \n",
      "    Negative Log Likelihood: 90.6758\tSigma2 Prior: -776.4464\tRegularization: 0.0018\n",
      "Iter: 8560  \tTraining Loss: -686.5720    \n",
      "    Negative Log Likelihood: 87.0649\tSigma2 Prior: -773.6387\tRegularization: 0.0018\n",
      "Iter: 8570  \tTraining Loss: -686.8563    \n",
      "    Negative Log Likelihood: 87.8747\tSigma2 Prior: -774.7328\tRegularization: 0.0018\n",
      "Iter: 8580  \tTraining Loss: -686.2825    \n",
      "    Negative Log Likelihood: 87.8557\tSigma2 Prior: -774.1401\tRegularization: 0.0018\n",
      "Iter: 8590  \tTraining Loss: -686.9594    \n",
      "    Negative Log Likelihood: 86.6193\tSigma2 Prior: -773.5805\tRegularization: 0.0018\n",
      "Iter: 8600  \tTraining Loss: -687.9407    \n",
      "    Negative Log Likelihood: 86.6917\tSigma2 Prior: -774.6343\tRegularization: 0.0018\n",
      "Iter: 8610  \tTraining Loss: -687.3022    \n",
      "    Negative Log Likelihood: 91.4253\tSigma2 Prior: -778.7294\tRegularization: 0.0018\n",
      "Iter: 8620  \tTraining Loss: -685.9264    \n",
      "    Negative Log Likelihood: 88.6345\tSigma2 Prior: -774.5627\tRegularization: 0.0018\n",
      "Iter: 8630  \tTraining Loss: -689.0912    \n",
      "    Negative Log Likelihood: 81.4474\tSigma2 Prior: -770.5404\tRegularization: 0.0018\n",
      "Iter: 8640  \tTraining Loss: -688.8608    \n",
      "    Negative Log Likelihood: 92.1805\tSigma2 Prior: -781.0431\tRegularization: 0.0018\n",
      "Iter: 8650  \tTraining Loss: -688.2728    \n",
      "    Negative Log Likelihood: 83.8109\tSigma2 Prior: -772.0855\tRegularization: 0.0018\n",
      "Iter: 8660  \tTraining Loss: -685.4909    \n",
      "    Negative Log Likelihood: 79.1204\tSigma2 Prior: -764.6132\tRegularization: 0.0018\n",
      "Iter: 8670  \tTraining Loss: -683.1696    \n",
      "    Negative Log Likelihood: 91.9191\tSigma2 Prior: -775.0905\tRegularization: 0.0018\n",
      "Iter: 8680  \tTraining Loss: -686.0732    \n",
      "    Negative Log Likelihood: 84.3939\tSigma2 Prior: -770.4690\tRegularization: 0.0018\n",
      "Iter: 8690  \tTraining Loss: -686.0560    \n",
      "    Negative Log Likelihood: 83.8464\tSigma2 Prior: -769.9043\tRegularization: 0.0018\n",
      "Iter: 8700  \tTraining Loss: -684.0438    \n",
      "    Negative Log Likelihood: 84.3164\tSigma2 Prior: -768.3619\tRegularization: 0.0018\n",
      "Iter: 8710  \tTraining Loss: -684.3768    \n",
      "    Negative Log Likelihood: 84.9073\tSigma2 Prior: -769.2859\tRegularization: 0.0018\n",
      "Iter: 8720  \tTraining Loss: -684.0576    \n",
      "    Negative Log Likelihood: 86.1495\tSigma2 Prior: -770.2090\tRegularization: 0.0018\n",
      "Iter: 8730  \tTraining Loss: -684.5754    \n",
      "    Negative Log Likelihood: 82.4905\tSigma2 Prior: -767.0677\tRegularization: 0.0018\n",
      "Iter: 8740  \tTraining Loss: -685.4112    \n",
      "    Negative Log Likelihood: 84.0560\tSigma2 Prior: -769.4691\tRegularization: 0.0018\n",
      "Iter: 8750  \tTraining Loss: -685.6660    \n",
      "    Negative Log Likelihood: 87.5713\tSigma2 Prior: -773.2391\tRegularization: 0.0018\n",
      "Iter: 8760  \tTraining Loss: -685.5952    \n",
      "    Negative Log Likelihood: 83.5923\tSigma2 Prior: -769.1893\tRegularization: 0.0018\n",
      "Iter: 8770  \tTraining Loss: -685.5449    \n",
      "    Negative Log Likelihood: 84.9037\tSigma2 Prior: -770.4504\tRegularization: 0.0018\n",
      "Iter: 8780  \tTraining Loss: -685.8149    \n",
      "    Negative Log Likelihood: 84.1627\tSigma2 Prior: -769.9795\tRegularization: 0.0018\n",
      "Iter: 8790  \tTraining Loss: -687.9880    \n",
      "    Negative Log Likelihood: 84.0985\tSigma2 Prior: -772.0884\tRegularization: 0.0018\n",
      "Iter: 8800  \tTraining Loss: -687.3024    \n",
      "    Negative Log Likelihood: 85.4050\tSigma2 Prior: -772.7092\tRegularization: 0.0018\n",
      "Iter: 8810  \tTraining Loss: -690.0995    \n",
      "    Negative Log Likelihood: 82.5623\tSigma2 Prior: -772.6636\tRegularization: 0.0018\n",
      "Iter: 8820  \tTraining Loss: -683.1646    \n",
      "    Negative Log Likelihood: 90.4566\tSigma2 Prior: -773.6230\tRegularization: 0.0018\n",
      "Iter: 8830  \tTraining Loss: -687.4668    \n",
      "    Negative Log Likelihood: 85.6293\tSigma2 Prior: -773.0979\tRegularization: 0.0018\n",
      "Iter: 8840  \tTraining Loss: -689.3715    \n",
      "    Negative Log Likelihood: 85.9070\tSigma2 Prior: -775.2804\tRegularization: 0.0018\n",
      "Iter: 8850  \tTraining Loss: -687.4944    \n",
      "    Negative Log Likelihood: 82.1690\tSigma2 Prior: -769.6652\tRegularization: 0.0018\n",
      "Iter: 8860  \tTraining Loss: -690.4772    \n",
      "    Negative Log Likelihood: 86.7009\tSigma2 Prior: -777.1799\tRegularization: 0.0018\n",
      "Iter: 8870  \tTraining Loss: -689.1313    \n",
      "    Negative Log Likelihood: 84.9999\tSigma2 Prior: -774.1330\tRegularization: 0.0018\n",
      "Iter: 8880  \tTraining Loss: -688.4565    \n",
      "    Negative Log Likelihood: 86.6621\tSigma2 Prior: -775.1205\tRegularization: 0.0018\n",
      "Iter: 8890  \tTraining Loss: -686.1047    \n",
      "    Negative Log Likelihood: 85.9917\tSigma2 Prior: -772.0983\tRegularization: 0.0018\n",
      "Iter: 8900  \tTraining Loss: -687.6487    \n",
      "    Negative Log Likelihood: 88.9664\tSigma2 Prior: -776.6169\tRegularization: 0.0018\n",
      "Iter: 8910  \tTraining Loss: -687.6651    \n",
      "    Negative Log Likelihood: 89.3342\tSigma2 Prior: -777.0012\tRegularization: 0.0018\n",
      "Iter: 8920  \tTraining Loss: -688.3482    \n",
      "    Negative Log Likelihood: 84.7977\tSigma2 Prior: -773.1477\tRegularization: 0.0018\n",
      "Iter: 8930  \tTraining Loss: -689.0326    \n",
      "    Negative Log Likelihood: 86.5894\tSigma2 Prior: -775.6238\tRegularization: 0.0018\n",
      "Iter: 8940  \tTraining Loss: -689.6337    \n",
      "    Negative Log Likelihood: 87.9607\tSigma2 Prior: -777.5962\tRegularization: 0.0018\n",
      "Iter: 8950  \tTraining Loss: -689.4774    \n",
      "    Negative Log Likelihood: 86.5800\tSigma2 Prior: -776.0593\tRegularization: 0.0018\n",
      "Iter: 8960  \tTraining Loss: -689.5714    \n",
      "    Negative Log Likelihood: 86.1580\tSigma2 Prior: -775.7312\tRegularization: 0.0018\n",
      "Iter: 8970  \tTraining Loss: -689.9606    \n",
      "    Negative Log Likelihood: 86.3207\tSigma2 Prior: -776.2831\tRegularization: 0.0018\n",
      "Iter: 8980  \tTraining Loss: -690.5125    \n",
      "    Negative Log Likelihood: 86.2858\tSigma2 Prior: -776.8001\tRegularization: 0.0018\n",
      "Iter: 8990  \tTraining Loss: -690.2075    \n",
      "    Negative Log Likelihood: 87.0341\tSigma2 Prior: -777.2434\tRegularization: 0.0018\n",
      "Iter: 9000  \tTraining Loss: -689.9329    \n",
      "    Negative Log Likelihood: 86.1956\tSigma2 Prior: -776.1303\tRegularization: 0.0018\n",
      "Iter: 9010  \tTraining Loss: -690.3402    \n",
      "    Negative Log Likelihood: 86.3819\tSigma2 Prior: -776.7240\tRegularization: 0.0018\n",
      "Iter: 9020  \tTraining Loss: -690.3718    \n",
      "    Negative Log Likelihood: 87.0180\tSigma2 Prior: -777.3917\tRegularization: 0.0018\n",
      "Iter: 9030  \tTraining Loss: -691.4629    \n",
      "    Negative Log Likelihood: 85.2287\tSigma2 Prior: -776.6934\tRegularization: 0.0018\n",
      "Iter: 9040  \tTraining Loss: -692.7042    \n",
      "    Negative Log Likelihood: 86.2574\tSigma2 Prior: -778.9634\tRegularization: 0.0018\n",
      "Iter: 9050  \tTraining Loss: -691.6807    \n",
      "    Negative Log Likelihood: 88.0158\tSigma2 Prior: -779.6984\tRegularization: 0.0018\n",
      "Iter: 9060  \tTraining Loss: -692.5549    \n",
      "    Negative Log Likelihood: 88.4076\tSigma2 Prior: -780.9644\tRegularization: 0.0018\n",
      "Iter: 9070  \tTraining Loss: -688.9482    \n",
      "    Negative Log Likelihood: 87.4799\tSigma2 Prior: -776.4299\tRegularization: 0.0018\n",
      "Iter: 9080  \tTraining Loss: -687.4389    \n",
      "    Negative Log Likelihood: 88.8820\tSigma2 Prior: -776.3228\tRegularization: 0.0018\n",
      "Iter: 9090  \tTraining Loss: -691.4807    \n",
      "    Negative Log Likelihood: 87.2660\tSigma2 Prior: -778.7485\tRegularization: 0.0018\n",
      "Iter: 9100  \tTraining Loss: -690.6289    \n",
      "    Negative Log Likelihood: 91.0025\tSigma2 Prior: -781.6332\tRegularization: 0.0018\n",
      "Iter: 9110  \tTraining Loss: -690.1794    \n",
      "    Negative Log Likelihood: 88.1942\tSigma2 Prior: -778.3755\tRegularization: 0.0018\n",
      "Iter: 9120  \tTraining Loss: -689.6758    \n",
      "    Negative Log Likelihood: 90.7112\tSigma2 Prior: -780.3889\tRegularization: 0.0018\n",
      "Iter: 9130  \tTraining Loss: -692.3312    \n",
      "    Negative Log Likelihood: 86.1850\tSigma2 Prior: -778.5181\tRegularization: 0.0018\n",
      "Iter: 9140  \tTraining Loss: -692.5974    \n",
      "    Negative Log Likelihood: 84.9681\tSigma2 Prior: -777.5673\tRegularization: 0.0018\n",
      "Iter: 9150  \tTraining Loss: -688.5666    \n",
      "    Negative Log Likelihood: 88.7934\tSigma2 Prior: -777.3618\tRegularization: 0.0018\n",
      "Iter: 9160  \tTraining Loss: -686.3058    \n",
      "    Negative Log Likelihood: 88.7903\tSigma2 Prior: -775.0979\tRegularization: 0.0018\n",
      "Iter: 9170  \tTraining Loss: -685.5966    \n",
      "    Negative Log Likelihood: 88.8950\tSigma2 Prior: -774.4934\tRegularization: 0.0018\n",
      "Iter: 9180  \tTraining Loss: -690.8854    \n",
      "    Negative Log Likelihood: 82.5256\tSigma2 Prior: -773.4128\tRegularization: 0.0018\n",
      "Iter: 9190  \tTraining Loss: -688.1011    \n",
      "    Negative Log Likelihood: 86.7441\tSigma2 Prior: -774.8471\tRegularization: 0.0018\n",
      "Iter: 9200  \tTraining Loss: -687.0787    \n",
      "    Negative Log Likelihood: 84.3874\tSigma2 Prior: -771.4680\tRegularization: 0.0018\n",
      "Iter: 9210  \tTraining Loss: -689.2365    \n",
      "    Negative Log Likelihood: 85.5352\tSigma2 Prior: -774.7735\tRegularization: 0.0018\n",
      "Iter: 9220  \tTraining Loss: -691.0258    \n",
      "    Negative Log Likelihood: 86.3633\tSigma2 Prior: -777.3909\tRegularization: 0.0018\n",
      "Iter: 9230  \tTraining Loss: -690.6854    \n",
      "    Negative Log Likelihood: 87.0521\tSigma2 Prior: -777.7393\tRegularization: 0.0018\n",
      "Iter: 9240  \tTraining Loss: -690.5005    \n",
      "    Negative Log Likelihood: 86.0152\tSigma2 Prior: -776.5175\tRegularization: 0.0018\n",
      "Iter: 9250  \tTraining Loss: -690.7581    \n",
      "    Negative Log Likelihood: 85.7446\tSigma2 Prior: -776.5045\tRegularization: 0.0018\n",
      "Iter: 9260  \tTraining Loss: -690.6203    \n",
      "    Negative Log Likelihood: 86.9441\tSigma2 Prior: -777.5662\tRegularization: 0.0018\n",
      "Iter: 9270  \tTraining Loss: -690.7654    \n",
      "    Negative Log Likelihood: 87.4597\tSigma2 Prior: -778.2270\tRegularization: 0.0018\n",
      "Iter: 9280  \tTraining Loss: -691.2321    \n",
      "    Negative Log Likelihood: 87.0818\tSigma2 Prior: -778.3157\tRegularization: 0.0018\n",
      "Iter: 9290  \tTraining Loss: -691.8193    \n",
      "    Negative Log Likelihood: 86.0046\tSigma2 Prior: -777.8257\tRegularization: 0.0018\n",
      "Iter: 9300  \tTraining Loss: -691.2849    \n",
      "    Negative Log Likelihood: 86.7766\tSigma2 Prior: -778.0633\tRegularization: 0.0018\n",
      "Iter: 9310  \tTraining Loss: -691.6615    \n",
      "    Negative Log Likelihood: 86.7018\tSigma2 Prior: -778.3651\tRegularization: 0.0018\n",
      "Iter: 9320  \tTraining Loss: -692.2341    \n",
      "    Negative Log Likelihood: 85.8063\tSigma2 Prior: -778.0422\tRegularization: 0.0018\n",
      "Iter: 9330  \tTraining Loss: -693.1804    \n",
      "    Negative Log Likelihood: 87.4038\tSigma2 Prior: -780.5861\tRegularization: 0.0018\n",
      "Iter: 9340  \tTraining Loss: -691.6006    \n",
      "    Negative Log Likelihood: 89.5275\tSigma2 Prior: -781.1299\tRegularization: 0.0018\n",
      "Iter: 9350  \tTraining Loss: -693.8800    \n",
      "    Negative Log Likelihood: 86.4531\tSigma2 Prior: -780.3349\tRegularization: 0.0018\n",
      "Iter: 9360  \tTraining Loss: -689.9441    \n",
      "    Negative Log Likelihood: 90.8885\tSigma2 Prior: -780.8345\tRegularization: 0.0018\n",
      "Iter: 9370  \tTraining Loss: -692.5203    \n",
      "    Negative Log Likelihood: 87.2778\tSigma2 Prior: -779.8000\tRegularization: 0.0018\n",
      "Iter: 9380  \tTraining Loss: -693.4510    \n",
      "    Negative Log Likelihood: 89.8873\tSigma2 Prior: -783.3401\tRegularization: 0.0018\n",
      "Iter: 9390  \tTraining Loss: -692.2396    \n",
      "    Negative Log Likelihood: 82.2236\tSigma2 Prior: -774.4650\tRegularization: 0.0018\n",
      "Iter: 9400  \tTraining Loss: -693.4156    \n",
      "    Negative Log Likelihood: 86.0269\tSigma2 Prior: -779.4444\tRegularization: 0.0018\n",
      "Iter: 9410  \tTraining Loss: -691.8145    \n",
      "    Negative Log Likelihood: 86.9570\tSigma2 Prior: -778.7733\tRegularization: 0.0019\n",
      "Iter: 9420  \tTraining Loss: -692.9767    \n",
      "    Negative Log Likelihood: 85.2969\tSigma2 Prior: -778.2754\tRegularization: 0.0019\n",
      "Iter: 9430  \tTraining Loss: -691.8100    \n",
      "    Negative Log Likelihood: 85.2885\tSigma2 Prior: -777.1003\tRegularization: 0.0019\n",
      "Iter: 9440  \tTraining Loss: -689.6659    \n",
      "    Negative Log Likelihood: 87.0392\tSigma2 Prior: -776.7070\tRegularization: 0.0019\n",
      "Iter: 9450  \tTraining Loss: -690.7307    \n",
      "    Negative Log Likelihood: 88.3062\tSigma2 Prior: -779.0388\tRegularization: 0.0019\n",
      "Iter: 9460  \tTraining Loss: -685.2816    \n",
      "    Negative Log Likelihood: 81.4107\tSigma2 Prior: -766.6941\tRegularization: 0.0019\n",
      "Iter: 9470  \tTraining Loss: -687.9211    \n",
      "    Negative Log Likelihood: 89.0301\tSigma2 Prior: -776.9531\tRegularization: 0.0019\n",
      "Iter: 9480  \tTraining Loss: -687.6865    \n",
      "    Negative Log Likelihood: 88.6921\tSigma2 Prior: -776.3804\tRegularization: 0.0019\n",
      "Iter: 9490  \tTraining Loss: -687.1685    \n",
      "    Negative Log Likelihood: 82.9351\tSigma2 Prior: -770.1053\tRegularization: 0.0019\n",
      "Iter: 9500  \tTraining Loss: -687.5654    \n",
      "    Negative Log Likelihood: 83.8004\tSigma2 Prior: -771.3676\tRegularization: 0.0019\n",
      "Iter: 9510  \tTraining Loss: -688.0797    \n",
      "    Negative Log Likelihood: 84.6713\tSigma2 Prior: -772.7527\tRegularization: 0.0019\n",
      "Iter: 9520  \tTraining Loss: -688.3316    \n",
      "    Negative Log Likelihood: 85.0135\tSigma2 Prior: -773.3469\tRegularization: 0.0019\n",
      "Iter: 9530  \tTraining Loss: -687.9398    \n",
      "    Negative Log Likelihood: 84.6828\tSigma2 Prior: -772.6245\tRegularization: 0.0019\n",
      "Iter: 9540  \tTraining Loss: -687.0872    \n",
      "    Negative Log Likelihood: 83.6974\tSigma2 Prior: -770.7864\tRegularization: 0.0019\n",
      "Iter: 9550  \tTraining Loss: -687.4968    \n",
      "    Negative Log Likelihood: 81.5074\tSigma2 Prior: -769.0060\tRegularization: 0.0019\n",
      "Iter: 9560  \tTraining Loss: -686.7767    \n",
      "    Negative Log Likelihood: 88.1484\tSigma2 Prior: -774.9269\tRegularization: 0.0019\n",
      "Iter: 9570  \tTraining Loss: -686.3779    \n",
      "    Negative Log Likelihood: 87.8886\tSigma2 Prior: -774.2684\tRegularization: 0.0019\n",
      "Iter: 9580  \tTraining Loss: -685.1956    \n",
      "    Negative Log Likelihood: 87.6170\tSigma2 Prior: -772.8144\tRegularization: 0.0019\n",
      "Iter: 9590  \tTraining Loss: -687.2923    \n",
      "    Negative Log Likelihood: 85.9893\tSigma2 Prior: -773.2834\tRegularization: 0.0019\n",
      "Iter: 9600  \tTraining Loss: -689.4086    \n",
      "    Negative Log Likelihood: 85.6321\tSigma2 Prior: -775.0425\tRegularization: 0.0019\n",
      "Iter: 9610  \tTraining Loss: -685.1914    \n",
      "    Negative Log Likelihood: 89.9728\tSigma2 Prior: -775.1660\tRegularization: 0.0019\n",
      "Iter: 9620  \tTraining Loss: -687.5897    \n",
      "    Negative Log Likelihood: 83.4086\tSigma2 Prior: -771.0001\tRegularization: 0.0019\n",
      "Iter: 9630  \tTraining Loss: -689.5887    \n",
      "    Negative Log Likelihood: 84.3066\tSigma2 Prior: -773.8972\tRegularization: 0.0019\n",
      "Iter: 9640  \tTraining Loss: -691.9681    \n",
      "    Negative Log Likelihood: 84.0194\tSigma2 Prior: -775.9893\tRegularization: 0.0019\n",
      "Iter: 9650  \tTraining Loss: -693.6736    \n",
      "    Negative Log Likelihood: 86.5894\tSigma2 Prior: -780.2648\tRegularization: 0.0019\n",
      "Iter: 9660  \tTraining Loss: -690.3543    \n",
      "    Negative Log Likelihood: 85.8071\tSigma2 Prior: -776.1633\tRegularization: 0.0019\n",
      "Iter: 9670  \tTraining Loss: -693.0488    \n",
      "    Negative Log Likelihood: 84.7378\tSigma2 Prior: -777.7884\tRegularization: 0.0019\n",
      "Iter: 9680  \tTraining Loss: -686.0186    \n",
      "    Negative Log Likelihood: 84.4942\tSigma2 Prior: -770.5146\tRegularization: 0.0019\n",
      "Iter: 9690  \tTraining Loss: -689.2301    \n",
      "    Negative Log Likelihood: 83.1113\tSigma2 Prior: -772.3433\tRegularization: 0.0019\n",
      "Iter: 9700  \tTraining Loss: -686.9887    \n",
      "    Negative Log Likelihood: 88.5813\tSigma2 Prior: -775.5719\tRegularization: 0.0019\n",
      "Iter: 9710  \tTraining Loss: -687.7965    \n",
      "    Negative Log Likelihood: 88.4307\tSigma2 Prior: -776.2291\tRegularization: 0.0019\n",
      "Iter: 9720  \tTraining Loss: -690.1548    \n",
      "    Negative Log Likelihood: 83.7539\tSigma2 Prior: -773.9106\tRegularization: 0.0019\n",
      "Iter: 9730  \tTraining Loss: -689.6328    \n",
      "    Negative Log Likelihood: 87.9264\tSigma2 Prior: -777.5611\tRegularization: 0.0019\n",
      "Iter: 9740  \tTraining Loss: -689.8543    \n",
      "    Negative Log Likelihood: 88.1170\tSigma2 Prior: -777.9731\tRegularization: 0.0019\n",
      "Iter: 9750  \tTraining Loss: -690.3681    \n",
      "    Negative Log Likelihood: 87.3631\tSigma2 Prior: -777.7330\tRegularization: 0.0019\n",
      "Iter: 9760  \tTraining Loss: -690.2046    \n",
      "    Negative Log Likelihood: 89.1496\tSigma2 Prior: -779.3561\tRegularization: 0.0019\n",
      "Iter: 9770  \tTraining Loss: -690.9326    \n",
      "    Negative Log Likelihood: 86.0562\tSigma2 Prior: -776.9907\tRegularization: 0.0019\n",
      "Iter: 9780  \tTraining Loss: -690.7434    \n",
      "    Negative Log Likelihood: 85.5402\tSigma2 Prior: -776.2855\tRegularization: 0.0019\n",
      "Iter: 9790  \tTraining Loss: -689.1243    \n",
      "    Negative Log Likelihood: 90.9939\tSigma2 Prior: -780.1200\tRegularization: 0.0019\n",
      "Iter: 9800  \tTraining Loss: -690.2807    \n",
      "    Negative Log Likelihood: 84.5202\tSigma2 Prior: -774.8027\tRegularization: 0.0019\n",
      "Iter: 9810  \tTraining Loss: -688.3777    \n",
      "    Negative Log Likelihood: 87.1275\tSigma2 Prior: -775.5071\tRegularization: 0.0019\n",
      "Iter: 9820  \tTraining Loss: -689.7360    \n",
      "    Negative Log Likelihood: 86.4949\tSigma2 Prior: -776.2327\tRegularization: 0.0019\n",
      "Iter: 9830  \tTraining Loss: -688.0653    \n",
      "    Negative Log Likelihood: 88.9830\tSigma2 Prior: -777.0502\tRegularization: 0.0019\n",
      "Iter: 9840  \tTraining Loss: -688.0447    \n",
      "    Negative Log Likelihood: 88.4055\tSigma2 Prior: -776.4521\tRegularization: 0.0019\n",
      "Iter: 9850  \tTraining Loss: -688.3766    \n",
      "    Negative Log Likelihood: 84.3006\tSigma2 Prior: -772.6790\tRegularization: 0.0019\n",
      "Iter: 9860  \tTraining Loss: -689.2596    \n",
      "    Negative Log Likelihood: 81.9893\tSigma2 Prior: -771.2509\tRegularization: 0.0019\n",
      "Iter: 9870  \tTraining Loss: -689.1412    \n",
      "    Negative Log Likelihood: 82.5246\tSigma2 Prior: -771.6678\tRegularization: 0.0019\n",
      "Iter: 9880  \tTraining Loss: -691.3600    \n",
      "    Negative Log Likelihood: 84.8935\tSigma2 Prior: -776.2554\tRegularization: 0.0019\n",
      "Iter: 9890  \tTraining Loss: -683.1126    \n",
      "    Negative Log Likelihood: 82.6310\tSigma2 Prior: -765.7455\tRegularization: 0.0019\n",
      "Iter: 9900  \tTraining Loss: -686.9399    \n",
      "    Negative Log Likelihood: 83.8246\tSigma2 Prior: -770.7664\tRegularization: 0.0019\n",
      "Iter: 9910  \tTraining Loss: -687.1812    \n",
      "    Negative Log Likelihood: 90.7986\tSigma2 Prior: -777.9816\tRegularization: 0.0019\n",
      "Iter: 9920  \tTraining Loss: -688.0994    \n",
      "    Negative Log Likelihood: 85.0040\tSigma2 Prior: -773.1053\tRegularization: 0.0019\n",
      "Iter: 9930  \tTraining Loss: -687.3548    \n",
      "    Negative Log Likelihood: 84.9157\tSigma2 Prior: -772.2724\tRegularization: 0.0019\n",
      "Iter: 9940  \tTraining Loss: -688.5759    \n",
      "    Negative Log Likelihood: 86.5756\tSigma2 Prior: -775.1534\tRegularization: 0.0019\n",
      "Iter: 9950  \tTraining Loss: -688.0206    \n",
      "    Negative Log Likelihood: 87.4591\tSigma2 Prior: -775.4816\tRegularization: 0.0019\n",
      "Iter: 9960  \tTraining Loss: -689.6634    \n",
      "    Negative Log Likelihood: 83.5260\tSigma2 Prior: -773.1913\tRegularization: 0.0019\n",
      "Iter: 9970  \tTraining Loss: -688.9575    \n",
      "    Negative Log Likelihood: 87.2423\tSigma2 Prior: -776.2017\tRegularization: 0.0019\n",
      "Iter: 9980  \tTraining Loss: -688.9385    \n",
      "    Negative Log Likelihood: 85.3173\tSigma2 Prior: -774.2577\tRegularization: 0.0019\n",
      "Iter: 9990  \tTraining Loss: -689.3627    \n",
      "    Negative Log Likelihood: 86.2897\tSigma2 Prior: -775.6544\tRegularization: 0.0019\n",
      "Iter: 10000  \tTraining Loss: -689.7474    \n",
      "    Negative Log Likelihood: 87.4967\tSigma2 Prior: -777.2460\tRegularization: 0.0019\n",
      "Iter: 10010  \tTraining Loss: -688.7381    \n",
      "    Negative Log Likelihood: 89.9372\tSigma2 Prior: -778.6771\tRegularization: 0.0019\n",
      "Iter: 10020  \tTraining Loss: -689.5050    \n",
      "    Negative Log Likelihood: 89.5890\tSigma2 Prior: -779.0959\tRegularization: 0.0019\n",
      "Iter: 10030  \tTraining Loss: -694.2943    \n",
      "    Negative Log Likelihood: 86.5360\tSigma2 Prior: -780.8321\tRegularization: 0.0019\n",
      "Iter: 10040  \tTraining Loss: -693.1766    \n",
      "    Negative Log Likelihood: 82.0622\tSigma2 Prior: -775.2407\tRegularization: 0.0019\n",
      "Iter: 10050  \tTraining Loss: -688.2565    \n",
      "    Negative Log Likelihood: 83.5790\tSigma2 Prior: -771.8374\tRegularization: 0.0019\n",
      "Iter: 10060  \tTraining Loss: -688.8271    \n",
      "    Negative Log Likelihood: 89.9069\tSigma2 Prior: -778.7360\tRegularization: 0.0019\n",
      "Iter: 10070  \tTraining Loss: -688.9737    \n",
      "    Negative Log Likelihood: 82.9517\tSigma2 Prior: -771.9273\tRegularization: 0.0019\n",
      "Iter: 10080  \tTraining Loss: -688.4390    \n",
      "    Negative Log Likelihood: 82.6760\tSigma2 Prior: -771.1169\tRegularization: 0.0019\n",
      "Iter: 10090  \tTraining Loss: -688.2425    \n",
      "    Negative Log Likelihood: 85.7514\tSigma2 Prior: -773.9958\tRegularization: 0.0019\n",
      "Iter: 10100  \tTraining Loss: -688.3258    \n",
      "    Negative Log Likelihood: 89.1073\tSigma2 Prior: -777.4351\tRegularization: 0.0019\n",
      "Iter: 10110  \tTraining Loss: -685.7627    \n",
      "    Negative Log Likelihood: 93.7488\tSigma2 Prior: -779.5134\tRegularization: 0.0019\n",
      "Iter: 10120  \tTraining Loss: -690.2722    \n",
      "    Negative Log Likelihood: 82.3101\tSigma2 Prior: -772.5841\tRegularization: 0.0019\n",
      "Iter: 10130  \tTraining Loss: -690.9038    \n",
      "    Negative Log Likelihood: 83.1882\tSigma2 Prior: -774.0939\tRegularization: 0.0019\n",
      "Iter: 10140  \tTraining Loss: -691.4551    \n",
      "    Negative Log Likelihood: 88.0140\tSigma2 Prior: -779.4710\tRegularization: 0.0019\n",
      "Iter: 10150  \tTraining Loss: -691.4106    \n",
      "    Negative Log Likelihood: 86.7993\tSigma2 Prior: -778.2118\tRegularization: 0.0019\n",
      "Iter: 10160  \tTraining Loss: -691.7070    \n",
      "    Negative Log Likelihood: 85.7055\tSigma2 Prior: -777.4143\tRegularization: 0.0019\n",
      "Iter: 10170  \tTraining Loss: -690.4279    \n",
      "    Negative Log Likelihood: 88.0885\tSigma2 Prior: -778.5182\tRegularization: 0.0019\n",
      "Iter: 10180  \tTraining Loss: -692.0806    \n",
      "    Negative Log Likelihood: 87.4067\tSigma2 Prior: -779.4893\tRegularization: 0.0019\n",
      "Iter: 10190  \tTraining Loss: -693.6644    \n",
      "    Negative Log Likelihood: 84.1741\tSigma2 Prior: -777.8404\tRegularization: 0.0019\n",
      "Iter: 10200  \tTraining Loss: -694.6169    \n",
      "    Negative Log Likelihood: 88.4277\tSigma2 Prior: -783.0464\tRegularization: 0.0019\n",
      "Iter: 10210  \tTraining Loss: -696.4893    \n",
      "    Negative Log Likelihood: 88.8064\tSigma2 Prior: -785.2976\tRegularization: 0.0019\n",
      "Iter: 10220  \tTraining Loss: -696.6110    \n",
      "    Negative Log Likelihood: 88.0563\tSigma2 Prior: -784.6692\tRegularization: 0.0019\n",
      "Iter: 10230  \tTraining Loss: -698.3472    \n",
      "    Negative Log Likelihood: 86.9869\tSigma2 Prior: -785.3360\tRegularization: 0.0019\n",
      "Iter: 10240  \tTraining Loss: -694.2715    \n",
      "    Negative Log Likelihood: 86.9736\tSigma2 Prior: -781.2471\tRegularization: 0.0019\n",
      "Iter: 10250  \tTraining Loss: -696.5814    \n",
      "    Negative Log Likelihood: 89.9851\tSigma2 Prior: -786.5684\tRegularization: 0.0019\n",
      "Iter: 10260  \tTraining Loss: -696.0488    \n",
      "    Negative Log Likelihood: 86.8695\tSigma2 Prior: -782.9202\tRegularization: 0.0019\n",
      "Iter: 10270  \tTraining Loss: -693.2224    \n",
      "    Negative Log Likelihood: 84.2921\tSigma2 Prior: -777.5163\tRegularization: 0.0019\n",
      "Iter: 10280  \tTraining Loss: -694.5617    \n",
      "    Negative Log Likelihood: 89.0761\tSigma2 Prior: -783.6396\tRegularization: 0.0019\n",
      "Iter: 10290  \tTraining Loss: -694.6318    \n",
      "    Negative Log Likelihood: 88.9556\tSigma2 Prior: -783.5892\tRegularization: 0.0019\n",
      "Iter: 10300  \tTraining Loss: -695.7515    \n",
      "    Negative Log Likelihood: 88.1535\tSigma2 Prior: -783.9069\tRegularization: 0.0019\n",
      "Iter: 10310  \tTraining Loss: -696.4280    \n",
      "    Negative Log Likelihood: 87.0724\tSigma2 Prior: -783.5024\tRegularization: 0.0019\n",
      "Iter: 10320  \tTraining Loss: -694.8027    \n",
      "    Negative Log Likelihood: 88.6111\tSigma2 Prior: -783.4157\tRegularization: 0.0019\n",
      "Iter: 10330  \tTraining Loss: -696.8419    \n",
      "    Negative Log Likelihood: 86.0238\tSigma2 Prior: -782.8676\tRegularization: 0.0019\n",
      "Iter: 10340  \tTraining Loss: -698.3568    \n",
      "    Negative Log Likelihood: 87.5669\tSigma2 Prior: -785.9257\tRegularization: 0.0019\n",
      "Iter: 10350  \tTraining Loss: -699.2057    \n",
      "    Negative Log Likelihood: 85.2451\tSigma2 Prior: -784.4527\tRegularization: 0.0019\n",
      "Iter: 10360  \tTraining Loss: -692.7255    \n",
      "    Negative Log Likelihood: 86.7502\tSigma2 Prior: -779.4777\tRegularization: 0.0019\n",
      "Iter: 10370  \tTraining Loss: -696.1784    \n",
      "    Negative Log Likelihood: 86.5718\tSigma2 Prior: -782.7521\tRegularization: 0.0019\n",
      "Iter: 10380  \tTraining Loss: -695.8433    \n",
      "    Negative Log Likelihood: 86.2623\tSigma2 Prior: -782.1075\tRegularization: 0.0019\n",
      "Iter: 10390  \tTraining Loss: -698.3948    \n",
      "    Negative Log Likelihood: 85.3268\tSigma2 Prior: -783.7236\tRegularization: 0.0019\n",
      "Iter: 10400  \tTraining Loss: -692.8424    \n",
      "    Negative Log Likelihood: 87.5800\tSigma2 Prior: -780.4243\tRegularization: 0.0019\n",
      "Iter: 10410  \tTraining Loss: -688.3880    \n",
      "    Negative Log Likelihood: 89.9076\tSigma2 Prior: -778.2975\tRegularization: 0.0019\n",
      "Iter: 10420  \tTraining Loss: -691.3940    \n",
      "    Negative Log Likelihood: 87.6426\tSigma2 Prior: -779.0386\tRegularization: 0.0019\n",
      "Iter: 10430  \tTraining Loss: -691.4673    \n",
      "    Negative Log Likelihood: 82.3049\tSigma2 Prior: -773.7741\tRegularization: 0.0019\n",
      "Iter: 10440  \tTraining Loss: -687.3892    \n",
      "    Negative Log Likelihood: 87.3252\tSigma2 Prior: -774.7163\tRegularization: 0.0019\n",
      "Iter: 10450  \tTraining Loss: -693.5834    \n",
      "    Negative Log Likelihood: 81.2070\tSigma2 Prior: -774.7924\tRegularization: 0.0019\n",
      "Iter: 10460  \tTraining Loss: -693.1152    \n",
      "    Negative Log Likelihood: 85.5351\tSigma2 Prior: -778.6523\tRegularization: 0.0019\n",
      "Iter: 10470  \tTraining Loss: -693.2961    \n",
      "    Negative Log Likelihood: 86.5618\tSigma2 Prior: -779.8598\tRegularization: 0.0019\n",
      "Iter: 10480  \tTraining Loss: -693.4337    \n",
      "    Negative Log Likelihood: 87.7227\tSigma2 Prior: -781.1583\tRegularization: 0.0019\n",
      "Iter: 10490  \tTraining Loss: -693.8058    \n",
      "    Negative Log Likelihood: 86.4306\tSigma2 Prior: -780.2384\tRegularization: 0.0019\n",
      "Iter: 10500  \tTraining Loss: -694.8306    \n",
      "    Negative Log Likelihood: 86.7301\tSigma2 Prior: -781.5626\tRegularization: 0.0019\n",
      "Iter: 10510  \tTraining Loss: -696.1508    \n",
      "    Negative Log Likelihood: 85.0308\tSigma2 Prior: -781.1835\tRegularization: 0.0019\n",
      "Iter: 10520  \tTraining Loss: -695.2340    \n",
      "    Negative Log Likelihood: 86.7721\tSigma2 Prior: -782.0081\tRegularization: 0.0019\n",
      "Iter: 10530  \tTraining Loss: -696.4630    \n",
      "    Negative Log Likelihood: 84.9830\tSigma2 Prior: -781.4478\tRegularization: 0.0019\n",
      "Iter: 10540  \tTraining Loss: -696.9222    \n",
      "    Negative Log Likelihood: 85.0227\tSigma2 Prior: -781.9468\tRegularization: 0.0019\n",
      "Iter: 10550  \tTraining Loss: -696.5056    \n",
      "    Negative Log Likelihood: 85.8220\tSigma2 Prior: -782.3294\tRegularization: 0.0019\n",
      "Iter: 10560  \tTraining Loss: -697.4108    \n",
      "    Negative Log Likelihood: 83.6480\tSigma2 Prior: -781.0607\tRegularization: 0.0019\n",
      "Iter: 10570  \tTraining Loss: -697.9219    \n",
      "    Negative Log Likelihood: 85.6936\tSigma2 Prior: -783.6174\tRegularization: 0.0019\n",
      "Iter: 10580  \tTraining Loss: -697.8846    \n",
      "    Negative Log Likelihood: 86.8529\tSigma2 Prior: -784.7394\tRegularization: 0.0019\n",
      "Iter: 10590  \tTraining Loss: -698.6201    \n",
      "    Negative Log Likelihood: 86.3879\tSigma2 Prior: -785.0098\tRegularization: 0.0019\n",
      "Iter: 10600  \tTraining Loss: -698.9678    \n",
      "    Negative Log Likelihood: 79.1808\tSigma2 Prior: -778.1506\tRegularization: 0.0019\n",
      "Iter: 10610  \tTraining Loss: -696.8230    \n",
      "    Negative Log Likelihood: 89.0295\tSigma2 Prior: -785.8544\tRegularization: 0.0019\n",
      "Iter: 10620  \tTraining Loss: -699.4802    \n",
      "    Negative Log Likelihood: 89.6019\tSigma2 Prior: -789.0840\tRegularization: 0.0019\n",
      "Iter: 10630  \tTraining Loss: -697.8096    \n",
      "    Negative Log Likelihood: 84.4821\tSigma2 Prior: -782.2936\tRegularization: 0.0019\n",
      "Iter: 10640  \tTraining Loss: -702.6923    \n",
      "    Negative Log Likelihood: 86.5873\tSigma2 Prior: -789.2815\tRegularization: 0.0019\n",
      "Iter: 10650  \tTraining Loss: -703.0270    \n",
      "    Negative Log Likelihood: 88.7739\tSigma2 Prior: -791.8028\tRegularization: 0.0019\n",
      "Iter: 10660  \tTraining Loss: -702.0673    \n",
      "    Negative Log Likelihood: 89.6757\tSigma2 Prior: -791.7449\tRegularization: 0.0019\n",
      "Iter: 10670  \tTraining Loss: -704.6284    \n",
      "    Negative Log Likelihood: 89.5817\tSigma2 Prior: -794.2120\tRegularization: 0.0019\n",
      "Iter: 10680  \tTraining Loss: -705.0894    \n",
      "    Negative Log Likelihood: 87.0758\tSigma2 Prior: -792.1671\tRegularization: 0.0019\n",
      "Iter: 10690  \tTraining Loss: -705.0289    \n",
      "    Negative Log Likelihood: 89.7672\tSigma2 Prior: -794.7980\tRegularization: 0.0019\n",
      "Iter: 10700  \tTraining Loss: -704.7317    \n",
      "    Negative Log Likelihood: 88.8008\tSigma2 Prior: -793.5344\tRegularization: 0.0019\n",
      "Iter: 10710  \tTraining Loss: -701.2957    \n",
      "    Negative Log Likelihood: 93.4596\tSigma2 Prior: -794.7572\tRegularization: 0.0019\n",
      "Iter: 10720  \tTraining Loss: -703.3355    \n",
      "    Negative Log Likelihood: 88.8887\tSigma2 Prior: -792.2261\tRegularization: 0.0019\n",
      "Iter: 10730  \tTraining Loss: -704.1133    \n",
      "    Negative Log Likelihood: 88.7789\tSigma2 Prior: -792.8940\tRegularization: 0.0019\n",
      "Iter: 10740  \tTraining Loss: -706.1119    \n",
      "    Negative Log Likelihood: 88.5459\tSigma2 Prior: -794.6597\tRegularization: 0.0019\n",
      "Iter: 10750  \tTraining Loss: -702.7780    \n",
      "    Negative Log Likelihood: 88.9122\tSigma2 Prior: -791.6921\tRegularization: 0.0019\n",
      "Iter: 10760  \tTraining Loss: -705.2068    \n",
      "    Negative Log Likelihood: 89.5006\tSigma2 Prior: -794.7094\tRegularization: 0.0019\n",
      "Iter: 10770  \tTraining Loss: -706.9453    \n",
      "    Negative Log Likelihood: 87.7955\tSigma2 Prior: -794.7427\tRegularization: 0.0019\n",
      "Iter: 10780  \tTraining Loss: -706.9257    \n",
      "    Negative Log Likelihood: 89.0513\tSigma2 Prior: -795.9789\tRegularization: 0.0019\n",
      "Iter: 10790  \tTraining Loss: -707.1505    \n",
      "    Negative Log Likelihood: 90.0338\tSigma2 Prior: -797.1862\tRegularization: 0.0019\n",
      "Iter: 10800  \tTraining Loss: -705.9786    \n",
      "    Negative Log Likelihood: 89.0878\tSigma2 Prior: -795.0684\tRegularization: 0.0019\n",
      "Iter: 10810  \tTraining Loss: -708.7043    \n",
      "    Negative Log Likelihood: 87.5629\tSigma2 Prior: -796.2691\tRegularization: 0.0019\n",
      "Iter: 10820  \tTraining Loss: -704.0980    \n",
      "    Negative Log Likelihood: 93.2785\tSigma2 Prior: -797.3784\tRegularization: 0.0019\n",
      "Iter: 10830  \tTraining Loss: -704.0710    \n",
      "    Negative Log Likelihood: 92.6219\tSigma2 Prior: -796.6948\tRegularization: 0.0019\n",
      "Iter: 10840  \tTraining Loss: -699.6948    \n",
      "    Negative Log Likelihood: 92.5681\tSigma2 Prior: -792.2647\tRegularization: 0.0019\n",
      "Iter: 10850  \tTraining Loss: -704.9960    \n",
      "    Negative Log Likelihood: 89.4008\tSigma2 Prior: -794.3987\tRegularization: 0.0019\n",
      "Iter: 10860  \tTraining Loss: -699.1304    \n",
      "    Negative Log Likelihood: 86.1259\tSigma2 Prior: -785.2582\tRegularization: 0.0019\n",
      "Iter: 10870  \tTraining Loss: -699.0701    \n",
      "    Negative Log Likelihood: 88.5784\tSigma2 Prior: -787.6503\tRegularization: 0.0019\n",
      "Iter: 10880  \tTraining Loss: -701.8381    \n",
      "    Negative Log Likelihood: 89.3499\tSigma2 Prior: -791.1899\tRegularization: 0.0019\n",
      "Iter: 10890  \tTraining Loss: -703.0038    \n",
      "    Negative Log Likelihood: 86.7036\tSigma2 Prior: -789.7094\tRegularization: 0.0019\n",
      "Iter: 10900  \tTraining Loss: -702.1377    \n",
      "    Negative Log Likelihood: 86.6730\tSigma2 Prior: -788.8126\tRegularization: 0.0019\n",
      "Iter: 10910  \tTraining Loss: -701.5215    \n",
      "    Negative Log Likelihood: 91.9600\tSigma2 Prior: -793.4833\tRegularization: 0.0019\n",
      "Iter: 10920  \tTraining Loss: -701.3350    \n",
      "    Negative Log Likelihood: 91.6051\tSigma2 Prior: -792.9420\tRegularization: 0.0019\n",
      "Iter: 10930  \tTraining Loss: -699.6937    \n",
      "    Negative Log Likelihood: 85.5955\tSigma2 Prior: -785.2910\tRegularization: 0.0019\n",
      "Iter: 10940  \tTraining Loss: -704.6470    \n",
      "    Negative Log Likelihood: 80.9767\tSigma2 Prior: -785.6256\tRegularization: 0.0019\n",
      "Iter: 10950  \tTraining Loss: -703.8255    \n",
      "    Negative Log Likelihood: 94.6217\tSigma2 Prior: -798.4492\tRegularization: 0.0019\n",
      "Iter: 10960  \tTraining Loss: -706.7700    \n",
      "    Negative Log Likelihood: 86.6831\tSigma2 Prior: -793.4550\tRegularization: 0.0019\n",
      "Iter: 10970  \tTraining Loss: -705.8924    \n",
      "    Negative Log Likelihood: 91.4245\tSigma2 Prior: -797.3188\tRegularization: 0.0019\n",
      "Iter: 10980  \tTraining Loss: -707.2005    \n",
      "    Negative Log Likelihood: 86.0607\tSigma2 Prior: -793.2631\tRegularization: 0.0019\n",
      "Iter: 10990  \tTraining Loss: -708.2249    \n",
      "    Negative Log Likelihood: 88.7622\tSigma2 Prior: -796.9890\tRegularization: 0.0019\n",
      "Iter: 11000  \tTraining Loss: -709.6572    \n",
      "    Negative Log Likelihood: 88.8329\tSigma2 Prior: -798.4920\tRegularization: 0.0019\n",
      "Iter: 11010  \tTraining Loss: -704.2957    \n",
      "    Negative Log Likelihood: 93.1306\tSigma2 Prior: -797.4282\tRegularization: 0.0019\n",
      "Iter: 11020  \tTraining Loss: -706.3562    \n",
      "    Negative Log Likelihood: 89.8283\tSigma2 Prior: -796.1865\tRegularization: 0.0019\n",
      "Iter: 11030  \tTraining Loss: -703.2603    \n",
      "    Negative Log Likelihood: 95.6469\tSigma2 Prior: -798.9091\tRegularization: 0.0019\n",
      "Iter: 11040  \tTraining Loss: -706.9976    \n",
      "    Negative Log Likelihood: 87.0836\tSigma2 Prior: -794.0831\tRegularization: 0.0019\n",
      "Iter: 11050  \tTraining Loss: -708.0391    \n",
      "    Negative Log Likelihood: 88.9084\tSigma2 Prior: -796.9495\tRegularization: 0.0019\n",
      "Iter: 11060  \tTraining Loss: -706.5812    \n",
      "    Negative Log Likelihood: 88.5567\tSigma2 Prior: -795.1398\tRegularization: 0.0019\n",
      "Iter: 11070  \tTraining Loss: -698.8248    \n",
      "    Negative Log Likelihood: 98.3922\tSigma2 Prior: -797.2189\tRegularization: 0.0019\n",
      "Iter: 11080  \tTraining Loss: -705.8919    \n",
      "    Negative Log Likelihood: 81.1899\tSigma2 Prior: -787.0837\tRegularization: 0.0019\n",
      "Iter: 11090  \tTraining Loss: -704.1044    \n",
      "    Negative Log Likelihood: 86.2176\tSigma2 Prior: -790.3239\tRegularization: 0.0019\n",
      "Iter: 11100  \tTraining Loss: -709.4305    \n",
      "    Negative Log Likelihood: 86.4495\tSigma2 Prior: -795.8820\tRegularization: 0.0019\n",
      "Iter: 11110  \tTraining Loss: -707.5877    \n",
      "    Negative Log Likelihood: 87.9692\tSigma2 Prior: -795.5588\tRegularization: 0.0019\n",
      "Iter: 11120  \tTraining Loss: -710.5185    \n",
      "    Negative Log Likelihood: 90.5363\tSigma2 Prior: -801.0567\tRegularization: 0.0019\n",
      "Iter: 11130  \tTraining Loss: -710.3432    \n",
      "    Negative Log Likelihood: 91.1734\tSigma2 Prior: -801.5185\tRegularization: 0.0019\n",
      "Iter: 11140  \tTraining Loss: -707.2973    \n",
      "    Negative Log Likelihood: 91.1646\tSigma2 Prior: -798.4637\tRegularization: 0.0019\n",
      "Iter: 11150  \tTraining Loss: -707.1480    \n",
      "    Negative Log Likelihood: 83.1619\tSigma2 Prior: -790.3118\tRegularization: 0.0019\n",
      "Iter: 11160  \tTraining Loss: -709.1877    \n",
      "    Negative Log Likelihood: 87.4603\tSigma2 Prior: -796.6499\tRegularization: 0.0019\n",
      "Iter: 11170  \tTraining Loss: -704.9311    \n",
      "    Negative Log Likelihood: 92.9365\tSigma2 Prior: -797.8694\tRegularization: 0.0019\n",
      "Iter: 11180  \tTraining Loss: -705.9231    \n",
      "    Negative Log Likelihood: 86.5670\tSigma2 Prior: -792.4919\tRegularization: 0.0019\n",
      "Iter: 11190  \tTraining Loss: -707.8140    \n",
      "    Negative Log Likelihood: 86.4642\tSigma2 Prior: -794.2802\tRegularization: 0.0019\n",
      "Iter: 11200  \tTraining Loss: -709.3879    \n",
      "    Negative Log Likelihood: 88.1763\tSigma2 Prior: -797.5660\tRegularization: 0.0019\n",
      "Iter: 11210  \tTraining Loss: -707.8525    \n",
      "    Negative Log Likelihood: 89.0174\tSigma2 Prior: -796.8718\tRegularization: 0.0019\n",
      "Iter: 11220  \tTraining Loss: -708.8027    \n",
      "    Negative Log Likelihood: 86.5935\tSigma2 Prior: -795.3981\tRegularization: 0.0019\n",
      "Iter: 11230  \tTraining Loss: -709.9295    \n",
      "    Negative Log Likelihood: 86.9968\tSigma2 Prior: -796.9283\tRegularization: 0.0019\n",
      "Iter: 11240  \tTraining Loss: -709.5972    \n",
      "    Negative Log Likelihood: 88.5858\tSigma2 Prior: -798.1850\tRegularization: 0.0019\n",
      "Iter: 11250  \tTraining Loss: -710.5707    \n",
      "    Negative Log Likelihood: 85.0489\tSigma2 Prior: -795.6215\tRegularization: 0.0019\n",
      "Iter: 11260  \tTraining Loss: -709.9212    \n",
      "    Negative Log Likelihood: 87.5694\tSigma2 Prior: -797.4925\tRegularization: 0.0019\n",
      "Iter: 11270  \tTraining Loss: -710.0609    \n",
      "    Negative Log Likelihood: 90.5498\tSigma2 Prior: -800.6125\tRegularization: 0.0019\n",
      "Iter: 11280  \tTraining Loss: -709.3724    \n",
      "    Negative Log Likelihood: 88.7151\tSigma2 Prior: -798.0895\tRegularization: 0.0019\n",
      "Iter: 11290  \tTraining Loss: -711.2675    \n",
      "    Negative Log Likelihood: 87.0508\tSigma2 Prior: -798.3202\tRegularization: 0.0019\n",
      "Iter: 11300  \tTraining Loss: -710.4485    \n",
      "    Negative Log Likelihood: 89.8173\tSigma2 Prior: -800.2678\tRegularization: 0.0019\n",
      "Iter: 11310  \tTraining Loss: -711.9246    \n",
      "    Negative Log Likelihood: 88.1951\tSigma2 Prior: -800.1216\tRegularization: 0.0019\n",
      "Iter: 11320  \tTraining Loss: -710.6105    \n",
      "    Negative Log Likelihood: 92.2776\tSigma2 Prior: -802.8901\tRegularization: 0.0019\n",
      "Iter: 11330  \tTraining Loss: -711.1542    \n",
      "    Negative Log Likelihood: 87.9521\tSigma2 Prior: -799.1082\tRegularization: 0.0019\n",
      "Iter: 11340  \tTraining Loss: -711.5736    \n",
      "    Negative Log Likelihood: 88.5897\tSigma2 Prior: -800.1652\tRegularization: 0.0019\n",
      "Iter: 11350  \tTraining Loss: -711.7249    \n",
      "    Negative Log Likelihood: 92.2651\tSigma2 Prior: -803.9919\tRegularization: 0.0019\n",
      "Iter: 11360  \tTraining Loss: -711.0381    \n",
      "    Negative Log Likelihood: 86.8280\tSigma2 Prior: -797.8681\tRegularization: 0.0019\n",
      "Iter: 11370  \tTraining Loss: -712.7189    \n",
      "    Negative Log Likelihood: 87.0236\tSigma2 Prior: -799.7444\tRegularization: 0.0019\n",
      "Iter: 11380  \tTraining Loss: -712.1711    \n",
      "    Negative Log Likelihood: 89.7357\tSigma2 Prior: -801.9088\tRegularization: 0.0019\n",
      "Iter: 11390  \tTraining Loss: -714.0304    \n",
      "    Negative Log Likelihood: 91.6317\tSigma2 Prior: -805.6641\tRegularization: 0.0019\n",
      "Iter: 11400  \tTraining Loss: -714.8009    \n",
      "    Negative Log Likelihood: 92.6029\tSigma2 Prior: -807.4058\tRegularization: 0.0019\n",
      "Iter: 11410  \tTraining Loss: -715.2086    \n",
      "    Negative Log Likelihood: 91.6327\tSigma2 Prior: -806.8433\tRegularization: 0.0019\n",
      "Iter: 11420  \tTraining Loss: -715.1428    \n",
      "    Negative Log Likelihood: 93.1271\tSigma2 Prior: -808.2719\tRegularization: 0.0019\n",
      "Iter: 11430  \tTraining Loss: -716.5962    \n",
      "    Negative Log Likelihood: 91.8790\tSigma2 Prior: -808.4772\tRegularization: 0.0019\n",
      "Iter: 11440  \tTraining Loss: -716.5201    \n",
      "    Negative Log Likelihood: 93.4478\tSigma2 Prior: -809.9698\tRegularization: 0.0019\n",
      "Iter: 11450  \tTraining Loss: -715.7032    \n",
      "    Negative Log Likelihood: 95.0825\tSigma2 Prior: -810.7877\tRegularization: 0.0019\n",
      "Iter: 11460  \tTraining Loss: -713.3954    \n",
      "    Negative Log Likelihood: 92.1036\tSigma2 Prior: -805.5010\tRegularization: 0.0019\n",
      "Iter: 11470  \tTraining Loss: -716.9652    \n",
      "    Negative Log Likelihood: 92.5924\tSigma2 Prior: -809.5596\tRegularization: 0.0019\n",
      "Iter: 11480  \tTraining Loss: -717.1754    \n",
      "    Negative Log Likelihood: 91.9283\tSigma2 Prior: -809.1057\tRegularization: 0.0019\n",
      "Iter: 11490  \tTraining Loss: -716.8209    \n",
      "    Negative Log Likelihood: 91.4591\tSigma2 Prior: -808.2820\tRegularization: 0.0019\n",
      "Iter: 11500  \tTraining Loss: -717.7096    \n",
      "    Negative Log Likelihood: 93.4324\tSigma2 Prior: -811.1439\tRegularization: 0.0019\n",
      "Iter: 11510  \tTraining Loss: -715.5276    \n",
      "    Negative Log Likelihood: 94.1769\tSigma2 Prior: -809.7065\tRegularization: 0.0019\n",
      "Iter: 11520  \tTraining Loss: -719.0535    \n",
      "    Negative Log Likelihood: 90.4016\tSigma2 Prior: -809.4570\tRegularization: 0.0019\n",
      "Iter: 11530  \tTraining Loss: -712.4771    \n",
      "    Negative Log Likelihood: 91.3160\tSigma2 Prior: -803.7950\tRegularization: 0.0019\n",
      "Iter: 11540  \tTraining Loss: -719.1608    \n",
      "    Negative Log Likelihood: 90.4754\tSigma2 Prior: -809.6382\tRegularization: 0.0019\n",
      "Iter: 11550  \tTraining Loss: -716.8526    \n",
      "    Negative Log Likelihood: 95.2988\tSigma2 Prior: -812.1534\tRegularization: 0.0019\n",
      "Iter: 11560  \tTraining Loss: -720.5971    \n",
      "    Negative Log Likelihood: 92.0126\tSigma2 Prior: -812.6117\tRegularization: 0.0019\n",
      "Iter: 11570  \tTraining Loss: -720.0341    \n",
      "    Negative Log Likelihood: 92.0004\tSigma2 Prior: -812.0364\tRegularization: 0.0019\n",
      "Iter: 11580  \tTraining Loss: -720.3076    \n",
      "    Negative Log Likelihood: 91.1084\tSigma2 Prior: -811.4180\tRegularization: 0.0019\n",
      "Iter: 11590  \tTraining Loss: -722.8676    \n",
      "    Negative Log Likelihood: 91.4806\tSigma2 Prior: -814.3501\tRegularization: 0.0019\n",
      "Iter: 11600  \tTraining Loss: -719.4740    \n",
      "    Negative Log Likelihood: 92.5837\tSigma2 Prior: -812.0597\tRegularization: 0.0019\n",
      "Iter: 11610  \tTraining Loss: -720.9385    \n",
      "    Negative Log Likelihood: 92.7323\tSigma2 Prior: -813.6728\tRegularization: 0.0019\n",
      "Iter: 11620  \tTraining Loss: -720.4370    \n",
      "    Negative Log Likelihood: 95.0252\tSigma2 Prior: -815.4641\tRegularization: 0.0019\n",
      "Iter: 11630  \tTraining Loss: -713.7313    \n",
      "    Negative Log Likelihood: 90.3907\tSigma2 Prior: -804.1239\tRegularization: 0.0019\n",
      "Iter: 11640  \tTraining Loss: -712.8110    \n",
      "    Negative Log Likelihood: 96.5176\tSigma2 Prior: -809.3306\tRegularization: 0.0019\n",
      "Iter: 11650  \tTraining Loss: -712.7937    \n",
      "    Negative Log Likelihood: 95.0022\tSigma2 Prior: -807.7979\tRegularization: 0.0019\n",
      "Iter: 11660  \tTraining Loss: -706.0667    \n",
      "    Negative Log Likelihood: 99.6722\tSigma2 Prior: -805.7408\tRegularization: 0.0019\n",
      "Iter: 11670  \tTraining Loss: -471.0482    \n",
      "    Negative Log Likelihood: 211.1206\tSigma2 Prior: -682.1707\tRegularization: 0.0019\n",
      "Iter: 11680  \tTraining Loss: 401.7444    \n",
      "    Negative Log Likelihood: 943.7439\tSigma2 Prior: -542.0014\tRegularization: 0.0020\n",
      "Iter: 11690  \tTraining Loss: 82.4311    \n",
      "    Negative Log Likelihood: 555.6583\tSigma2 Prior: -473.2292\tRegularization: 0.0020\n",
      "Iter: 11700  \tTraining Loss: -442.1245    \n",
      "    Negative Log Likelihood: 9.3834\tSigma2 Prior: -451.5099\tRegularization: 0.0020\n",
      "Iter: 11710  \tTraining Loss: -440.4710    \n",
      "    Negative Log Likelihood: 6.0337\tSigma2 Prior: -446.5067\tRegularization: 0.0020\n",
      "Iter: 11720  \tTraining Loss: -440.9856    \n",
      "    Negative Log Likelihood: 5.7331\tSigma2 Prior: -446.7207\tRegularization: 0.0020\n",
      "Iter: 11730  \tTraining Loss: -443.2592    \n",
      "    Negative Log Likelihood: 5.7920\tSigma2 Prior: -449.0532\tRegularization: 0.0020\n",
      "Iter: 11740  \tTraining Loss: -446.8260    \n",
      "    Negative Log Likelihood: 6.2485\tSigma2 Prior: -453.0764\tRegularization: 0.0020\n",
      "Iter: 11750  \tTraining Loss: -449.7154    \n",
      "    Negative Log Likelihood: 6.2308\tSigma2 Prior: -455.9482\tRegularization: 0.0020\n",
      "Iter: 11760  \tTraining Loss: -453.2112    \n",
      "    Negative Log Likelihood: 8.5808\tSigma2 Prior: -461.7939\tRegularization: 0.0020\n",
      "Iter: 11770  \tTraining Loss: -457.5302    \n",
      "    Negative Log Likelihood: 8.1994\tSigma2 Prior: -465.7315\tRegularization: 0.0020\n",
      "Iter: 11780  \tTraining Loss: -463.1046    \n",
      "    Negative Log Likelihood: 10.2923\tSigma2 Prior: -473.3989\tRegularization: 0.0020\n",
      "Iter: 11790  \tTraining Loss: -467.3072    \n",
      "    Negative Log Likelihood: 10.3395\tSigma2 Prior: -477.6487\tRegularization: 0.0020\n",
      "Iter: 11800  \tTraining Loss: -472.6594    \n",
      "    Negative Log Likelihood: 12.6567\tSigma2 Prior: -485.3181\tRegularization: 0.0020\n",
      "Iter: 11810  \tTraining Loss: -478.1369    \n",
      "    Negative Log Likelihood: 13.2195\tSigma2 Prior: -491.3584\tRegularization: 0.0020\n",
      "Iter: 11820  \tTraining Loss: -484.1326    \n",
      "    Negative Log Likelihood: 16.6372\tSigma2 Prior: -500.7718\tRegularization: 0.0020\n",
      "Iter: 11830  \tTraining Loss: -489.1686    \n",
      "    Negative Log Likelihood: 19.4343\tSigma2 Prior: -508.6049\tRegularization: 0.0020\n",
      "Iter: 11840  \tTraining Loss: -494.0458    \n",
      "    Negative Log Likelihood: 19.2651\tSigma2 Prior: -513.3129\tRegularization: 0.0020\n",
      "Iter: 11850  \tTraining Loss: -498.1759    \n",
      "    Negative Log Likelihood: 20.7633\tSigma2 Prior: -518.9412\tRegularization: 0.0020\n",
      "Iter: 11860  \tTraining Loss: -503.1256    \n",
      "    Negative Log Likelihood: 23.0787\tSigma2 Prior: -526.2063\tRegularization: 0.0020\n",
      "Iter: 11870  \tTraining Loss: -507.4982    \n",
      "    Negative Log Likelihood: 24.9285\tSigma2 Prior: -532.4286\tRegularization: 0.0020\n",
      "Iter: 11880  \tTraining Loss: -511.2664    \n",
      "    Negative Log Likelihood: 25.6792\tSigma2 Prior: -536.9475\tRegularization: 0.0020\n",
      "Iter: 11890  \tTraining Loss: -515.1341    \n",
      "    Negative Log Likelihood: 26.8999\tSigma2 Prior: -542.0360\tRegularization: 0.0020\n",
      "Iter: 11900  \tTraining Loss: -518.8223    \n",
      "    Negative Log Likelihood: 29.7802\tSigma2 Prior: -548.6045\tRegularization: 0.0020\n",
      "Iter: 11910  \tTraining Loss: -522.7522    \n",
      "    Negative Log Likelihood: 30.2689\tSigma2 Prior: -553.0231\tRegularization: 0.0020\n",
      "Iter: 11920  \tTraining Loss: -525.2834    \n",
      "    Negative Log Likelihood: 26.8810\tSigma2 Prior: -552.1664\tRegularization: 0.0020\n",
      "Iter: 11930  \tTraining Loss: -528.6368    \n",
      "    Negative Log Likelihood: 29.6753\tSigma2 Prior: -558.3142\tRegularization: 0.0020\n",
      "Iter: 11940  \tTraining Loss: -531.1558    \n",
      "    Negative Log Likelihood: 33.0215\tSigma2 Prior: -564.1793\tRegularization: 0.0020\n",
      "Iter: 11950  \tTraining Loss: -538.2734    \n",
      "    Negative Log Likelihood: 32.1551\tSigma2 Prior: -570.4305\tRegularization: 0.0020\n",
      "Iter: 11960  \tTraining Loss: -540.0012    \n",
      "    Negative Log Likelihood: 32.3914\tSigma2 Prior: -572.3945\tRegularization: 0.0020\n",
      "Iter: 11970  \tTraining Loss: -544.7091    \n",
      "    Negative Log Likelihood: 34.8578\tSigma2 Prior: -579.5690\tRegularization: 0.0020\n",
      "Iter: 11980  \tTraining Loss: -550.0637    \n",
      "    Negative Log Likelihood: 35.7441\tSigma2 Prior: -585.8099\tRegularization: 0.0020\n",
      "Iter: 11990  \tTraining Loss: -553.9349    \n",
      "    Negative Log Likelihood: 37.6896\tSigma2 Prior: -591.6265\tRegularization: 0.0020\n",
      "Iter: 12000  \tTraining Loss: -556.4230    \n",
      "    Negative Log Likelihood: 40.3485\tSigma2 Prior: -596.7735\tRegularization: 0.0020\n",
      "Iter: 12010  \tTraining Loss: -559.6747    \n",
      "    Negative Log Likelihood: 43.3285\tSigma2 Prior: -603.0052\tRegularization: 0.0020\n",
      "Iter: 12020  \tTraining Loss: -563.0472    \n",
      "    Negative Log Likelihood: 40.6522\tSigma2 Prior: -603.7014\tRegularization: 0.0020\n",
      "Iter: 12030  \tTraining Loss: -564.3599    \n",
      "    Negative Log Likelihood: 42.4502\tSigma2 Prior: -606.8121\tRegularization: 0.0020\n",
      "Iter: 12040  \tTraining Loss: -566.6930    \n",
      "    Negative Log Likelihood: 42.8065\tSigma2 Prior: -609.5015\tRegularization: 0.0020\n",
      "Iter: 12050  \tTraining Loss: -570.4142    \n",
      "    Negative Log Likelihood: 42.4505\tSigma2 Prior: -612.8668\tRegularization: 0.0020\n",
      "Iter: 12060  \tTraining Loss: -574.4461    \n",
      "    Negative Log Likelihood: 45.7257\tSigma2 Prior: -620.1738\tRegularization: 0.0020\n",
      "Iter: 12070  \tTraining Loss: -578.8525    \n",
      "    Negative Log Likelihood: 50.2494\tSigma2 Prior: -629.1040\tRegularization: 0.0020\n",
      "Iter: 12080  \tTraining Loss: -583.6066    \n",
      "    Negative Log Likelihood: 49.7957\tSigma2 Prior: -633.4042\tRegularization: 0.0020\n",
      "Iter: 12090  \tTraining Loss: -588.5576    \n",
      "    Negative Log Likelihood: 50.5905\tSigma2 Prior: -639.1500\tRegularization: 0.0020\n",
      "Iter: 12100  \tTraining Loss: -591.3017    \n",
      "    Negative Log Likelihood: 51.0253\tSigma2 Prior: -642.3290\tRegularization: 0.0020\n",
      "Iter: 12110  \tTraining Loss: -594.8079    \n",
      "    Negative Log Likelihood: 52.0415\tSigma2 Prior: -646.8514\tRegularization: 0.0020\n",
      "Iter: 12120  \tTraining Loss: -597.1467    \n",
      "    Negative Log Likelihood: 55.9330\tSigma2 Prior: -653.0818\tRegularization: 0.0020\n",
      "Iter: 12130  \tTraining Loss: -602.3635    \n",
      "    Negative Log Likelihood: 55.0736\tSigma2 Prior: -657.4391\tRegularization: 0.0020\n",
      "Iter: 12140  \tTraining Loss: -603.8265    \n",
      "    Negative Log Likelihood: 57.6731\tSigma2 Prior: -661.5015\tRegularization: 0.0020\n",
      "Iter: 12150  \tTraining Loss: -607.8439    \n",
      "    Negative Log Likelihood: 56.6500\tSigma2 Prior: -664.4959\tRegularization: 0.0020\n",
      "Iter: 12160  \tTraining Loss: -611.3878    \n",
      "    Negative Log Likelihood: 58.0240\tSigma2 Prior: -669.4138\tRegularization: 0.0020\n",
      "Iter: 12170  \tTraining Loss: -615.4773    \n",
      "    Negative Log Likelihood: 58.7041\tSigma2 Prior: -674.1833\tRegularization: 0.0020\n",
      "Iter: 12180  \tTraining Loss: -619.1048    \n",
      "    Negative Log Likelihood: 60.2570\tSigma2 Prior: -679.3638\tRegularization: 0.0020\n",
      "Iter: 12190  \tTraining Loss: -622.2746    \n",
      "    Negative Log Likelihood: 61.3018\tSigma2 Prior: -683.5784\tRegularization: 0.0020\n",
      "Iter: 12200  \tTraining Loss: -626.8355    \n",
      "    Negative Log Likelihood: 63.7253\tSigma2 Prior: -690.5628\tRegularization: 0.0020\n",
      "Iter: 12210  \tTraining Loss: -630.3563    \n",
      "    Negative Log Likelihood: 63.8841\tSigma2 Prior: -694.2424\tRegularization: 0.0020\n",
      "Iter: 12220  \tTraining Loss: -634.9146    \n",
      "    Negative Log Likelihood: 65.0160\tSigma2 Prior: -699.9326\tRegularization: 0.0020\n",
      "Iter: 12230  \tTraining Loss: -639.5405    \n",
      "    Negative Log Likelihood: 67.6303\tSigma2 Prior: -707.1728\tRegularization: 0.0020\n",
      "Iter: 12240  \tTraining Loss: -643.4125    \n",
      "    Negative Log Likelihood: 69.2556\tSigma2 Prior: -712.6700\tRegularization: 0.0020\n",
      "Iter: 12250  \tTraining Loss: -642.9412    \n",
      "    Negative Log Likelihood: 74.5558\tSigma2 Prior: -717.4990\tRegularization: 0.0020\n",
      "Iter: 12260  \tTraining Loss: -645.7892    \n",
      "    Negative Log Likelihood: 76.6950\tSigma2 Prior: -722.4863\tRegularization: 0.0020\n",
      "Iter: 12270  \tTraining Loss: -653.8708    \n",
      "    Negative Log Likelihood: 74.3377\tSigma2 Prior: -728.2106\tRegularization: 0.0020\n",
      "Iter: 12280  \tTraining Loss: -657.0231    \n",
      "    Negative Log Likelihood: 71.4441\tSigma2 Prior: -728.4692\tRegularization: 0.0020\n",
      "Iter: 12290  \tTraining Loss: -659.3356    \n",
      "    Negative Log Likelihood: 74.5139\tSigma2 Prior: -733.8516\tRegularization: 0.0020\n",
      "Iter: 12300  \tTraining Loss: -664.2459    \n",
      "    Negative Log Likelihood: 75.6762\tSigma2 Prior: -739.9241\tRegularization: 0.0020\n",
      "Iter: 12310  \tTraining Loss: -668.2166    \n",
      "    Negative Log Likelihood: 76.8286\tSigma2 Prior: -745.0472\tRegularization: 0.0020\n",
      "Iter: 12320  \tTraining Loss: -670.6516    \n",
      "    Negative Log Likelihood: 79.0062\tSigma2 Prior: -749.6597\tRegularization: 0.0020\n",
      "Iter: 12330  \tTraining Loss: -673.2257    \n",
      "    Negative Log Likelihood: 80.3927\tSigma2 Prior: -753.6204\tRegularization: 0.0020\n",
      "Iter: 12340  \tTraining Loss: -676.5632    \n",
      "    Negative Log Likelihood: 79.6964\tSigma2 Prior: -756.2616\tRegularization: 0.0020\n",
      "Iter: 12350  \tTraining Loss: -681.0952    \n",
      "    Negative Log Likelihood: 80.8438\tSigma2 Prior: -761.9410\tRegularization: 0.0020\n",
      "Iter: 12360  \tTraining Loss: -680.8846    \n",
      "    Negative Log Likelihood: 83.3351\tSigma2 Prior: -764.2217\tRegularization: 0.0020\n",
      "Iter: 12370  \tTraining Loss: -684.0156    \n",
      "    Negative Log Likelihood: 83.0163\tSigma2 Prior: -767.0339\tRegularization: 0.0020\n",
      "Iter: 12380  \tTraining Loss: -686.1384    \n",
      "    Negative Log Likelihood: 85.1342\tSigma2 Prior: -771.2747\tRegularization: 0.0020\n",
      "Iter: 12390  \tTraining Loss: -687.6180    \n",
      "    Negative Log Likelihood: 84.8336\tSigma2 Prior: -772.4537\tRegularization: 0.0020\n",
      "Iter: 12400  \tTraining Loss: -687.7814    \n",
      "    Negative Log Likelihood: 87.4211\tSigma2 Prior: -775.2045\tRegularization: 0.0020\n",
      "Iter: 12410  \tTraining Loss: -688.9118    \n",
      "    Negative Log Likelihood: 88.8216\tSigma2 Prior: -777.7355\tRegularization: 0.0020\n",
      "Iter: 12420  \tTraining Loss: -693.8477    \n",
      "    Negative Log Likelihood: 87.1149\tSigma2 Prior: -780.9645\tRegularization: 0.0020\n",
      "Iter: 12430  \tTraining Loss: -693.7695    \n",
      "    Negative Log Likelihood: 90.3458\tSigma2 Prior: -784.1172\tRegularization: 0.0020\n",
      "Iter: 12440  \tTraining Loss: -695.3071    \n",
      "    Negative Log Likelihood: 93.5721\tSigma2 Prior: -788.8812\tRegularization: 0.0020\n",
      "Iter: 12450  \tTraining Loss: -697.3273    \n",
      "    Negative Log Likelihood: 91.5292\tSigma2 Prior: -788.8585\tRegularization: 0.0020\n",
      "Iter: 12460  \tTraining Loss: -701.9796    \n",
      "    Negative Log Likelihood: 88.3331\tSigma2 Prior: -790.3147\tRegularization: 0.0020\n",
      "Iter: 12470  \tTraining Loss: -703.8833    \n",
      "    Negative Log Likelihood: 88.7953\tSigma2 Prior: -792.6807\tRegularization: 0.0020\n",
      "Iter: 12480  \tTraining Loss: -704.4860    \n",
      "    Negative Log Likelihood: 94.4707\tSigma2 Prior: -798.9588\tRegularization: 0.0020\n",
      "Iter: 12490  \tTraining Loss: -710.2286    \n",
      "    Negative Log Likelihood: 91.3543\tSigma2 Prior: -801.5849\tRegularization: 0.0020\n",
      "Iter: 12500  \tTraining Loss: -706.5934    \n",
      "    Negative Log Likelihood: 98.0856\tSigma2 Prior: -804.6810\tRegularization: 0.0020\n",
      "Iter: 12510  \tTraining Loss: -706.5620    \n",
      "    Negative Log Likelihood: 101.4125\tSigma2 Prior: -807.9765\tRegularization: 0.0020\n",
      "Iter: 12520  \tTraining Loss: -712.0792    \n",
      "    Negative Log Likelihood: 94.7587\tSigma2 Prior: -806.8398\tRegularization: 0.0020\n",
      "Iter: 12530  \tTraining Loss: -712.4424    \n",
      "    Negative Log Likelihood: 95.7038\tSigma2 Prior: -808.1483\tRegularization: 0.0020\n",
      "Iter: 12540  \tTraining Loss: -713.4824    \n",
      "    Negative Log Likelihood: 96.4188\tSigma2 Prior: -809.9031\tRegularization: 0.0020\n",
      "Iter: 12550  \tTraining Loss: -714.9235    \n",
      "    Negative Log Likelihood: 96.5869\tSigma2 Prior: -811.5125\tRegularization: 0.0020\n",
      "Iter: 12560  \tTraining Loss: -715.7424    \n",
      "    Negative Log Likelihood: 97.6283\tSigma2 Prior: -813.3728\tRegularization: 0.0020\n",
      "Iter: 12570  \tTraining Loss: -716.8081    \n",
      "    Negative Log Likelihood: 98.2654\tSigma2 Prior: -815.0756\tRegularization: 0.0020\n",
      "Iter: 12580  \tTraining Loss: -716.8389    \n",
      "    Negative Log Likelihood: 98.7280\tSigma2 Prior: -815.5689\tRegularization: 0.0020\n",
      "Iter: 12590  \tTraining Loss: -718.9688    \n",
      "    Negative Log Likelihood: 98.5875\tSigma2 Prior: -817.5583\tRegularization: 0.0020\n",
      "Iter: 12600  \tTraining Loss: -720.1647    \n",
      "    Negative Log Likelihood: 99.7064\tSigma2 Prior: -819.8731\tRegularization: 0.0020\n",
      "Iter: 12610  \tTraining Loss: -723.9730    \n",
      "    Negative Log Likelihood: 98.9956\tSigma2 Prior: -822.9706\tRegularization: 0.0020\n",
      "Iter: 12620  \tTraining Loss: -723.3020    \n",
      "    Negative Log Likelihood: 101.2744\tSigma2 Prior: -824.5784\tRegularization: 0.0020\n",
      "Iter: 12630  \tTraining Loss: -725.9579    \n",
      "    Negative Log Likelihood: 99.2513\tSigma2 Prior: -825.2112\tRegularization: 0.0020\n",
      "Iter: 12640  \tTraining Loss: -720.1175    \n",
      "    Negative Log Likelihood: 97.1053\tSigma2 Prior: -817.2248\tRegularization: 0.0020\n",
      "Iter: 12650  \tTraining Loss: -726.2350    \n",
      "    Negative Log Likelihood: 98.2025\tSigma2 Prior: -824.4395\tRegularization: 0.0020\n",
      "Iter: 12660  \tTraining Loss: -720.3149    \n",
      "    Negative Log Likelihood: 104.0611\tSigma2 Prior: -824.3781\tRegularization: 0.0020\n",
      "Iter: 12670  \tTraining Loss: -722.1097    \n",
      "    Negative Log Likelihood: 101.1500\tSigma2 Prior: -823.2618\tRegularization: 0.0020\n",
      "Iter: 12680  \tTraining Loss: -712.6964    \n",
      "    Negative Log Likelihood: 106.4880\tSigma2 Prior: -819.1864\tRegularization: 0.0020\n",
      "Iter: 12690  \tTraining Loss: -727.5323    \n",
      "    Negative Log Likelihood: 100.4528\tSigma2 Prior: -827.9871\tRegularization: 0.0020\n",
      "Iter: 12700  \tTraining Loss: -722.8198    \n",
      "    Negative Log Likelihood: 104.7321\tSigma2 Prior: -827.5539\tRegularization: 0.0020\n",
      "Iter: 12710  \tTraining Loss: -727.9186    \n",
      "    Negative Log Likelihood: 102.5957\tSigma2 Prior: -830.5164\tRegularization: 0.0020\n",
      "Iter: 12720  \tTraining Loss: -730.4084    \n",
      "    Negative Log Likelihood: 102.0880\tSigma2 Prior: -832.4985\tRegularization: 0.0020\n",
      "Iter: 12730  \tTraining Loss: -728.7227    \n",
      "    Negative Log Likelihood: 104.7639\tSigma2 Prior: -833.4886\tRegularization: 0.0020\n",
      "Iter: 12740  \tTraining Loss: -727.4766    \n",
      "    Negative Log Likelihood: 97.2826\tSigma2 Prior: -824.7612\tRegularization: 0.0020\n",
      "Iter: 12750  \tTraining Loss: -733.6645    \n",
      "    Negative Log Likelihood: 98.3339\tSigma2 Prior: -832.0004\tRegularization: 0.0020\n",
      "Iter: 12760  \tTraining Loss: -728.0349    \n",
      "    Negative Log Likelihood: 108.5384\tSigma2 Prior: -836.5753\tRegularization: 0.0020\n",
      "Iter: 12770  \tTraining Loss: -729.3152    \n",
      "    Negative Log Likelihood: 96.1963\tSigma2 Prior: -825.5135\tRegularization: 0.0020\n",
      "Iter: 12780  \tTraining Loss: -730.9630    \n",
      "    Negative Log Likelihood: 95.6628\tSigma2 Prior: -826.6278\tRegularization: 0.0020\n",
      "Iter: 12790  \tTraining Loss: -731.1982    \n",
      "    Negative Log Likelihood: 101.1464\tSigma2 Prior: -832.3467\tRegularization: 0.0020\n",
      "Iter: 12800  \tTraining Loss: -731.4133    \n",
      "    Negative Log Likelihood: 103.7351\tSigma2 Prior: -835.1505\tRegularization: 0.0020\n",
      "Iter: 12810  \tTraining Loss: -732.5187    \n",
      "    Negative Log Likelihood: 103.4126\tSigma2 Prior: -835.9332\tRegularization: 0.0020\n",
      "Iter: 12820  \tTraining Loss: -734.2505    \n",
      "    Negative Log Likelihood: 102.9736\tSigma2 Prior: -837.2261\tRegularization: 0.0020\n",
      "Iter: 12830  \tTraining Loss: -734.3835    \n",
      "    Negative Log Likelihood: 104.4629\tSigma2 Prior: -838.8484\tRegularization: 0.0020\n",
      "Iter: 12840  \tTraining Loss: -734.3095    \n",
      "    Negative Log Likelihood: 105.2121\tSigma2 Prior: -839.5236\tRegularization: 0.0020\n",
      "Iter: 12850  \tTraining Loss: -735.7567    \n",
      "    Negative Log Likelihood: 104.5425\tSigma2 Prior: -840.3012\tRegularization: 0.0020\n",
      "Iter: 12860  \tTraining Loss: -736.5550    \n",
      "    Negative Log Likelihood: 104.6354\tSigma2 Prior: -841.1924\tRegularization: 0.0020\n",
      "Iter: 12870  \tTraining Loss: -736.7955    \n",
      "    Negative Log Likelihood: 105.4213\tSigma2 Prior: -842.2188\tRegularization: 0.0020\n",
      "Iter: 12880  \tTraining Loss: -737.2977    \n",
      "    Negative Log Likelihood: 105.6351\tSigma2 Prior: -842.9348\tRegularization: 0.0020\n",
      "Iter: 12890  \tTraining Loss: -737.3429    \n",
      "    Negative Log Likelihood: 106.7227\tSigma2 Prior: -844.0676\tRegularization: 0.0020\n",
      "Iter: 12900  \tTraining Loss: -737.2217    \n",
      "    Negative Log Likelihood: 108.1000\tSigma2 Prior: -845.3237\tRegularization: 0.0020\n",
      "Iter: 12910  \tTraining Loss: -739.6031    \n",
      "    Negative Log Likelihood: 104.5653\tSigma2 Prior: -844.1705\tRegularization: 0.0020\n",
      "Iter: 12920  \tTraining Loss: -740.2620    \n",
      "    Negative Log Likelihood: 106.0217\tSigma2 Prior: -846.2856\tRegularization: 0.0020\n",
      "Iter: 12930  \tTraining Loss: -739.4202    \n",
      "    Negative Log Likelihood: 107.8594\tSigma2 Prior: -847.2817\tRegularization: 0.0020\n",
      "Iter: 12940  \tTraining Loss: -740.0626    \n",
      "    Negative Log Likelihood: 108.0138\tSigma2 Prior: -848.0784\tRegularization: 0.0020\n",
      "Iter: 12950  \tTraining Loss: -740.6407    \n",
      "    Negative Log Likelihood: 108.6133\tSigma2 Prior: -849.2560\tRegularization: 0.0020\n",
      "Iter: 12960  \tTraining Loss: -741.1124    \n",
      "    Negative Log Likelihood: 107.6834\tSigma2 Prior: -848.7977\tRegularization: 0.0020\n",
      "Iter: 12970  \tTraining Loss: -742.3826    \n",
      "    Negative Log Likelihood: 109.4152\tSigma2 Prior: -851.7999\tRegularization: 0.0020\n",
      "Iter: 12980  \tTraining Loss: -729.9505    \n",
      "    Negative Log Likelihood: 118.1455\tSigma2 Prior: -848.0980\tRegularization: 0.0020\n",
      "Iter: 12990  \tTraining Loss: -738.4308    \n",
      "    Negative Log Likelihood: 112.0608\tSigma2 Prior: -850.4937\tRegularization: 0.0020\n",
      "Iter: 13000  \tTraining Loss: -739.5927    \n",
      "    Negative Log Likelihood: 111.2643\tSigma2 Prior: -850.8591\tRegularization: 0.0020\n",
      "Iter: 13010  \tTraining Loss: -739.8515    \n",
      "    Negative Log Likelihood: 110.0963\tSigma2 Prior: -849.9498\tRegularization: 0.0020\n",
      "Iter: 13020  \tTraining Loss: -738.4769    \n",
      "    Negative Log Likelihood: 114.6194\tSigma2 Prior: -853.0983\tRegularization: 0.0020\n",
      "Iter: 13030  \tTraining Loss: -742.0814    \n",
      "    Negative Log Likelihood: 107.6375\tSigma2 Prior: -849.7209\tRegularization: 0.0020\n",
      "Iter: 13040  \tTraining Loss: -739.3381    \n",
      "    Negative Log Likelihood: 113.1680\tSigma2 Prior: -852.5082\tRegularization: 0.0020\n",
      "Iter: 13050  \tTraining Loss: -742.3909    \n",
      "    Negative Log Likelihood: 109.6862\tSigma2 Prior: -852.0791\tRegularization: 0.0020\n",
      "Iter: 13060  \tTraining Loss: -742.2676    \n",
      "    Negative Log Likelihood: 111.1780\tSigma2 Prior: -853.4476\tRegularization: 0.0020\n",
      "Iter: 13070  \tTraining Loss: -743.6220    \n",
      "    Negative Log Likelihood: 110.8868\tSigma2 Prior: -854.5109\tRegularization: 0.0020\n",
      "Iter: 13080  \tTraining Loss: -741.5918    \n",
      "    Negative Log Likelihood: 112.3978\tSigma2 Prior: -853.9916\tRegularization: 0.0020\n",
      "Iter: 13090  \tTraining Loss: -746.7501    \n",
      "    Negative Log Likelihood: 107.0089\tSigma2 Prior: -853.7610\tRegularization: 0.0020\n",
      "Iter: 13100  \tTraining Loss: -743.5480    \n",
      "    Negative Log Likelihood: 114.5389\tSigma2 Prior: -858.0889\tRegularization: 0.0020\n",
      "Iter: 13110  \tTraining Loss: -743.1818    \n",
      "    Negative Log Likelihood: 107.6923\tSigma2 Prior: -850.8761\tRegularization: 0.0020\n",
      "Iter: 13120  \tTraining Loss: -745.2581    \n",
      "    Negative Log Likelihood: 105.3113\tSigma2 Prior: -850.5714\tRegularization: 0.0020\n",
      "Iter: 13130  \tTraining Loss: -744.2597    \n",
      "    Negative Log Likelihood: 109.9532\tSigma2 Prior: -854.2150\tRegularization: 0.0020\n",
      "Iter: 13140  \tTraining Loss: -744.7648    \n",
      "    Negative Log Likelihood: 109.7223\tSigma2 Prior: -854.4892\tRegularization: 0.0020\n",
      "Iter: 13150  \tTraining Loss: -745.0375    \n",
      "    Negative Log Likelihood: 111.6225\tSigma2 Prior: -856.6621\tRegularization: 0.0020\n",
      "Iter: 13160  \tTraining Loss: -745.1442    \n",
      "    Negative Log Likelihood: 112.4759\tSigma2 Prior: -857.6221\tRegularization: 0.0020\n",
      "Iter: 13170  \tTraining Loss: -745.1870    \n",
      "    Negative Log Likelihood: 112.8982\tSigma2 Prior: -858.0872\tRegularization: 0.0020\n",
      "Iter: 13180  \tTraining Loss: -746.7711    \n",
      "    Negative Log Likelihood: 111.3212\tSigma2 Prior: -858.0943\tRegularization: 0.0020\n",
      "Iter: 13190  \tTraining Loss: -748.4129    \n",
      "    Negative Log Likelihood: 109.9984\tSigma2 Prior: -858.4134\tRegularization: 0.0020\n",
      "Iter: 13200  \tTraining Loss: -747.9601    \n",
      "    Negative Log Likelihood: 110.0471\tSigma2 Prior: -858.0093\tRegularization: 0.0020\n",
      "Iter: 13210  \tTraining Loss: -747.6939    \n",
      "    Negative Log Likelihood: 110.9938\tSigma2 Prior: -858.6898\tRegularization: 0.0020\n",
      "Iter: 13220  \tTraining Loss: -746.5234    \n",
      "    Negative Log Likelihood: 111.8456\tSigma2 Prior: -858.3711\tRegularization: 0.0020\n",
      "Iter: 13230  \tTraining Loss: -746.5693    \n",
      "    Negative Log Likelihood: 112.5866\tSigma2 Prior: -859.1580\tRegularization: 0.0020\n",
      "Iter: 13240  \tTraining Loss: -747.5912    \n",
      "    Negative Log Likelihood: 110.9204\tSigma2 Prior: -858.5137\tRegularization: 0.0020\n",
      "Iter: 13250  \tTraining Loss: -747.7081    \n",
      "    Negative Log Likelihood: 112.1377\tSigma2 Prior: -859.8478\tRegularization: 0.0020\n",
      "Iter: 13260  \tTraining Loss: -746.4775    \n",
      "    Negative Log Likelihood: 113.8749\tSigma2 Prior: -860.3545\tRegularization: 0.0021\n",
      "Iter: 13270  \tTraining Loss: -746.6112    \n",
      "    Negative Log Likelihood: 113.3877\tSigma2 Prior: -860.0010\tRegularization: 0.0021\n",
      "Iter: 13280  \tTraining Loss: -748.7317    \n",
      "    Negative Log Likelihood: 112.4140\tSigma2 Prior: -861.1478\tRegularization: 0.0021\n",
      "Iter: 13290  \tTraining Loss: -747.4181    \n",
      "    Negative Log Likelihood: 111.5752\tSigma2 Prior: -858.9954\tRegularization: 0.0021\n",
      "Iter: 13300  \tTraining Loss: -732.9089    \n",
      "    Negative Log Likelihood: 119.4641\tSigma2 Prior: -852.3751\tRegularization: 0.0021\n",
      "Iter: 13310  \tTraining Loss: -743.2773    \n",
      "    Negative Log Likelihood: 112.2366\tSigma2 Prior: -855.5161\tRegularization: 0.0021\n",
      "Iter: 13320  \tTraining Loss: -745.3610    \n",
      "    Negative Log Likelihood: 115.4395\tSigma2 Prior: -860.8026\tRegularization: 0.0021\n",
      "Iter: 13330  \tTraining Loss: -746.5881    \n",
      "    Negative Log Likelihood: 113.0118\tSigma2 Prior: -859.6021\tRegularization: 0.0021\n",
      "Iter: 13340  \tTraining Loss: -748.3517    \n",
      "    Negative Log Likelihood: 114.3234\tSigma2 Prior: -862.6772\tRegularization: 0.0021\n",
      "Iter: 13350  \tTraining Loss: -748.8547    \n",
      "    Negative Log Likelihood: 112.2186\tSigma2 Prior: -861.0754\tRegularization: 0.0021\n",
      "Iter: 13360  \tTraining Loss: -743.8369    \n",
      "    Negative Log Likelihood: 118.6381\tSigma2 Prior: -862.4770\tRegularization: 0.0021\n",
      "Iter: 13370  \tTraining Loss: -741.0289    \n",
      "    Negative Log Likelihood: 123.7692\tSigma2 Prior: -864.8001\tRegularization: 0.0021\n",
      "Iter: 13380  \tTraining Loss: -746.2834    \n",
      "    Negative Log Likelihood: 111.3250\tSigma2 Prior: -857.6105\tRegularization: 0.0021\n",
      "Iter: 13390  \tTraining Loss: -746.2355    \n",
      "    Negative Log Likelihood: 112.4073\tSigma2 Prior: -858.6449\tRegularization: 0.0021\n",
      "Iter: 13400  \tTraining Loss: -746.4183    \n",
      "    Negative Log Likelihood: 116.1189\tSigma2 Prior: -862.5392\tRegularization: 0.0021\n",
      "Iter: 13410  \tTraining Loss: -746.5262    \n",
      "    Negative Log Likelihood: 116.4930\tSigma2 Prior: -863.0213\tRegularization: 0.0021\n",
      "Iter: 13420  \tTraining Loss: -745.7023    \n",
      "    Negative Log Likelihood: 115.0462\tSigma2 Prior: -860.7506\tRegularization: 0.0021\n",
      "Iter: 13430  \tTraining Loss: -745.4073    \n",
      "    Negative Log Likelihood: 115.5914\tSigma2 Prior: -861.0008\tRegularization: 0.0021\n",
      "Iter: 13440  \tTraining Loss: -746.6905    \n",
      "    Negative Log Likelihood: 115.5582\tSigma2 Prior: -862.2507\tRegularization: 0.0021\n",
      "Iter: 13450  \tTraining Loss: -747.5477    \n",
      "    Negative Log Likelihood: 114.0868\tSigma2 Prior: -861.6367\tRegularization: 0.0021\n",
      "Iter: 13460  \tTraining Loss: -747.4022    \n",
      "    Negative Log Likelihood: 114.5665\tSigma2 Prior: -861.9708\tRegularization: 0.0021\n",
      "Iter: 13470  \tTraining Loss: -747.1422    \n",
      "    Negative Log Likelihood: 114.6912\tSigma2 Prior: -861.8354\tRegularization: 0.0021\n",
      "Iter: 13480  \tTraining Loss: -750.8451    \n",
      "    Negative Log Likelihood: 111.6812\tSigma2 Prior: -862.5283\tRegularization: 0.0021\n",
      "Iter: 13490  \tTraining Loss: -751.1047    \n",
      "    Negative Log Likelihood: 106.9555\tSigma2 Prior: -858.0623\tRegularization: 0.0021\n",
      "Iter: 13500  \tTraining Loss: -746.6387    \n",
      "    Negative Log Likelihood: 110.7406\tSigma2 Prior: -857.3813\tRegularization: 0.0021\n",
      "Iter: 13510  \tTraining Loss: -749.2802    \n",
      "    Negative Log Likelihood: 106.9496\tSigma2 Prior: -856.2319\tRegularization: 0.0021\n",
      "Iter: 13520  \tTraining Loss: -751.3993    \n",
      "    Negative Log Likelihood: 109.0391\tSigma2 Prior: -860.4404\tRegularization: 0.0021\n",
      "Iter: 13530  \tTraining Loss: -749.8019    \n",
      "    Negative Log Likelihood: 112.5539\tSigma2 Prior: -862.3580\tRegularization: 0.0021\n",
      "Iter: 13540  \tTraining Loss: -747.2690    \n",
      "    Negative Log Likelihood: 113.3330\tSigma2 Prior: -860.6041\tRegularization: 0.0021\n",
      "Iter: 13550  \tTraining Loss: -745.8148    \n",
      "    Negative Log Likelihood: 113.4959\tSigma2 Prior: -859.3127\tRegularization: 0.0021\n",
      "Iter: 13560  \tTraining Loss: -749.3745    \n",
      "    Negative Log Likelihood: 112.0205\tSigma2 Prior: -861.3971\tRegularization: 0.0021\n",
      "Iter: 13570  \tTraining Loss: -747.5890    \n",
      "    Negative Log Likelihood: 114.1662\tSigma2 Prior: -861.7573\tRegularization: 0.0021\n",
      "Iter: 13580  \tTraining Loss: -749.6105    \n",
      "    Negative Log Likelihood: 110.8345\tSigma2 Prior: -860.4470\tRegularization: 0.0021\n",
      "Iter: 13590  \tTraining Loss: -749.6152    \n",
      "    Negative Log Likelihood: 111.5333\tSigma2 Prior: -861.1506\tRegularization: 0.0021\n",
      "Iter: 13600  \tTraining Loss: -750.2413    \n",
      "    Negative Log Likelihood: 111.3605\tSigma2 Prior: -861.6039\tRegularization: 0.0021\n",
      "Iter: 13610  \tTraining Loss: -738.8925    \n",
      "    Negative Log Likelihood: 115.9509\tSigma2 Prior: -854.8455\tRegularization: 0.0021\n",
      "Iter: 13620  \tTraining Loss: -744.6221    \n",
      "    Negative Log Likelihood: 111.8487\tSigma2 Prior: -856.4728\tRegularization: 0.0021\n",
      "Iter: 13630  \tTraining Loss: -745.4475    \n",
      "    Negative Log Likelihood: 107.8810\tSigma2 Prior: -853.3306\tRegularization: 0.0021\n",
      "Iter: 13640  \tTraining Loss: -746.9481    \n",
      "    Negative Log Likelihood: 109.1757\tSigma2 Prior: -856.1259\tRegularization: 0.0021\n",
      "Iter: 13650  \tTraining Loss: -744.9222    \n",
      "    Negative Log Likelihood: 114.3258\tSigma2 Prior: -859.2501\tRegularization: 0.0021\n",
      "Iter: 13660  \tTraining Loss: -750.7339    \n",
      "    Negative Log Likelihood: 108.4571\tSigma2 Prior: -859.1931\tRegularization: 0.0021\n",
      "Iter: 13670  \tTraining Loss: -742.7991    \n",
      "    Negative Log Likelihood: 111.3275\tSigma2 Prior: -854.1287\tRegularization: 0.0021\n",
      "Iter: 13680  \tTraining Loss: -737.5375    \n",
      "    Negative Log Likelihood: 111.8776\tSigma2 Prior: -849.4171\tRegularization: 0.0021\n",
      "Iter: 13690  \tTraining Loss: -739.0287    \n",
      "    Negative Log Likelihood: 108.0211\tSigma2 Prior: -847.0519\tRegularization: 0.0021\n",
      "Iter: 13700  \tTraining Loss: -740.1715    \n",
      "    Negative Log Likelihood: 110.0338\tSigma2 Prior: -850.2074\tRegularization: 0.0021\n",
      "Iter: 13710  \tTraining Loss: -742.3964    \n",
      "    Negative Log Likelihood: 108.8468\tSigma2 Prior: -851.2454\tRegularization: 0.0021\n",
      "Iter: 13720  \tTraining Loss: -743.3522    \n",
      "    Negative Log Likelihood: 108.6376\tSigma2 Prior: -851.9919\tRegularization: 0.0021\n",
      "Iter: 13730  \tTraining Loss: -742.1457    \n",
      "    Negative Log Likelihood: 108.2902\tSigma2 Prior: -850.4379\tRegularization: 0.0021\n",
      "Iter: 13740  \tTraining Loss: -740.6286    \n",
      "    Negative Log Likelihood: 109.5180\tSigma2 Prior: -850.1487\tRegularization: 0.0021\n",
      "Iter: 13750  \tTraining Loss: -740.7548    \n",
      "    Negative Log Likelihood: 110.8855\tSigma2 Prior: -851.6423\tRegularization: 0.0021\n",
      "Iter: 13760  \tTraining Loss: -742.2350    \n",
      "    Negative Log Likelihood: 109.1233\tSigma2 Prior: -851.3603\tRegularization: 0.0021\n",
      "Iter: 13770  \tTraining Loss: -741.2488    \n",
      "    Negative Log Likelihood: 109.7682\tSigma2 Prior: -851.0191\tRegularization: 0.0021\n",
      "Iter: 13780  \tTraining Loss: -742.5898    \n",
      "    Negative Log Likelihood: 110.5258\tSigma2 Prior: -853.1177\tRegularization: 0.0021\n",
      "Iter: 13790  \tTraining Loss: -743.5658    \n",
      "    Negative Log Likelihood: 111.4829\tSigma2 Prior: -855.0508\tRegularization: 0.0021\n",
      "Iter: 13800  \tTraining Loss: -741.3781    \n",
      "    Negative Log Likelihood: 109.6747\tSigma2 Prior: -851.0549\tRegularization: 0.0021\n",
      "Iter: 13810  \tTraining Loss: -742.5698    \n",
      "    Negative Log Likelihood: 108.9719\tSigma2 Prior: -851.5438\tRegularization: 0.0021\n",
      "Iter: 13820  \tTraining Loss: -743.8220    \n",
      "    Negative Log Likelihood: 108.4190\tSigma2 Prior: -852.2431\tRegularization: 0.0021\n",
      "Iter: 13830  \tTraining Loss: -745.0586    \n",
      "    Negative Log Likelihood: 109.7140\tSigma2 Prior: -854.7746\tRegularization: 0.0021\n",
      "Iter: 13840  \tTraining Loss: -745.6111    \n",
      "    Negative Log Likelihood: 110.9230\tSigma2 Prior: -856.5362\tRegularization: 0.0021\n",
      "Iter: 13850  \tTraining Loss: -747.6432    \n",
      "    Negative Log Likelihood: 108.5184\tSigma2 Prior: -856.1637\tRegularization: 0.0021\n",
      "Iter: 13860  \tTraining Loss: -740.8849    \n",
      "    Negative Log Likelihood: 116.5071\tSigma2 Prior: -857.3942\tRegularization: 0.0021\n",
      "Iter: 13870  \tTraining Loss: -743.0646    \n",
      "    Negative Log Likelihood: 115.6480\tSigma2 Prior: -858.7147\tRegularization: 0.0021\n",
      "Iter: 13880  \tTraining Loss: -746.0526    \n",
      "    Negative Log Likelihood: 109.0997\tSigma2 Prior: -855.1544\tRegularization: 0.0021\n",
      "Iter: 13890  \tTraining Loss: -745.6746    \n",
      "    Negative Log Likelihood: 113.6212\tSigma2 Prior: -859.2979\tRegularization: 0.0021\n",
      "Iter: 13900  \tTraining Loss: -749.4521    \n",
      "    Negative Log Likelihood: 109.7908\tSigma2 Prior: -859.2449\tRegularization: 0.0021\n",
      "Iter: 13910  \tTraining Loss: -750.1949    \n",
      "    Negative Log Likelihood: 108.9136\tSigma2 Prior: -859.1106\tRegularization: 0.0021\n",
      "Iter: 13920  \tTraining Loss: -750.5139    \n",
      "    Negative Log Likelihood: 110.1411\tSigma2 Prior: -860.6570\tRegularization: 0.0021\n",
      "Iter: 13930  \tTraining Loss: -750.6818    \n",
      "    Negative Log Likelihood: 113.7074\tSigma2 Prior: -864.3912\tRegularization: 0.0021\n",
      "Iter: 13940  \tTraining Loss: -752.2428    \n",
      "    Negative Log Likelihood: 110.6571\tSigma2 Prior: -862.9020\tRegularization: 0.0021\n",
      "Iter: 13950  \tTraining Loss: -754.3754    \n",
      "    Negative Log Likelihood: 111.3402\tSigma2 Prior: -865.7177\tRegularization: 0.0021\n",
      "Iter: 13960  \tTraining Loss: -743.8245    \n",
      "    Negative Log Likelihood: 118.3722\tSigma2 Prior: -862.1988\tRegularization: 0.0021\n",
      "Iter: 13970  \tTraining Loss: -748.5258    \n",
      "    Negative Log Likelihood: 115.3985\tSigma2 Prior: -863.9263\tRegularization: 0.0021\n",
      "Iter: 13980  \tTraining Loss: -745.0779    \n",
      "    Negative Log Likelihood: 120.8455\tSigma2 Prior: -865.9254\tRegularization: 0.0021\n",
      "Iter: 13990  \tTraining Loss: -752.5338    \n",
      "    Negative Log Likelihood: 108.9890\tSigma2 Prior: -861.5249\tRegularization: 0.0021\n",
      "Iter: 14000  \tTraining Loss: -750.2468    \n",
      "    Negative Log Likelihood: 114.1766\tSigma2 Prior: -864.4255\tRegularization: 0.0021\n",
      "Iter: 14010  \tTraining Loss: -737.4217    \n",
      "    Negative Log Likelihood: 125.0836\tSigma2 Prior: -862.5073\tRegularization: 0.0021\n",
      "Iter: 14020  \tTraining Loss: -743.1097    \n",
      "    Negative Log Likelihood: 115.6922\tSigma2 Prior: -858.8040\tRegularization: 0.0021\n",
      "Iter: 14030  \tTraining Loss: -739.4976    \n",
      "    Negative Log Likelihood: 114.5922\tSigma2 Prior: -854.0919\tRegularization: 0.0021\n",
      "Iter: 14040  \tTraining Loss: -741.7852    \n",
      "    Negative Log Likelihood: 116.5429\tSigma2 Prior: -858.3301\tRegularization: 0.0021\n",
      "Iter: 14050  \tTraining Loss: -743.2391    \n",
      "    Negative Log Likelihood: 115.7769\tSigma2 Prior: -859.0181\tRegularization: 0.0021\n",
      "Iter: 14060  \tTraining Loss: -744.7120    \n",
      "    Negative Log Likelihood: 116.1577\tSigma2 Prior: -860.8718\tRegularization: 0.0021\n",
      "Iter: 14070  \tTraining Loss: -748.4995    \n",
      "    Negative Log Likelihood: 108.4473\tSigma2 Prior: -856.9489\tRegularization: 0.0021\n",
      "Iter: 14080  \tTraining Loss: -748.5212    \n",
      "    Negative Log Likelihood: 106.9397\tSigma2 Prior: -855.4630\tRegularization: 0.0021\n",
      "Iter: 14090  \tTraining Loss: -747.4197    \n",
      "    Negative Log Likelihood: 107.8812\tSigma2 Prior: -855.3029\tRegularization: 0.0021\n",
      "Iter: 14100  \tTraining Loss: -746.2213    \n",
      "    Negative Log Likelihood: 111.6046\tSigma2 Prior: -857.8279\tRegularization: 0.0021\n",
      "Iter: 14110  \tTraining Loss: -746.8627    \n",
      "    Negative Log Likelihood: 110.7205\tSigma2 Prior: -857.5853\tRegularization: 0.0021\n",
      "Iter: 14120  \tTraining Loss: -746.2993    \n",
      "    Negative Log Likelihood: 111.5290\tSigma2 Prior: -857.8304\tRegularization: 0.0021\n",
      "Iter: 14130  \tTraining Loss: -746.4073    \n",
      "    Negative Log Likelihood: 110.7436\tSigma2 Prior: -857.1530\tRegularization: 0.0021\n",
      "Iter: 14140  \tTraining Loss: -747.2386    \n",
      "    Negative Log Likelihood: 110.8190\tSigma2 Prior: -858.0597\tRegularization: 0.0021\n",
      "Iter: 14150  \tTraining Loss: -747.1424    \n",
      "    Negative Log Likelihood: 115.1503\tSigma2 Prior: -862.2948\tRegularization: 0.0021\n",
      "Iter: 14160  \tTraining Loss: -748.3836    \n",
      "    Negative Log Likelihood: 112.2338\tSigma2 Prior: -860.6195\tRegularization: 0.0021\n",
      "Iter: 14170  \tTraining Loss: -748.8258    \n",
      "    Negative Log Likelihood: 111.3591\tSigma2 Prior: -860.1870\tRegularization: 0.0021\n",
      "Iter: 14180  \tTraining Loss: -746.9827    \n",
      "    Negative Log Likelihood: 115.9319\tSigma2 Prior: -862.9166\tRegularization: 0.0021\n",
      "Iter: 14190  \tTraining Loss: -747.1862    \n",
      "    Negative Log Likelihood: 115.5618\tSigma2 Prior: -862.7501\tRegularization: 0.0021\n",
      "Iter: 14200  \tTraining Loss: -748.5972    \n",
      "    Negative Log Likelihood: 113.7858\tSigma2 Prior: -862.3851\tRegularization: 0.0021\n",
      "Iter: 14210  \tTraining Loss: -749.8140    \n",
      "    Negative Log Likelihood: 112.8208\tSigma2 Prior: -862.6368\tRegularization: 0.0021\n",
      "Iter: 14220  \tTraining Loss: -748.7408    \n",
      "    Negative Log Likelihood: 114.3454\tSigma2 Prior: -863.0883\tRegularization: 0.0021\n",
      "Iter: 14230  \tTraining Loss: -748.6398    \n",
      "    Negative Log Likelihood: 113.3164\tSigma2 Prior: -861.9583\tRegularization: 0.0021\n",
      "Iter: 14240  \tTraining Loss: -751.4471    \n",
      "    Negative Log Likelihood: 109.7760\tSigma2 Prior: -861.2253\tRegularization: 0.0021\n",
      "Iter: 14250  \tTraining Loss: -749.7535    \n",
      "    Negative Log Likelihood: 114.1034\tSigma2 Prior: -863.8590\tRegularization: 0.0021\n",
      "Iter: 14260  \tTraining Loss: -751.7870    \n",
      "    Negative Log Likelihood: 114.3037\tSigma2 Prior: -866.0927\tRegularization: 0.0021\n",
      "Iter: 14270  \tTraining Loss: -755.0019    \n",
      "    Negative Log Likelihood: 107.9679\tSigma2 Prior: -862.9719\tRegularization: 0.0021\n",
      "Iter: 14280  \tTraining Loss: -743.4257    \n",
      "    Negative Log Likelihood: 114.3122\tSigma2 Prior: -857.7399\tRegularization: 0.0021\n",
      "Iter: 14290  \tTraining Loss: -741.1767    \n",
      "    Negative Log Likelihood: 121.9243\tSigma2 Prior: -863.1030\tRegularization: 0.0021\n",
      "Iter: 14300  \tTraining Loss: -740.7936    \n",
      "    Negative Log Likelihood: 113.8516\tSigma2 Prior: -854.6473\tRegularization: 0.0021\n",
      "Iter: 14310  \tTraining Loss: -745.5037    \n",
      "    Negative Log Likelihood: 107.0875\tSigma2 Prior: -852.5932\tRegularization: 0.0021\n",
      "Iter: 14320  \tTraining Loss: -743.0009    \n",
      "    Negative Log Likelihood: 111.5781\tSigma2 Prior: -854.5811\tRegularization: 0.0021\n",
      "Iter: 14330  \tTraining Loss: -743.6675    \n",
      "    Negative Log Likelihood: 116.3167\tSigma2 Prior: -859.9862\tRegularization: 0.0021\n",
      "Iter: 14340  \tTraining Loss: -745.3434    \n",
      "    Negative Log Likelihood: 109.8580\tSigma2 Prior: -855.2034\tRegularization: 0.0021\n",
      "Iter: 14350  \tTraining Loss: -744.9387    \n",
      "    Negative Log Likelihood: 110.4160\tSigma2 Prior: -855.3568\tRegularization: 0.0021\n",
      "Iter: 14360  \tTraining Loss: -745.9219    \n",
      "    Negative Log Likelihood: 112.0096\tSigma2 Prior: -857.9336\tRegularization: 0.0021\n",
      "Iter: 14370  \tTraining Loss: -747.2922    \n",
      "    Negative Log Likelihood: 113.6916\tSigma2 Prior: -860.9858\tRegularization: 0.0021\n",
      "Iter: 14380  \tTraining Loss: -747.1117    \n",
      "    Negative Log Likelihood: 112.7442\tSigma2 Prior: -859.8580\tRegularization: 0.0021\n",
      "Iter: 14390  \tTraining Loss: -748.6460    \n",
      "    Negative Log Likelihood: 109.4961\tSigma2 Prior: -858.1442\tRegularization: 0.0021\n",
      "Iter: 14400  \tTraining Loss: -748.5182    \n",
      "    Negative Log Likelihood: 110.7325\tSigma2 Prior: -859.2527\tRegularization: 0.0021\n",
      "Iter: 14410  \tTraining Loss: -747.2053    \n",
      "    Negative Log Likelihood: 114.1813\tSigma2 Prior: -861.3887\tRegularization: 0.0021\n",
      "Iter: 14420  \tTraining Loss: -745.6533    \n",
      "    Negative Log Likelihood: 116.1417\tSigma2 Prior: -861.7971\tRegularization: 0.0021\n",
      "Iter: 14430  \tTraining Loss: -746.8408    \n",
      "    Negative Log Likelihood: 112.8134\tSigma2 Prior: -859.6562\tRegularization: 0.0021\n",
      "Iter: 14440  \tTraining Loss: -746.5821    \n",
      "    Negative Log Likelihood: 113.5361\tSigma2 Prior: -860.1203\tRegularization: 0.0021\n",
      "Iter: 14450  \tTraining Loss: -748.0836    \n",
      "    Negative Log Likelihood: 113.0156\tSigma2 Prior: -861.1013\tRegularization: 0.0021\n",
      "Iter: 14460  \tTraining Loss: -747.4688    \n",
      "    Negative Log Likelihood: 115.4407\tSigma2 Prior: -862.9116\tRegularization: 0.0021\n",
      "Iter: 14470  \tTraining Loss: -747.4144    \n",
      "    Negative Log Likelihood: 115.2270\tSigma2 Prior: -862.6435\tRegularization: 0.0021\n",
      "Iter: 14480  \tTraining Loss: -748.6263    \n",
      "    Negative Log Likelihood: 112.1163\tSigma2 Prior: -860.7448\tRegularization: 0.0021\n",
      "Iter: 14490  \tTraining Loss: -748.0586    \n",
      "    Negative Log Likelihood: 113.3237\tSigma2 Prior: -861.3844\tRegularization: 0.0021\n",
      "Iter: 14500  \tTraining Loss: -747.8744    \n",
      "    Negative Log Likelihood: 113.7531\tSigma2 Prior: -861.6295\tRegularization: 0.0021\n",
      "Iter: 14510  \tTraining Loss: -749.4230    \n",
      "    Negative Log Likelihood: 112.7603\tSigma2 Prior: -862.1854\tRegularization: 0.0021\n",
      "Iter: 14520  \tTraining Loss: -750.2274    \n",
      "    Negative Log Likelihood: 112.2760\tSigma2 Prior: -862.5055\tRegularization: 0.0021\n",
      "Iter: 14530  \tTraining Loss: -749.0457    \n",
      "    Negative Log Likelihood: 113.5079\tSigma2 Prior: -862.5557\tRegularization: 0.0021\n",
      "Iter: 14540  \tTraining Loss: -750.3411    \n",
      "    Negative Log Likelihood: 113.6264\tSigma2 Prior: -863.9696\tRegularization: 0.0021\n",
      "Iter: 14550  \tTraining Loss: -751.9430    \n",
      "    Negative Log Likelihood: 112.5688\tSigma2 Prior: -864.5139\tRegularization: 0.0021\n",
      "Iter: 14560  \tTraining Loss: -753.0949    \n",
      "    Negative Log Likelihood: 114.7030\tSigma2 Prior: -867.8000\tRegularization: 0.0021\n",
      "Iter: 14570  \tTraining Loss: -749.5553    \n",
      "    Negative Log Likelihood: 117.3925\tSigma2 Prior: -866.9498\tRegularization: 0.0021\n",
      "Iter: 14580  \tTraining Loss: -754.4828    \n",
      "    Negative Log Likelihood: 113.7601\tSigma2 Prior: -868.2450\tRegularization: 0.0021\n",
      "Iter: 14590  \tTraining Loss: -757.3721    \n",
      "    Negative Log Likelihood: 111.4311\tSigma2 Prior: -868.8053\tRegularization: 0.0021\n",
      "Iter: 14600  \tTraining Loss: -752.6029    \n",
      "    Negative Log Likelihood: 112.9241\tSigma2 Prior: -865.5291\tRegularization: 0.0021\n",
      "Iter: 14610  \tTraining Loss: -753.3984    \n",
      "    Negative Log Likelihood: 115.6336\tSigma2 Prior: -869.0341\tRegularization: 0.0021\n",
      "Iter: 14620  \tTraining Loss: -755.9918    \n",
      "    Negative Log Likelihood: 110.8419\tSigma2 Prior: -866.8358\tRegularization: 0.0021\n",
      "Iter: 14630  \tTraining Loss: -756.7482    \n",
      "    Negative Log Likelihood: 111.4583\tSigma2 Prior: -868.2086\tRegularization: 0.0021\n",
      "Iter: 14640  \tTraining Loss: -755.9977    \n",
      "    Negative Log Likelihood: 114.6755\tSigma2 Prior: -870.6753\tRegularization: 0.0021\n",
      "Iter: 14650  \tTraining Loss: -756.3912    \n",
      "    Negative Log Likelihood: 113.1697\tSigma2 Prior: -869.5630\tRegularization: 0.0021\n",
      "Iter: 14660  \tTraining Loss: -758.3170    \n",
      "    Negative Log Likelihood: 109.1984\tSigma2 Prior: -867.5175\tRegularization: 0.0021\n",
      "Iter: 14670  \tTraining Loss: -751.6014    \n",
      "    Negative Log Likelihood: 114.2284\tSigma2 Prior: -865.8318\tRegularization: 0.0021\n",
      "Iter: 14680  \tTraining Loss: -753.9243    \n",
      "    Negative Log Likelihood: 108.7272\tSigma2 Prior: -862.6536\tRegularization: 0.0021\n",
      "Iter: 14690  \tTraining Loss: -751.4571    \n",
      "    Negative Log Likelihood: 108.6174\tSigma2 Prior: -860.0765\tRegularization: 0.0021\n",
      "Iter: 14700  \tTraining Loss: -751.3388    \n",
      "    Negative Log Likelihood: 119.3736\tSigma2 Prior: -870.7144\tRegularization: 0.0021\n",
      "Iter: 14710  \tTraining Loss: -752.9270    \n",
      "    Negative Log Likelihood: 109.3572\tSigma2 Prior: -862.2863\tRegularization: 0.0021\n",
      "Iter: 14720  \tTraining Loss: -755.3320    \n",
      "    Negative Log Likelihood: 109.7591\tSigma2 Prior: -865.0932\tRegularization: 0.0021\n",
      "Iter: 14730  \tTraining Loss: -755.0053    \n",
      "    Negative Log Likelihood: 110.5973\tSigma2 Prior: -865.6047\tRegularization: 0.0021\n",
      "Iter: 14740  \tTraining Loss: -754.4080    \n",
      "    Negative Log Likelihood: 111.1229\tSigma2 Prior: -865.5330\tRegularization: 0.0021\n",
      "Iter: 14750  \tTraining Loss: -748.9598    \n",
      "    Negative Log Likelihood: 117.5105\tSigma2 Prior: -866.4724\tRegularization: 0.0021\n",
      "Iter: 14760  \tTraining Loss: -749.3058    \n",
      "    Negative Log Likelihood: 111.0722\tSigma2 Prior: -860.3801\tRegularization: 0.0021\n",
      "Iter: 14770  \tTraining Loss: -749.5770    \n",
      "    Negative Log Likelihood: 116.8488\tSigma2 Prior: -866.4279\tRegularization: 0.0021\n",
      "Iter: 14780  \tTraining Loss: -751.9815    \n",
      "    Negative Log Likelihood: 111.2259\tSigma2 Prior: -863.2095\tRegularization: 0.0021\n",
      "Iter: 14790  \tTraining Loss: -749.0804    \n",
      "    Negative Log Likelihood: 114.7802\tSigma2 Prior: -863.8627\tRegularization: 0.0021\n",
      "Iter: 14800  \tTraining Loss: -749.9852    \n",
      "    Negative Log Likelihood: 111.9408\tSigma2 Prior: -861.9280\tRegularization: 0.0021\n",
      "Iter: 14810  \tTraining Loss: -751.3701    \n",
      "    Negative Log Likelihood: 113.1273\tSigma2 Prior: -864.4994\tRegularization: 0.0021\n",
      "Iter: 14820  \tTraining Loss: -753.1902    \n",
      "    Negative Log Likelihood: 113.2835\tSigma2 Prior: -866.4758\tRegularization: 0.0021\n",
      "Iter: 14830  \tTraining Loss: -753.2645    \n",
      "    Negative Log Likelihood: 111.3956\tSigma2 Prior: -864.6621\tRegularization: 0.0021\n",
      "Iter: 14840  \tTraining Loss: -752.9473    \n",
      "    Negative Log Likelihood: 107.3128\tSigma2 Prior: -860.2622\tRegularization: 0.0021\n",
      "Iter: 14850  \tTraining Loss: -745.5461    \n",
      "    Negative Log Likelihood: 109.7990\tSigma2 Prior: -855.3471\tRegularization: 0.0021\n",
      "Iter: 14860  \tTraining Loss: -734.6586    \n",
      "    Negative Log Likelihood: 131.5062\tSigma2 Prior: -866.1669\tRegularization: 0.0021\n",
      "Iter: 14870  \tTraining Loss: -746.8916    \n",
      "    Negative Log Likelihood: 105.8268\tSigma2 Prior: -852.7205\tRegularization: 0.0021\n",
      "Iter: 14880  \tTraining Loss: -746.8140    \n",
      "    Negative Log Likelihood: 105.7614\tSigma2 Prior: -852.5775\tRegularization: 0.0021\n",
      "Iter: 14890  \tTraining Loss: -748.5210    \n",
      "    Negative Log Likelihood: 109.2844\tSigma2 Prior: -857.8075\tRegularization: 0.0021\n",
      "Iter: 14900  \tTraining Loss: -746.0482    \n",
      "    Negative Log Likelihood: 116.4426\tSigma2 Prior: -862.4929\tRegularization: 0.0021\n",
      "Iter: 14910  \tTraining Loss: -747.8507    \n",
      "    Negative Log Likelihood: 107.2385\tSigma2 Prior: -855.0912\tRegularization: 0.0021\n",
      "Iter: 14920  \tTraining Loss: -743.5939    \n",
      "    Negative Log Likelihood: 108.6931\tSigma2 Prior: -852.2891\tRegularization: 0.0021\n",
      "Iter: 14930  \tTraining Loss: -746.6387    \n",
      "    Negative Log Likelihood: 110.1204\tSigma2 Prior: -856.7612\tRegularization: 0.0021\n",
      "Iter: 14940  \tTraining Loss: -744.9511    \n",
      "    Negative Log Likelihood: 113.6469\tSigma2 Prior: -858.6001\tRegularization: 0.0021\n",
      "Iter: 14950  \tTraining Loss: -746.5991    \n",
      "    Negative Log Likelihood: 111.3618\tSigma2 Prior: -857.9631\tRegularization: 0.0021\n",
      "Iter: 14960  \tTraining Loss: -744.7599    \n",
      "    Negative Log Likelihood: 111.5646\tSigma2 Prior: -856.3267\tRegularization: 0.0021\n",
      "Iter: 14970  \tTraining Loss: -746.6356    \n",
      "    Negative Log Likelihood: 109.6060\tSigma2 Prior: -856.2437\tRegularization: 0.0021\n",
      "Iter: 14980  \tTraining Loss: -747.4133    \n",
      "    Negative Log Likelihood: 111.7388\tSigma2 Prior: -859.1543\tRegularization: 0.0021\n",
      "Iter: 14990  \tTraining Loss: -747.1342    \n",
      "    Negative Log Likelihood: 113.9323\tSigma2 Prior: -861.0685\tRegularization: 0.0021\n",
      "Iter: 15000  \tTraining Loss: -741.4299    \n",
      "    Negative Log Likelihood: 119.5550\tSigma2 Prior: -860.9871\tRegularization: 0.0021\n",
      "Iter: 15010  \tTraining Loss: -739.6282    \n",
      "    Negative Log Likelihood: 116.6002\tSigma2 Prior: -856.2305\tRegularization: 0.0021\n",
      "Iter: 15020  \tTraining Loss: -750.7248    \n",
      "    Negative Log Likelihood: 104.5738\tSigma2 Prior: -855.3007\tRegularization: 0.0021\n",
      "Iter: 15030  \tTraining Loss: -748.4230    \n",
      "    Negative Log Likelihood: 105.1574\tSigma2 Prior: -853.5825\tRegularization: 0.0021\n",
      "Iter: 15040  \tTraining Loss: -747.4243    \n",
      "    Negative Log Likelihood: 103.3754\tSigma2 Prior: -850.8018\tRegularization: 0.0021\n",
      "Iter: 15050  \tTraining Loss: -745.4446    \n",
      "    Negative Log Likelihood: 97.3878\tSigma2 Prior: -842.8345\tRegularization: 0.0021\n",
      "Iter: 15060  \tTraining Loss: -748.1006    \n",
      "    Negative Log Likelihood: 103.0306\tSigma2 Prior: -851.1333\tRegularization: 0.0021\n",
      "Iter: 15070  \tTraining Loss: -740.2125    \n",
      "    Negative Log Likelihood: 117.7095\tSigma2 Prior: -857.9241\tRegularization: 0.0021\n",
      "Iter: 15080  \tTraining Loss: -744.1956    \n",
      "    Negative Log Likelihood: 107.7351\tSigma2 Prior: -851.9328\tRegularization: 0.0021\n",
      "Iter: 15090  \tTraining Loss: -745.2032    \n",
      "    Negative Log Likelihood: 106.1469\tSigma2 Prior: -851.3524\tRegularization: 0.0021\n",
      "Iter: 15100  \tTraining Loss: -747.6812    \n",
      "    Negative Log Likelihood: 105.8079\tSigma2 Prior: -853.4913\tRegularization: 0.0021\n",
      "Iter: 15110  \tTraining Loss: -747.7579    \n",
      "    Negative Log Likelihood: 108.7059\tSigma2 Prior: -856.4659\tRegularization: 0.0021\n",
      "Iter: 15120  \tTraining Loss: -748.4556    \n",
      "    Negative Log Likelihood: 109.1976\tSigma2 Prior: -857.6553\tRegularization: 0.0021\n",
      "Iter: 15130  \tTraining Loss: -734.9753    \n",
      "    Negative Log Likelihood: 116.4897\tSigma2 Prior: -851.4672\tRegularization: 0.0021\n",
      "Iter: 15140  \tTraining Loss: -742.7170    \n",
      "    Negative Log Likelihood: 100.0746\tSigma2 Prior: -842.7938\tRegularization: 0.0021\n",
      "Iter: 15150  \tTraining Loss: -747.6697    \n",
      "    Negative Log Likelihood: 112.1370\tSigma2 Prior: -859.8088\tRegularization: 0.0021\n",
      "Iter: 15160  \tTraining Loss: -750.0559    \n",
      "    Negative Log Likelihood: 105.8681\tSigma2 Prior: -855.9261\tRegularization: 0.0021\n",
      "Iter: 15170  \tTraining Loss: -749.6818    \n",
      "    Negative Log Likelihood: 109.9858\tSigma2 Prior: -859.6698\tRegularization: 0.0021\n",
      "Iter: 15180  \tTraining Loss: -750.8408    \n",
      "    Negative Log Likelihood: 108.8386\tSigma2 Prior: -859.6816\tRegularization: 0.0021\n",
      "Iter: 15190  \tTraining Loss: -751.1005    \n",
      "    Negative Log Likelihood: 112.6803\tSigma2 Prior: -863.7828\tRegularization: 0.0021\n",
      "Iter: 15200  \tTraining Loss: -751.8701    \n",
      "    Negative Log Likelihood: 111.8263\tSigma2 Prior: -863.6984\tRegularization: 0.0021\n",
      "Iter: 15210  \tTraining Loss: -753.0653    \n",
      "    Negative Log Likelihood: 112.2079\tSigma2 Prior: -865.2754\tRegularization: 0.0021\n",
      "Iter: 15220  \tTraining Loss: -746.6356    \n",
      "    Negative Log Likelihood: 115.4229\tSigma2 Prior: -862.0607\tRegularization: 0.0021\n",
      "Iter: 15230  \tTraining Loss: -752.0970    \n",
      "    Negative Log Likelihood: 107.3901\tSigma2 Prior: -859.4892\tRegularization: 0.0021\n",
      "Iter: 15240  \tTraining Loss: -748.9280    \n",
      "    Negative Log Likelihood: 112.8297\tSigma2 Prior: -861.7598\tRegularization: 0.0021\n",
      "Iter: 15250  \tTraining Loss: -741.0283    \n",
      "    Negative Log Likelihood: 111.3734\tSigma2 Prior: -852.4039\tRegularization: 0.0021\n",
      "Iter: 15260  \tTraining Loss: -742.8073    \n",
      "    Negative Log Likelihood: 111.1170\tSigma2 Prior: -853.9264\tRegularization: 0.0021\n",
      "Iter: 15270  \tTraining Loss: -738.6068    \n",
      "    Negative Log Likelihood: 111.1025\tSigma2 Prior: -849.7114\tRegularization: 0.0021\n",
      "Iter: 15280  \tTraining Loss: -743.1971    \n",
      "    Negative Log Likelihood: 106.6468\tSigma2 Prior: -849.8461\tRegularization: 0.0021\n",
      "Iter: 15290  \tTraining Loss: -739.4520    \n",
      "    Negative Log Likelihood: 116.1865\tSigma2 Prior: -855.6406\tRegularization: 0.0021\n",
      "Iter: 15300  \tTraining Loss: -743.6590    \n",
      "    Negative Log Likelihood: 107.7111\tSigma2 Prior: -851.3723\tRegularization: 0.0021\n",
      "Iter: 15310  \tTraining Loss: -741.3484    \n",
      "    Negative Log Likelihood: 102.0089\tSigma2 Prior: -843.3596\tRegularization: 0.0021\n",
      "Iter: 15320  \tTraining Loss: -742.2964    \n",
      "    Negative Log Likelihood: 102.0323\tSigma2 Prior: -844.3309\tRegularization: 0.0021\n",
      "Iter: 15330  \tTraining Loss: -740.8048    \n",
      "    Negative Log Likelihood: 116.5331\tSigma2 Prior: -857.3400\tRegularization: 0.0021\n",
      "Iter: 15340  \tTraining Loss: -746.7423    \n",
      "    Negative Log Likelihood: 112.8484\tSigma2 Prior: -859.5928\tRegularization: 0.0021\n",
      "Iter: 15350  \tTraining Loss: -742.6822    \n",
      "    Negative Log Likelihood: 112.3998\tSigma2 Prior: -855.0841\tRegularization: 0.0021\n",
      "Iter: 15360  \tTraining Loss: -736.9627    \n",
      "    Negative Log Likelihood: 103.9963\tSigma2 Prior: -840.9612\tRegularization: 0.0021\n",
      "Iter: 15370  \tTraining Loss: -732.3958    \n",
      "    Negative Log Likelihood: 115.4217\tSigma2 Prior: -847.8196\tRegularization: 0.0021\n",
      "Iter: 15380  \tTraining Loss: -739.2937    \n",
      "    Negative Log Likelihood: 104.3807\tSigma2 Prior: -843.6765\tRegularization: 0.0021\n",
      "Iter: 15390  \tTraining Loss: -737.8024    \n",
      "    Negative Log Likelihood: 110.4901\tSigma2 Prior: -848.2947\tRegularization: 0.0021\n",
      "Iter: 15400  \tTraining Loss: -743.8187    \n",
      "    Negative Log Likelihood: 99.1238\tSigma2 Prior: -842.9446\tRegularization: 0.0021\n",
      "Iter: 15410  \tTraining Loss: -744.7075    \n",
      "    Negative Log Likelihood: 108.8224\tSigma2 Prior: -853.5321\tRegularization: 0.0021\n",
      "Iter: 15420  \tTraining Loss: -746.4866    \n",
      "    Negative Log Likelihood: 109.2715\tSigma2 Prior: -855.7603\tRegularization: 0.0021\n",
      "Iter: 15430  \tTraining Loss: -746.1026    \n",
      "    Negative Log Likelihood: 108.4417\tSigma2 Prior: -854.5464\tRegularization: 0.0021\n",
      "Iter: 15440  \tTraining Loss: -745.2324    \n",
      "    Negative Log Likelihood: 109.0567\tSigma2 Prior: -854.2911\tRegularization: 0.0021\n",
      "Iter: 15450  \tTraining Loss: -746.6997    \n",
      "    Negative Log Likelihood: 110.6022\tSigma2 Prior: -857.3041\tRegularization: 0.0021\n",
      "Iter: 15460  \tTraining Loss: -748.7598    \n",
      "    Negative Log Likelihood: 110.3947\tSigma2 Prior: -859.1567\tRegularization: 0.0021\n",
      "Iter: 15470  \tTraining Loss: -745.9300    \n",
      "    Negative Log Likelihood: 110.2727\tSigma2 Prior: -856.2048\tRegularization: 0.0021\n",
      "Iter: 15480  \tTraining Loss: -750.0695    \n",
      "    Negative Log Likelihood: 107.8566\tSigma2 Prior: -857.9282\tRegularization: 0.0021\n",
      "Iter: 15490  \tTraining Loss: -750.1218    \n",
      "    Negative Log Likelihood: 109.4717\tSigma2 Prior: -859.5956\tRegularization: 0.0021\n",
      "Iter: 15500  \tTraining Loss: -751.3734    \n",
      "    Negative Log Likelihood: 109.5659\tSigma2 Prior: -860.9414\tRegularization: 0.0021\n",
      "Iter: 15510  \tTraining Loss: -750.1920    \n",
      "    Negative Log Likelihood: 109.3587\tSigma2 Prior: -859.5529\tRegularization: 0.0021\n",
      "Iter: 15520  \tTraining Loss: -747.3157    \n",
      "    Negative Log Likelihood: 112.2239\tSigma2 Prior: -859.5418\tRegularization: 0.0021\n",
      "Iter: 15530  \tTraining Loss: -751.5200    \n",
      "    Negative Log Likelihood: 106.7433\tSigma2 Prior: -858.2654\tRegularization: 0.0021\n",
      "Iter: 15540  \tTraining Loss: -748.8011    \n",
      "    Negative Log Likelihood: 108.6792\tSigma2 Prior: -857.4824\tRegularization: 0.0021\n",
      "Iter: 15550  \tTraining Loss: -748.1289    \n",
      "    Negative Log Likelihood: 105.3151\tSigma2 Prior: -853.4462\tRegularization: 0.0021\n",
      "Iter: 15560  \tTraining Loss: -736.6943    \n",
      "    Negative Log Likelihood: 115.4828\tSigma2 Prior: -852.1793\tRegularization: 0.0021\n",
      "Iter: 15570  \tTraining Loss: -748.2303    \n",
      "    Negative Log Likelihood: 108.1127\tSigma2 Prior: -856.3452\tRegularization: 0.0021\n",
      "Iter: 15580  \tTraining Loss: -749.6288    \n",
      "    Negative Log Likelihood: 108.9699\tSigma2 Prior: -858.6009\tRegularization: 0.0021\n",
      "Iter: 15590  \tTraining Loss: -747.8201    \n",
      "    Negative Log Likelihood: 111.4622\tSigma2 Prior: -859.2845\tRegularization: 0.0021\n",
      "Iter: 15600  \tTraining Loss: -749.4440    \n",
      "    Negative Log Likelihood: 109.3016\tSigma2 Prior: -858.7478\tRegularization: 0.0021\n",
      "Iter: 15610  \tTraining Loss: -741.0917    \n",
      "    Negative Log Likelihood: 110.1504\tSigma2 Prior: -851.2443\tRegularization: 0.0021\n",
      "Iter: 15620  \tTraining Loss: -744.7870    \n",
      "    Negative Log Likelihood: 107.1125\tSigma2 Prior: -851.9016\tRegularization: 0.0021\n",
      "Iter: 15630  \tTraining Loss: -744.3250    \n",
      "    Negative Log Likelihood: 105.4172\tSigma2 Prior: -849.7444\tRegularization: 0.0021\n",
      "Iter: 15640  \tTraining Loss: -743.0939    \n",
      "    Negative Log Likelihood: 111.3949\tSigma2 Prior: -854.4909\tRegularization: 0.0021\n",
      "Iter: 15650  \tTraining Loss: -750.7366    \n",
      "    Negative Log Likelihood: 107.4150\tSigma2 Prior: -858.1537\tRegularization: 0.0021\n",
      "Iter: 15660  \tTraining Loss: -749.3645    \n",
      "    Negative Log Likelihood: 109.4756\tSigma2 Prior: -858.8422\tRegularization: 0.0021\n",
      "Iter: 15670  \tTraining Loss: -740.4873    \n",
      "    Negative Log Likelihood: 110.3268\tSigma2 Prior: -850.8162\tRegularization: 0.0021\n",
      "Iter: 15680  \tTraining Loss: -743.3478    \n",
      "    Negative Log Likelihood: 101.9856\tSigma2 Prior: -845.3355\tRegularization: 0.0021\n",
      "Iter: 15690  \tTraining Loss: -743.9550    \n",
      "    Negative Log Likelihood: 104.6925\tSigma2 Prior: -848.6496\tRegularization: 0.0021\n",
      "Iter: 15700  \tTraining Loss: -745.4174    \n",
      "    Negative Log Likelihood: 109.5646\tSigma2 Prior: -854.9841\tRegularization: 0.0021\n",
      "Iter: 15710  \tTraining Loss: -745.6590    \n",
      "    Negative Log Likelihood: 109.8894\tSigma2 Prior: -855.5505\tRegularization: 0.0021\n",
      "Iter: 15720  \tTraining Loss: -746.3983    \n",
      "    Negative Log Likelihood: 104.4070\tSigma2 Prior: -850.8074\tRegularization: 0.0021\n",
      "Iter: 15730  \tTraining Loss: -745.4059    \n",
      "    Negative Log Likelihood: 104.5859\tSigma2 Prior: -849.9940\tRegularization: 0.0021\n",
      "Iter: 15740  \tTraining Loss: -746.2368    \n",
      "    Negative Log Likelihood: 104.8434\tSigma2 Prior: -851.0823\tRegularization: 0.0021\n",
      "Iter: 15750  \tTraining Loss: -743.7173    \n",
      "    Negative Log Likelihood: 109.9223\tSigma2 Prior: -853.6418\tRegularization: 0.0021\n",
      "Iter: 15760  \tTraining Loss: -744.8473    \n",
      "    Negative Log Likelihood: 109.0986\tSigma2 Prior: -853.9481\tRegularization: 0.0021\n",
      "Iter: 15770  \tTraining Loss: -743.9876    \n",
      "    Negative Log Likelihood: 109.7867\tSigma2 Prior: -853.7764\tRegularization: 0.0021\n",
      "Iter: 15780  \tTraining Loss: -746.5168    \n",
      "    Negative Log Likelihood: 108.7523\tSigma2 Prior: -855.2712\tRegularization: 0.0021\n",
      "Iter: 15790  \tTraining Loss: -747.4174    \n",
      "    Negative Log Likelihood: 110.5113\tSigma2 Prior: -857.9308\tRegularization: 0.0021\n",
      "Iter: 15800  \tTraining Loss: -747.8909    \n",
      "    Negative Log Likelihood: 111.8837\tSigma2 Prior: -859.7767\tRegularization: 0.0021\n",
      "Iter: 15810  \tTraining Loss: -748.3483    \n",
      "    Negative Log Likelihood: 109.7313\tSigma2 Prior: -858.0817\tRegularization: 0.0021\n",
      "Iter: 15820  \tTraining Loss: -748.9925    \n",
      "    Negative Log Likelihood: 109.6018\tSigma2 Prior: -858.5965\tRegularization: 0.0021\n",
      "Iter: 15830  \tTraining Loss: -749.3214    \n",
      "    Negative Log Likelihood: 107.6017\tSigma2 Prior: -856.9251\tRegularization: 0.0021\n",
      "Iter: 15840  \tTraining Loss: -749.3716    \n",
      "    Negative Log Likelihood: 107.4255\tSigma2 Prior: -856.7993\tRegularization: 0.0021\n",
      "Iter: 15850  \tTraining Loss: -750.0850    \n",
      "    Negative Log Likelihood: 109.7575\tSigma2 Prior: -859.8447\tRegularization: 0.0021\n",
      "Iter: 15860  \tTraining Loss: -748.8521    \n",
      "    Negative Log Likelihood: 112.1405\tSigma2 Prior: -860.9948\tRegularization: 0.0021\n",
      "Iter: 15870  \tTraining Loss: -748.4001    \n",
      "    Negative Log Likelihood: 110.6269\tSigma2 Prior: -859.0291\tRegularization: 0.0021\n",
      "Iter: 15880  \tTraining Loss: -745.2194    \n",
      "    Negative Log Likelihood: 110.5887\tSigma2 Prior: -855.8102\tRegularization: 0.0021\n",
      "Iter: 15890  \tTraining Loss: -747.9923    \n",
      "    Negative Log Likelihood: 107.2365\tSigma2 Prior: -855.2310\tRegularization: 0.0021\n",
      "Iter: 15900  \tTraining Loss: -749.0488    \n",
      "    Negative Log Likelihood: 105.8176\tSigma2 Prior: -854.8685\tRegularization: 0.0021\n",
      "Iter: 15910  \tTraining Loss: -749.3955    \n",
      "    Negative Log Likelihood: 108.6752\tSigma2 Prior: -858.0728\tRegularization: 0.0021\n",
      "Iter: 15920  \tTraining Loss: -750.8999    \n",
      "    Negative Log Likelihood: 110.2031\tSigma2 Prior: -861.1052\tRegularization: 0.0021\n",
      "Iter: 15930  \tTraining Loss: -751.0258    \n",
      "    Negative Log Likelihood: 109.7353\tSigma2 Prior: -860.7632\tRegularization: 0.0021\n",
      "Iter: 15940  \tTraining Loss: -753.7361    \n",
      "    Negative Log Likelihood: 109.5146\tSigma2 Prior: -863.2529\tRegularization: 0.0021\n",
      "Iter: 15950  \tTraining Loss: -751.8442    \n",
      "    Negative Log Likelihood: 110.3194\tSigma2 Prior: -862.1658\tRegularization: 0.0021\n",
      "Iter: 15960  \tTraining Loss: -743.1516    \n",
      "    Negative Log Likelihood: 112.9171\tSigma2 Prior: -856.0709\tRegularization: 0.0021\n",
      "Iter: 15970  \tTraining Loss: -748.7789    \n",
      "    Negative Log Likelihood: 101.5738\tSigma2 Prior: -850.3547\tRegularization: 0.0021\n",
      "Iter: 15980  \tTraining Loss: -748.1877    \n",
      "    Negative Log Likelihood: 103.3052\tSigma2 Prior: -851.4951\tRegularization: 0.0021\n",
      "Iter: 15990  \tTraining Loss: -748.1879    \n",
      "    Negative Log Likelihood: 108.8256\tSigma2 Prior: -857.0156\tRegularization: 0.0021\n",
      "Iter: 16000  \tTraining Loss: -745.6212    \n",
      "    Negative Log Likelihood: 115.8075\tSigma2 Prior: -861.4308\tRegularization: 0.0021\n",
      "Iter: 16010  \tTraining Loss: -746.8541    \n",
      "    Negative Log Likelihood: 114.7913\tSigma2 Prior: -861.6475\tRegularization: 0.0021\n",
      "Iter: 16020  \tTraining Loss: -748.7802    \n",
      "    Negative Log Likelihood: 113.1095\tSigma2 Prior: -861.8918\tRegularization: 0.0021\n",
      "Iter: 16030  \tTraining Loss: -750.2820    \n",
      "    Negative Log Likelihood: 112.1846\tSigma2 Prior: -862.4688\tRegularization: 0.0021\n",
      "Iter: 16040  \tTraining Loss: -750.4842    \n",
      "    Negative Log Likelihood: 113.6672\tSigma2 Prior: -864.1535\tRegularization: 0.0021\n",
      "Iter: 16050  \tTraining Loss: -750.8927    \n",
      "    Negative Log Likelihood: 114.3269\tSigma2 Prior: -865.2217\tRegularization: 0.0021\n",
      "Iter: 16060  \tTraining Loss: -749.2951    \n",
      "    Negative Log Likelihood: 115.7777\tSigma2 Prior: -865.0750\tRegularization: 0.0021\n",
      "Iter: 16070  \tTraining Loss: -751.4799    \n",
      "    Negative Log Likelihood: 113.1891\tSigma2 Prior: -864.6711\tRegularization: 0.0021\n",
      "Iter: 16080  \tTraining Loss: -752.0047    \n",
      "    Negative Log Likelihood: 113.2924\tSigma2 Prior: -865.2992\tRegularization: 0.0021\n",
      "Iter: 16090  \tTraining Loss: -751.8818    \n",
      "    Negative Log Likelihood: 113.3681\tSigma2 Prior: -865.2520\tRegularization: 0.0021\n",
      "Iter: 16100  \tTraining Loss: -751.3605    \n",
      "    Negative Log Likelihood: 114.0187\tSigma2 Prior: -865.3813\tRegularization: 0.0021\n",
      "Iter: 16110  \tTraining Loss: -751.9612    \n",
      "    Negative Log Likelihood: 112.8982\tSigma2 Prior: -864.8615\tRegularization: 0.0021\n",
      "Iter: 16120  \tTraining Loss: -751.1662    \n",
      "    Negative Log Likelihood: 114.9133\tSigma2 Prior: -866.0816\tRegularization: 0.0021\n",
      "Iter: 16130  \tTraining Loss: -752.4749    \n",
      "    Negative Log Likelihood: 112.7365\tSigma2 Prior: -865.2134\tRegularization: 0.0021\n",
      "Iter: 16140  \tTraining Loss: -751.4014    \n",
      "    Negative Log Likelihood: 114.2703\tSigma2 Prior: -865.6738\tRegularization: 0.0021\n",
      "Iter: 16150  \tTraining Loss: -752.1789    \n",
      "    Negative Log Likelihood: 112.5042\tSigma2 Prior: -864.6852\tRegularization: 0.0021\n",
      "Iter: 16160  \tTraining Loss: -751.9982    \n",
      "    Negative Log Likelihood: 113.5572\tSigma2 Prior: -865.5575\tRegularization: 0.0021\n",
      "Iter: 16170  \tTraining Loss: -752.0215    \n",
      "    Negative Log Likelihood: 113.4212\tSigma2 Prior: -865.4448\tRegularization: 0.0021\n",
      "Iter: 16180  \tTraining Loss: -752.0653    \n",
      "    Negative Log Likelihood: 112.6277\tSigma2 Prior: -864.6952\tRegularization: 0.0021\n",
      "Iter: 16190  \tTraining Loss: -752.7476    \n",
      "    Negative Log Likelihood: 112.5482\tSigma2 Prior: -865.2980\tRegularization: 0.0021\n",
      "Iter: 16200  \tTraining Loss: -750.7415    \n",
      "    Negative Log Likelihood: 114.5487\tSigma2 Prior: -865.2924\tRegularization: 0.0021\n",
      "Iter: 16210  \tTraining Loss: -749.7645    \n",
      "    Negative Log Likelihood: 116.3580\tSigma2 Prior: -866.1246\tRegularization: 0.0021\n",
      "Iter: 16220  \tTraining Loss: -750.0459    \n",
      "    Negative Log Likelihood: 116.4155\tSigma2 Prior: -866.4636\tRegularization: 0.0021\n",
      "Iter: 16230  \tTraining Loss: -749.9521    \n",
      "    Negative Log Likelihood: 114.9900\tSigma2 Prior: -864.9443\tRegularization: 0.0021\n",
      "Iter: 16240  \tTraining Loss: -751.6451    \n",
      "    Negative Log Likelihood: 109.9041\tSigma2 Prior: -861.5513\tRegularization: 0.0021\n",
      "Iter: 16250  \tTraining Loss: -752.3228    \n",
      "    Negative Log Likelihood: 110.5185\tSigma2 Prior: -862.8435\tRegularization: 0.0021\n",
      "Iter: 16260  \tTraining Loss: -754.2959    \n",
      "    Negative Log Likelihood: 106.5410\tSigma2 Prior: -860.8391\tRegularization: 0.0021\n",
      "Iter: 16270  \tTraining Loss: -752.2302    \n",
      "    Negative Log Likelihood: 111.9544\tSigma2 Prior: -864.1867\tRegularization: 0.0021\n",
      "Iter: 16280  \tTraining Loss: -754.0764    \n",
      "    Negative Log Likelihood: 111.3719\tSigma2 Prior: -865.4504\tRegularization: 0.0021\n",
      "Iter: 16290  \tTraining Loss: -752.9509    \n",
      "    Negative Log Likelihood: 114.3317\tSigma2 Prior: -867.2847\tRegularization: 0.0021\n",
      "Iter: 16300  \tTraining Loss: -754.2374    \n",
      "    Negative Log Likelihood: 112.8064\tSigma2 Prior: -867.0460\tRegularization: 0.0021\n",
      "Iter: 16310  \tTraining Loss: -755.3899    \n",
      "    Negative Log Likelihood: 105.4830\tSigma2 Prior: -860.8751\tRegularization: 0.0021\n",
      "Iter: 16320  \tTraining Loss: -755.2565    \n",
      "    Negative Log Likelihood: 109.1301\tSigma2 Prior: -864.3887\tRegularization: 0.0021\n",
      "Iter: 16330  \tTraining Loss: -751.0994    \n",
      "    Negative Log Likelihood: 110.1465\tSigma2 Prior: -861.2480\tRegularization: 0.0021\n",
      "Iter: 16340  \tTraining Loss: -749.4777    \n",
      "    Negative Log Likelihood: 113.1598\tSigma2 Prior: -862.6396\tRegularization: 0.0022\n",
      "Iter: 16350  \tTraining Loss: -749.0648    \n",
      "    Negative Log Likelihood: 113.7508\tSigma2 Prior: -862.8177\tRegularization: 0.0022\n",
      "Iter: 16360  \tTraining Loss: -747.5948    \n",
      "    Negative Log Likelihood: 114.1135\tSigma2 Prior: -861.7105\tRegularization: 0.0022\n",
      "Iter: 16370  \tTraining Loss: -749.4135    \n",
      "    Negative Log Likelihood: 112.6864\tSigma2 Prior: -862.1021\tRegularization: 0.0022\n",
      "Iter: 16380  \tTraining Loss: -748.9402    \n",
      "    Negative Log Likelihood: 111.7332\tSigma2 Prior: -860.6755\tRegularization: 0.0022\n",
      "Iter: 16390  \tTraining Loss: -749.3647    \n",
      "    Negative Log Likelihood: 113.2674\tSigma2 Prior: -862.6342\tRegularization: 0.0022\n",
      "Iter: 16400  \tTraining Loss: -750.4298    \n",
      "    Negative Log Likelihood: 114.0394\tSigma2 Prior: -864.4714\tRegularization: 0.0022\n",
      "Iter: 16410  \tTraining Loss: -748.5422    \n",
      "    Negative Log Likelihood: 113.8989\tSigma2 Prior: -862.4433\tRegularization: 0.0022\n",
      "Iter: 16420  \tTraining Loss: -750.1674    \n",
      "    Negative Log Likelihood: 110.9488\tSigma2 Prior: -861.1183\tRegularization: 0.0022\n",
      "Iter: 16430  \tTraining Loss: -750.4421    \n",
      "    Negative Log Likelihood: 110.3888\tSigma2 Prior: -860.8330\tRegularization: 0.0022\n",
      "Iter: 16440  \tTraining Loss: -749.8004    \n",
      "    Negative Log Likelihood: 111.6220\tSigma2 Prior: -861.4244\tRegularization: 0.0022\n",
      "Iter: 16450  \tTraining Loss: -748.4874    \n",
      "    Negative Log Likelihood: 114.6605\tSigma2 Prior: -863.1500\tRegularization: 0.0022\n",
      "Iter: 16460  \tTraining Loss: -748.9213    \n",
      "    Negative Log Likelihood: 113.1229\tSigma2 Prior: -862.0464\tRegularization: 0.0022\n",
      "Iter: 16470  \tTraining Loss: -749.7737    \n",
      "    Negative Log Likelihood: 111.5656\tSigma2 Prior: -861.3414\tRegularization: 0.0022\n",
      "Iter: 16480  \tTraining Loss: -750.7841    \n",
      "    Negative Log Likelihood: 110.5295\tSigma2 Prior: -861.3157\tRegularization: 0.0022\n",
      "Iter: 16490  \tTraining Loss: -750.2006    \n",
      "    Negative Log Likelihood: 113.0372\tSigma2 Prior: -863.2399\tRegularization: 0.0022\n",
      "Iter: 16500  \tTraining Loss: -750.7507    \n",
      "    Negative Log Likelihood: 112.0043\tSigma2 Prior: -862.7571\tRegularization: 0.0022\n",
      "Iter: 16510  \tTraining Loss: -750.0947    \n",
      "    Negative Log Likelihood: 112.6177\tSigma2 Prior: -862.7145\tRegularization: 0.0022\n",
      "Iter: 16520  \tTraining Loss: -750.4322    \n",
      "    Negative Log Likelihood: 112.1142\tSigma2 Prior: -862.5485\tRegularization: 0.0022\n",
      "Iter: 16530  \tTraining Loss: -751.4429    \n",
      "    Negative Log Likelihood: 109.9649\tSigma2 Prior: -861.4099\tRegularization: 0.0022\n",
      "Iter: 16540  \tTraining Loss: -751.1985    \n",
      "    Negative Log Likelihood: 108.6887\tSigma2 Prior: -859.8893\tRegularization: 0.0022\n",
      "Iter: 16550  \tTraining Loss: -749.3685    \n",
      "    Negative Log Likelihood: 113.6519\tSigma2 Prior: -863.0226\tRegularization: 0.0022\n",
      "Iter: 16560  \tTraining Loss: -749.3815    \n",
      "    Negative Log Likelihood: 111.1841\tSigma2 Prior: -860.5678\tRegularization: 0.0022\n",
      "Iter: 16570  \tTraining Loss: -748.8936    \n",
      "    Negative Log Likelihood: 110.9392\tSigma2 Prior: -859.8349\tRegularization: 0.0022\n",
      "Iter: 16580  \tTraining Loss: -751.9506    \n",
      "    Negative Log Likelihood: 107.3490\tSigma2 Prior: -859.3018\tRegularization: 0.0022\n",
      "Iter: 16590  \tTraining Loss: -751.7797    \n",
      "    Negative Log Likelihood: 108.8153\tSigma2 Prior: -860.5972\tRegularization: 0.0022\n",
      "Iter: 16600  \tTraining Loss: -751.3859    \n",
      "    Negative Log Likelihood: 113.1796\tSigma2 Prior: -864.5677\tRegularization: 0.0022\n",
      "Iter: 16610  \tTraining Loss: -752.9681    \n",
      "    Negative Log Likelihood: 110.5723\tSigma2 Prior: -863.5425\tRegularization: 0.0022\n",
      "Iter: 16620  \tTraining Loss: -753.8773    \n",
      "    Negative Log Likelihood: 107.8846\tSigma2 Prior: -861.7640\tRegularization: 0.0022\n",
      "Iter: 16630  \tTraining Loss: -755.6912    \n",
      "    Negative Log Likelihood: 108.2311\tSigma2 Prior: -863.9245\tRegularization: 0.0022\n",
      "Iter: 16640  \tTraining Loss: -756.8038    \n",
      "    Negative Log Likelihood: 111.5824\tSigma2 Prior: -868.3884\tRegularization: 0.0022\n",
      "Iter: 16650  \tTraining Loss: -757.9896    \n",
      "    Negative Log Likelihood: 111.3109\tSigma2 Prior: -869.3026\tRegularization: 0.0022\n",
      "Iter: 16660  \tTraining Loss: -757.8307    \n",
      "    Negative Log Likelihood: 112.7378\tSigma2 Prior: -870.5706\tRegularization: 0.0022\n",
      "Iter: 16670  \tTraining Loss: -754.3398    \n",
      "    Negative Log Likelihood: 117.2786\tSigma2 Prior: -871.6206\tRegularization: 0.0022\n",
      "Iter: 16680  \tTraining Loss: -759.3812    \n",
      "    Negative Log Likelihood: 110.7936\tSigma2 Prior: -870.1769\tRegularization: 0.0022\n",
      "Iter: 16690  \tTraining Loss: -754.2932    \n",
      "    Negative Log Likelihood: 106.1124\tSigma2 Prior: -860.4077\tRegularization: 0.0022\n",
      "Iter: 16700  \tTraining Loss: -753.0457    \n",
      "    Negative Log Likelihood: 111.1352\tSigma2 Prior: -864.1830\tRegularization: 0.0022\n",
      "Iter: 16710  \tTraining Loss: -755.4236    \n",
      "    Negative Log Likelihood: 108.5018\tSigma2 Prior: -863.9276\tRegularization: 0.0022\n",
      "Iter: 16720  \tTraining Loss: -750.4900    \n",
      "    Negative Log Likelihood: 114.7770\tSigma2 Prior: -865.2691\tRegularization: 0.0022\n",
      "Iter: 16730  \tTraining Loss: -751.3713    \n",
      "    Negative Log Likelihood: 112.1044\tSigma2 Prior: -863.4778\tRegularization: 0.0022\n",
      "Iter: 16740  \tTraining Loss: -754.5594    \n",
      "    Negative Log Likelihood: 109.3604\tSigma2 Prior: -863.9219\tRegularization: 0.0022\n",
      "Iter: 16750  \tTraining Loss: -753.7521    \n",
      "    Negative Log Likelihood: 110.8954\tSigma2 Prior: -864.6497\tRegularization: 0.0022\n",
      "Iter: 16760  \tTraining Loss: -750.2839    \n",
      "    Negative Log Likelihood: 115.5154\tSigma2 Prior: -865.8015\tRegularization: 0.0022\n",
      "Iter: 16770  \tTraining Loss: -753.6361    \n",
      "    Negative Log Likelihood: 108.9747\tSigma2 Prior: -862.6129\tRegularization: 0.0022\n",
      "Iter: 16780  \tTraining Loss: -750.1987    \n",
      "    Negative Log Likelihood: 109.9276\tSigma2 Prior: -860.1284\tRegularization: 0.0022\n",
      "Iter: 16790  \tTraining Loss: -747.8748    \n",
      "    Negative Log Likelihood: 113.0229\tSigma2 Prior: -860.8998\tRegularization: 0.0022\n",
      "Iter: 16800  \tTraining Loss: -752.2267    \n",
      "    Negative Log Likelihood: 108.5710\tSigma2 Prior: -860.7998\tRegularization: 0.0022\n",
      "Iter: 16810  \tTraining Loss: -753.4080    \n",
      "    Negative Log Likelihood: 109.5922\tSigma2 Prior: -863.0024\tRegularization: 0.0022\n",
      "Iter: 16820  \tTraining Loss: -751.7983    \n",
      "    Negative Log Likelihood: 106.1075\tSigma2 Prior: -857.9080\tRegularization: 0.0022\n",
      "Iter: 16830  \tTraining Loss: -746.5746    \n",
      "    Negative Log Likelihood: 104.5206\tSigma2 Prior: -851.0974\tRegularization: 0.0022\n",
      "Iter: 16840  \tTraining Loss: -746.2797    \n",
      "    Negative Log Likelihood: 112.1546\tSigma2 Prior: -858.4364\tRegularization: 0.0022\n",
      "Iter: 16850  \tTraining Loss: -747.6862    \n",
      "    Negative Log Likelihood: 108.9573\tSigma2 Prior: -856.6456\tRegularization: 0.0022\n",
      "Iter: 16860  \tTraining Loss: -749.4445    \n",
      "    Negative Log Likelihood: 110.5023\tSigma2 Prior: -859.9490\tRegularization: 0.0022\n",
      "Iter: 16870  \tTraining Loss: -748.0118    \n",
      "    Negative Log Likelihood: 111.9245\tSigma2 Prior: -859.9385\tRegularization: 0.0022\n",
      "Iter: 16880  \tTraining Loss: -751.0151    \n",
      "    Negative Log Likelihood: 109.4812\tSigma2 Prior: -860.4985\tRegularization: 0.0022\n",
      "Iter: 16890  \tTraining Loss: -752.0072    \n",
      "    Negative Log Likelihood: 108.6978\tSigma2 Prior: -860.7072\tRegularization: 0.0022\n",
      "Iter: 16900  \tTraining Loss: -741.4836    \n",
      "    Negative Log Likelihood: 113.6158\tSigma2 Prior: -855.1016\tRegularization: 0.0022\n",
      "Iter: 16910  \tTraining Loss: -750.9188    \n",
      "    Negative Log Likelihood: 106.0386\tSigma2 Prior: -856.9597\tRegularization: 0.0022\n",
      "Iter: 16920  \tTraining Loss: -753.1029    \n",
      "    Negative Log Likelihood: 109.2985\tSigma2 Prior: -862.4036\tRegularization: 0.0022\n",
      "Iter: 16930  \tTraining Loss: -744.1164    \n",
      "    Negative Log Likelihood: 107.5786\tSigma2 Prior: -851.6972\tRegularization: 0.0022\n",
      "Iter: 16940  \tTraining Loss: -746.9244    \n",
      "    Negative Log Likelihood: 109.0183\tSigma2 Prior: -855.9449\tRegularization: 0.0022\n",
      "Iter: 16950  \tTraining Loss: -739.4411    \n",
      "    Negative Log Likelihood: 123.0981\tSigma2 Prior: -862.5414\tRegularization: 0.0022\n",
      "Iter: 16960  \tTraining Loss: -741.7134    \n",
      "    Negative Log Likelihood: 113.0814\tSigma2 Prior: -854.7970\tRegularization: 0.0022\n",
      "Iter: 16970  \tTraining Loss: -745.7282    \n",
      "    Negative Log Likelihood: 100.9875\tSigma2 Prior: -846.7179\tRegularization: 0.0022\n",
      "Iter: 16980  \tTraining Loss: -744.6743    \n",
      "    Negative Log Likelihood: 106.8365\tSigma2 Prior: -851.5130\tRegularization: 0.0022\n",
      "Iter: 16990  \tTraining Loss: -746.8810    \n",
      "    Negative Log Likelihood: 109.4188\tSigma2 Prior: -856.3021\tRegularization: 0.0022\n",
      "Iter: 17000  \tTraining Loss: -746.3456    \n",
      "    Negative Log Likelihood: 115.8293\tSigma2 Prior: -862.1771\tRegularization: 0.0022\n",
      "Iter: 17010  \tTraining Loss: -746.7762    \n",
      "    Negative Log Likelihood: 113.2962\tSigma2 Prior: -860.0746\tRegularization: 0.0022\n",
      "Iter: 17020  \tTraining Loss: -748.2133    \n",
      "    Negative Log Likelihood: 108.1121\tSigma2 Prior: -856.3275\tRegularization: 0.0022\n",
      "Iter: 17030  \tTraining Loss: -747.5443    \n",
      "    Negative Log Likelihood: 102.4130\tSigma2 Prior: -849.9594\tRegularization: 0.0022\n",
      "Iter: 17040  \tTraining Loss: -747.1160    \n",
      "    Negative Log Likelihood: 108.0533\tSigma2 Prior: -855.1714\tRegularization: 0.0022\n",
      "Iter: 17050  \tTraining Loss: -743.7423    \n",
      "    Negative Log Likelihood: 115.9927\tSigma2 Prior: -859.7372\tRegularization: 0.0022\n",
      "Iter: 17060  \tTraining Loss: -746.5675    \n",
      "    Negative Log Likelihood: 109.3989\tSigma2 Prior: -855.9686\tRegularization: 0.0022\n",
      "Iter: 17070  \tTraining Loss: -749.4669    \n",
      "    Negative Log Likelihood: 104.9669\tSigma2 Prior: -854.4360\tRegularization: 0.0022\n",
      "Iter: 17080  \tTraining Loss: -750.0365    \n",
      "    Negative Log Likelihood: 108.0728\tSigma2 Prior: -858.1116\tRegularization: 0.0022\n",
      "Iter: 17090  \tTraining Loss: -744.3060    \n",
      "    Negative Log Likelihood: 123.4201\tSigma2 Prior: -867.7283\tRegularization: 0.0022\n",
      "Iter: 17100  \tTraining Loss: -744.6530    \n",
      "    Negative Log Likelihood: 119.2956\tSigma2 Prior: -863.9508\tRegularization: 0.0022\n",
      "Iter: 17110  \tTraining Loss: -751.1383    \n",
      "    Negative Log Likelihood: 107.5026\tSigma2 Prior: -858.6431\tRegularization: 0.0022\n",
      "Iter: 17120  \tTraining Loss: -752.6362    \n",
      "    Negative Log Likelihood: 106.2053\tSigma2 Prior: -858.8436\tRegularization: 0.0022\n",
      "Iter: 17130  \tTraining Loss: -754.0907    \n",
      "    Negative Log Likelihood: 110.6403\tSigma2 Prior: -864.7332\tRegularization: 0.0022\n",
      "Iter: 17140  \tTraining Loss: -754.6522    \n",
      "    Negative Log Likelihood: 107.7447\tSigma2 Prior: -862.3990\tRegularization: 0.0022\n",
      "Iter: 17150  \tTraining Loss: -757.1799    \n",
      "    Negative Log Likelihood: 109.1769\tSigma2 Prior: -866.3590\tRegularization: 0.0022\n",
      "Iter: 17160  \tTraining Loss: -756.9567    \n",
      "    Negative Log Likelihood: 108.7423\tSigma2 Prior: -865.7012\tRegularization: 0.0022\n",
      "Iter: 17170  \tTraining Loss: -750.7309    \n",
      "    Negative Log Likelihood: 108.2404\tSigma2 Prior: -858.9734\tRegularization: 0.0022\n",
      "Iter: 17180  \tTraining Loss: -757.0203    \n",
      "    Negative Log Likelihood: 109.5120\tSigma2 Prior: -866.5345\tRegularization: 0.0022\n",
      "Iter: 17190  \tTraining Loss: -757.4188    \n",
      "    Negative Log Likelihood: 112.9803\tSigma2 Prior: -870.4012\tRegularization: 0.0022\n",
      "Iter: 17200  \tTraining Loss: -756.7792    \n",
      "    Negative Log Likelihood: 114.2466\tSigma2 Prior: -871.0281\tRegularization: 0.0022\n",
      "Iter: 17210  \tTraining Loss: -759.1552    \n",
      "    Negative Log Likelihood: 107.9422\tSigma2 Prior: -867.0996\tRegularization: 0.0022\n",
      "Iter: 17220  \tTraining Loss: -752.7960    \n",
      "    Negative Log Likelihood: 114.7620\tSigma2 Prior: -867.5601\tRegularization: 0.0022\n",
      "Iter: 17230  \tTraining Loss: -754.4780    \n",
      "    Negative Log Likelihood: 111.6305\tSigma2 Prior: -866.1108\tRegularization: 0.0022\n",
      "Iter: 17240  \tTraining Loss: -756.0376    \n",
      "    Negative Log Likelihood: 111.4453\tSigma2 Prior: -867.4850\tRegularization: 0.0022\n",
      "Iter: 17250  \tTraining Loss: -755.8969    \n",
      "    Negative Log Likelihood: 111.5937\tSigma2 Prior: -867.4928\tRegularization: 0.0022\n",
      "Iter: 17260  \tTraining Loss: -755.8867    \n",
      "    Negative Log Likelihood: 112.0989\tSigma2 Prior: -867.9879\tRegularization: 0.0022\n",
      "Iter: 17270  \tTraining Loss: -758.2797    \n",
      "    Negative Log Likelihood: 113.6598\tSigma2 Prior: -871.9417\tRegularization: 0.0022\n",
      "Iter: 17280  \tTraining Loss: -742.0892    \n",
      "    Negative Log Likelihood: 123.7535\tSigma2 Prior: -865.8449\tRegularization: 0.0022\n",
      "Iter: 17290  \tTraining Loss: -750.7144    \n",
      "    Negative Log Likelihood: 106.0464\tSigma2 Prior: -856.7631\tRegularization: 0.0022\n",
      "Iter: 17300  \tTraining Loss: -746.4188    \n",
      "    Negative Log Likelihood: 117.5821\tSigma2 Prior: -864.0031\tRegularization: 0.0022\n",
      "Iter: 17310  \tTraining Loss: -744.5510    \n",
      "    Negative Log Likelihood: 118.4885\tSigma2 Prior: -863.0417\tRegularization: 0.0022\n",
      "Iter: 17320  \tTraining Loss: -732.7834    \n",
      "    Negative Log Likelihood: 112.8813\tSigma2 Prior: -845.6669\tRegularization: 0.0022\n",
      "Iter: 17330  \tTraining Loss: -641.5648    \n",
      "    Negative Log Likelihood: 100.9354\tSigma2 Prior: -742.5024\tRegularization: 0.0022\n",
      "Iter: 17340  \tTraining Loss: -678.2151    \n",
      "    Negative Log Likelihood: 68.7273\tSigma2 Prior: -746.9446\tRegularization: 0.0022\n",
      "Iter: 17350  \tTraining Loss: -694.5721    \n",
      "    Negative Log Likelihood: 86.5903\tSigma2 Prior: -781.1646\tRegularization: 0.0022\n",
      "Iter: 17360  \tTraining Loss: -708.6161    \n",
      "    Negative Log Likelihood: 98.6397\tSigma2 Prior: -807.2579\tRegularization: 0.0022\n",
      "Iter: 17370  \tTraining Loss: -714.0665    \n",
      "    Negative Log Likelihood: 106.7692\tSigma2 Prior: -820.8379\tRegularization: 0.0022\n",
      "Iter: 17380  \tTraining Loss: -719.5836    \n",
      "    Negative Log Likelihood: 110.9621\tSigma2 Prior: -830.5480\tRegularization: 0.0022\n",
      "Iter: 17390  \tTraining Loss: -721.8068    \n",
      "    Negative Log Likelihood: 112.8753\tSigma2 Prior: -834.6843\tRegularization: 0.0022\n",
      "Iter: 17400  \tTraining Loss: -725.8503    \n",
      "    Negative Log Likelihood: 113.2076\tSigma2 Prior: -839.0601\tRegularization: 0.0022\n",
      "Iter: 17410  \tTraining Loss: -727.4889    \n",
      "    Negative Log Likelihood: 113.8167\tSigma2 Prior: -841.3079\tRegularization: 0.0022\n",
      "Iter: 17420  \tTraining Loss: -728.7283    \n",
      "    Negative Log Likelihood: 115.1498\tSigma2 Prior: -843.8803\tRegularization: 0.0022\n",
      "Iter: 17430  \tTraining Loss: -729.9009    \n",
      "    Negative Log Likelihood: 114.5979\tSigma2 Prior: -844.5010\tRegularization: 0.0022\n",
      "Iter: 17440  \tTraining Loss: -731.5878    \n",
      "    Negative Log Likelihood: 114.1217\tSigma2 Prior: -845.7117\tRegularization: 0.0022\n",
      "Iter: 17450  \tTraining Loss: -732.2524    \n",
      "    Negative Log Likelihood: 115.4772\tSigma2 Prior: -847.7318\tRegularization: 0.0022\n",
      "Iter: 17460  \tTraining Loss: -734.0084    \n",
      "    Negative Log Likelihood: 114.8977\tSigma2 Prior: -848.9083\tRegularization: 0.0022\n",
      "Iter: 17470  \tTraining Loss: -735.1066    \n",
      "    Negative Log Likelihood: 115.3085\tSigma2 Prior: -850.4174\tRegularization: 0.0022\n",
      "Iter: 17480  \tTraining Loss: -737.3431    \n",
      "    Negative Log Likelihood: 111.0144\tSigma2 Prior: -848.3597\tRegularization: 0.0022\n",
      "Iter: 17490  \tTraining Loss: -734.3436    \n",
      "    Negative Log Likelihood: 112.1652\tSigma2 Prior: -846.5110\tRegularization: 0.0022\n",
      "Iter: 17500  \tTraining Loss: -734.7500    \n",
      "    Negative Log Likelihood: 107.9863\tSigma2 Prior: -842.7385\tRegularization: 0.0022\n",
      "Iter: 17510  \tTraining Loss: -739.1896    \n",
      "    Negative Log Likelihood: 114.2232\tSigma2 Prior: -853.4149\tRegularization: 0.0022\n",
      "Iter: 17520  \tTraining Loss: -733.2647    \n",
      "    Negative Log Likelihood: 120.5613\tSigma2 Prior: -853.8282\tRegularization: 0.0022\n",
      "Iter: 17530  \tTraining Loss: -732.7167    \n",
      "    Negative Log Likelihood: 118.1428\tSigma2 Prior: -850.8617\tRegularization: 0.0022\n",
      "Iter: 17540  \tTraining Loss: -738.1299    \n",
      "    Negative Log Likelihood: 107.5521\tSigma2 Prior: -845.6843\tRegularization: 0.0022\n",
      "Iter: 17550  \tTraining Loss: -742.5988    \n",
      "    Negative Log Likelihood: 114.6711\tSigma2 Prior: -857.2720\tRegularization: 0.0022\n",
      "Iter: 17560  \tTraining Loss: -745.7856    \n",
      "    Negative Log Likelihood: 113.3143\tSigma2 Prior: -859.1021\tRegularization: 0.0022\n",
      "Iter: 17570  \tTraining Loss: -733.2408    \n",
      "    Negative Log Likelihood: 113.1595\tSigma2 Prior: -846.4025\tRegularization: 0.0022\n",
      "Iter: 17580  \tTraining Loss: -738.0879    \n",
      "    Negative Log Likelihood: 114.7517\tSigma2 Prior: -852.8419\tRegularization: 0.0022\n",
      "Iter: 17590  \tTraining Loss: -742.3875    \n",
      "    Negative Log Likelihood: 112.6412\tSigma2 Prior: -855.0309\tRegularization: 0.0022\n",
      "Iter: 17600  \tTraining Loss: -741.4021    \n",
      "    Negative Log Likelihood: 116.4815\tSigma2 Prior: -857.8858\tRegularization: 0.0022\n",
      "Iter: 17610  \tTraining Loss: -741.5393    \n",
      "    Negative Log Likelihood: 112.6802\tSigma2 Prior: -854.2217\tRegularization: 0.0022\n",
      "Iter: 17620  \tTraining Loss: -742.0183    \n",
      "    Negative Log Likelihood: 115.6938\tSigma2 Prior: -857.7143\tRegularization: 0.0022\n",
      "Iter: 17630  \tTraining Loss: -744.2366    \n",
      "    Negative Log Likelihood: 113.5632\tSigma2 Prior: -857.8020\tRegularization: 0.0022\n",
      "Iter: 17640  \tTraining Loss: -745.8375    \n",
      "    Negative Log Likelihood: 112.7314\tSigma2 Prior: -858.5712\tRegularization: 0.0022\n",
      "Iter: 17650  \tTraining Loss: -746.4668    \n",
      "    Negative Log Likelihood: 113.2526\tSigma2 Prior: -859.7216\tRegularization: 0.0022\n",
      "Iter: 17660  \tTraining Loss: -745.7209    \n",
      "    Negative Log Likelihood: 115.2826\tSigma2 Prior: -861.0057\tRegularization: 0.0022\n",
      "Iter: 17670  \tTraining Loss: -746.6190    \n",
      "    Negative Log Likelihood: 114.4769\tSigma2 Prior: -861.0981\tRegularization: 0.0022\n",
      "Iter: 17680  \tTraining Loss: -747.5618    \n",
      "    Negative Log Likelihood: 114.0041\tSigma2 Prior: -861.5681\tRegularization: 0.0022\n",
      "Iter: 17690  \tTraining Loss: -747.8585    \n",
      "    Negative Log Likelihood: 113.8586\tSigma2 Prior: -861.7193\tRegularization: 0.0022\n",
      "Iter: 17700  \tTraining Loss: -748.0986    \n",
      "    Negative Log Likelihood: 114.0637\tSigma2 Prior: -862.1644\tRegularization: 0.0022\n",
      "Iter: 17710  \tTraining Loss: -748.1732    \n",
      "    Negative Log Likelihood: 114.3975\tSigma2 Prior: -862.5729\tRegularization: 0.0022\n",
      "Iter: 17720  \tTraining Loss: -748.1650    \n",
      "    Negative Log Likelihood: 114.5373\tSigma2 Prior: -862.7045\tRegularization: 0.0022\n",
      "Iter: 17730  \tTraining Loss: -748.3491    \n",
      "    Negative Log Likelihood: 114.4999\tSigma2 Prior: -862.8512\tRegularization: 0.0022\n",
      "Iter: 17740  \tTraining Loss: -748.0110    \n",
      "    Negative Log Likelihood: 114.4721\tSigma2 Prior: -862.4854\tRegularization: 0.0022\n",
      "Iter: 17750  \tTraining Loss: -749.0447    \n",
      "    Negative Log Likelihood: 113.4381\tSigma2 Prior: -862.4850\tRegularization: 0.0022\n",
      "Iter: 17760  \tTraining Loss: -749.1340    \n",
      "    Negative Log Likelihood: 114.0204\tSigma2 Prior: -863.1566\tRegularization: 0.0022\n",
      "Iter: 17770  \tTraining Loss: -749.9360    \n",
      "    Negative Log Likelihood: 115.5831\tSigma2 Prior: -865.5213\tRegularization: 0.0022\n",
      "Iter: 17780  \tTraining Loss: -746.3193    \n",
      "    Negative Log Likelihood: 115.0025\tSigma2 Prior: -861.3240\tRegularization: 0.0022\n",
      "Iter: 17790  \tTraining Loss: -744.3400    \n",
      "    Negative Log Likelihood: 117.2326\tSigma2 Prior: -861.5748\tRegularization: 0.0022\n",
      "Iter: 17800  \tTraining Loss: -744.8806    \n",
      "    Negative Log Likelihood: 109.1897\tSigma2 Prior: -854.0725\tRegularization: 0.0022\n",
      "Iter: 17810  \tTraining Loss: -747.4837    \n",
      "    Negative Log Likelihood: 112.6988\tSigma2 Prior: -860.1848\tRegularization: 0.0022\n",
      "Iter: 17820  \tTraining Loss: -746.2928    \n",
      "    Negative Log Likelihood: 116.5603\tSigma2 Prior: -862.8553\tRegularization: 0.0022\n",
      "Iter: 17830  \tTraining Loss: -737.7538    \n",
      "    Negative Log Likelihood: 115.7230\tSigma2 Prior: -853.4790\tRegularization: 0.0022\n",
      "Iter: 17840  \tTraining Loss: -740.1221    \n",
      "    Negative Log Likelihood: 115.7427\tSigma2 Prior: -855.8670\tRegularization: 0.0022\n",
      "Iter: 17850  \tTraining Loss: -747.0472    \n",
      "    Negative Log Likelihood: 112.2646\tSigma2 Prior: -859.3140\tRegularization: 0.0022\n",
      "Iter: 17860  \tTraining Loss: -749.8593    \n",
      "    Negative Log Likelihood: 111.8699\tSigma2 Prior: -861.7314\tRegularization: 0.0022\n",
      "Iter: 17870  \tTraining Loss: -750.6531    \n",
      "    Negative Log Likelihood: 112.2376\tSigma2 Prior: -862.8929\tRegularization: 0.0022\n",
      "Iter: 17880  \tTraining Loss: -747.5068    \n",
      "    Negative Log Likelihood: 116.5206\tSigma2 Prior: -864.0295\tRegularization: 0.0022\n",
      "Iter: 17890  \tTraining Loss: -748.6906    \n",
      "    Negative Log Likelihood: 116.2835\tSigma2 Prior: -864.9763\tRegularization: 0.0022\n",
      "Iter: 17900  \tTraining Loss: -748.2845    \n",
      "    Negative Log Likelihood: 116.7430\tSigma2 Prior: -865.0297\tRegularization: 0.0022\n",
      "Iter: 17910  \tTraining Loss: -748.7870    \n",
      "    Negative Log Likelihood: 117.1858\tSigma2 Prior: -865.9750\tRegularization: 0.0022\n",
      "Iter: 17920  \tTraining Loss: -749.9133    \n",
      "    Negative Log Likelihood: 115.1830\tSigma2 Prior: -865.0985\tRegularization: 0.0022\n",
      "Iter: 17930  \tTraining Loss: -750.2858    \n",
      "    Negative Log Likelihood: 115.0906\tSigma2 Prior: -865.3786\tRegularization: 0.0022\n",
      "Iter: 17940  \tTraining Loss: -749.7405    \n",
      "    Negative Log Likelihood: 115.4113\tSigma2 Prior: -865.1540\tRegularization: 0.0022\n",
      "Iter: 17950  \tTraining Loss: -750.6072    \n",
      "    Negative Log Likelihood: 113.0895\tSigma2 Prior: -863.6989\tRegularization: 0.0022\n",
      "Iter: 17960  \tTraining Loss: -748.1613    \n",
      "    Negative Log Likelihood: 116.7198\tSigma2 Prior: -864.8832\tRegularization: 0.0022\n",
      "Iter: 17970  \tTraining Loss: -752.4329    \n",
      "    Negative Log Likelihood: 106.7221\tSigma2 Prior: -859.1571\tRegularization: 0.0022\n",
      "Iter: 17980  \tTraining Loss: -751.6135    \n",
      "    Negative Log Likelihood: 110.4463\tSigma2 Prior: -862.0620\tRegularization: 0.0022\n",
      "Iter: 17990  \tTraining Loss: -751.7832    \n",
      "    Negative Log Likelihood: 110.2944\tSigma2 Prior: -862.0798\tRegularization: 0.0022\n",
      "Iter: 18000  \tTraining Loss: -752.3017    \n",
      "    Negative Log Likelihood: 107.8375\tSigma2 Prior: -860.1414\tRegularization: 0.0022\n",
      "Iter: 18010  \tTraining Loss: -749.4217    \n",
      "    Negative Log Likelihood: 109.8551\tSigma2 Prior: -859.2791\tRegularization: 0.0022\n",
      "Iter: 18020  \tTraining Loss: -748.6002    \n",
      "    Negative Log Likelihood: 111.8580\tSigma2 Prior: -860.4604\tRegularization: 0.0022\n",
      "Iter: 18030  \tTraining Loss: -750.1597    \n",
      "    Negative Log Likelihood: 106.4077\tSigma2 Prior: -856.5698\tRegularization: 0.0022\n",
      "Iter: 18040  \tTraining Loss: -749.5563    \n",
      "    Negative Log Likelihood: 107.5706\tSigma2 Prior: -857.1292\tRegularization: 0.0022\n",
      "Iter: 18050  \tTraining Loss: -740.1387    \n",
      "    Negative Log Likelihood: 102.5842\tSigma2 Prior: -842.7252\tRegularization: 0.0022\n",
      "Iter: 18060  \tTraining Loss: -746.9039    \n",
      "    Negative Log Likelihood: 111.0452\tSigma2 Prior: -857.9514\tRegularization: 0.0022\n",
      "Iter: 18070  \tTraining Loss: -747.4737    \n",
      "    Negative Log Likelihood: 110.4513\tSigma2 Prior: -857.9272\tRegularization: 0.0022\n",
      "Iter: 18080  \tTraining Loss: -749.5979    \n",
      "    Negative Log Likelihood: 107.3222\tSigma2 Prior: -856.9223\tRegularization: 0.0022\n",
      "Iter: 18090  \tTraining Loss: -750.0594    \n",
      "    Negative Log Likelihood: 110.6095\tSigma2 Prior: -860.6712\tRegularization: 0.0022\n",
      "Iter: 18100  \tTraining Loss: -749.9427    \n",
      "    Negative Log Likelihood: 111.3640\tSigma2 Prior: -861.3090\tRegularization: 0.0022\n",
      "Iter: 18110  \tTraining Loss: -750.5263    \n",
      "    Negative Log Likelihood: 111.1771\tSigma2 Prior: -861.7057\tRegularization: 0.0022\n",
      "Iter: 18120  \tTraining Loss: -752.2438    \n",
      "    Negative Log Likelihood: 110.7722\tSigma2 Prior: -863.0183\tRegularization: 0.0022\n",
      "Iter: 18130  \tTraining Loss: -745.9165    \n",
      "    Negative Log Likelihood: 111.6923\tSigma2 Prior: -857.6111\tRegularization: 0.0022\n",
      "Iter: 18140  \tTraining Loss: -749.1424    \n",
      "    Negative Log Likelihood: 105.1986\tSigma2 Prior: -854.3432\tRegularization: 0.0022\n",
      "Iter: 18150  \tTraining Loss: -738.8282    \n",
      "    Negative Log Likelihood: 112.1630\tSigma2 Prior: -850.9935\tRegularization: 0.0022\n",
      "Iter: 18160  \tTraining Loss: -745.3638    \n",
      "    Negative Log Likelihood: 104.8528\tSigma2 Prior: -850.2189\tRegularization: 0.0022\n",
      "Iter: 18170  \tTraining Loss: -744.2421    \n",
      "    Negative Log Likelihood: 110.4784\tSigma2 Prior: -854.7228\tRegularization: 0.0022\n",
      "Iter: 18180  \tTraining Loss: -745.1219    \n",
      "    Negative Log Likelihood: 112.7676\tSigma2 Prior: -857.8918\tRegularization: 0.0022\n",
      "Iter: 18190  \tTraining Loss: -745.7839    \n",
      "    Negative Log Likelihood: 110.2339\tSigma2 Prior: -856.0200\tRegularization: 0.0022\n",
      "Iter: 18200  \tTraining Loss: -745.2045    \n",
      "    Negative Log Likelihood: 111.1089\tSigma2 Prior: -856.3157\tRegularization: 0.0022\n",
      "Iter: 18210  \tTraining Loss: -746.9983    \n",
      "    Negative Log Likelihood: 110.3915\tSigma2 Prior: -857.3920\tRegularization: 0.0022\n",
      "Iter: 18220  \tTraining Loss: -745.6613    \n",
      "    Negative Log Likelihood: 114.1615\tSigma2 Prior: -859.8250\tRegularization: 0.0022\n",
      "Iter: 18230  \tTraining Loss: -748.4664    \n",
      "    Negative Log Likelihood: 109.5130\tSigma2 Prior: -857.9817\tRegularization: 0.0022\n",
      "Iter: 18240  \tTraining Loss: -746.2766    \n",
      "    Negative Log Likelihood: 108.8823\tSigma2 Prior: -855.1612\tRegularization: 0.0022\n",
      "Iter: 18250  \tTraining Loss: -746.1497    \n",
      "    Negative Log Likelihood: 106.9120\tSigma2 Prior: -853.0640\tRegularization: 0.0022\n",
      "Iter: 18260  \tTraining Loss: -744.9819    \n",
      "    Negative Log Likelihood: 108.6999\tSigma2 Prior: -853.6841\tRegularization: 0.0022\n",
      "Iter: 18270  \tTraining Loss: -743.4121    \n",
      "    Negative Log Likelihood: 114.3510\tSigma2 Prior: -857.7654\tRegularization: 0.0022\n",
      "Iter: 18280  \tTraining Loss: -741.8247    \n",
      "    Negative Log Likelihood: 112.8157\tSigma2 Prior: -854.6426\tRegularization: 0.0022\n",
      "Iter: 18290  \tTraining Loss: -743.8814    \n",
      "    Negative Log Likelihood: 108.3045\tSigma2 Prior: -852.1882\tRegularization: 0.0022\n",
      "Iter: 18300  \tTraining Loss: -743.6978    \n",
      "    Negative Log Likelihood: 110.7088\tSigma2 Prior: -854.4089\tRegularization: 0.0022\n",
      "Iter: 18310  \tTraining Loss: -743.3366    \n",
      "    Negative Log Likelihood: 111.6479\tSigma2 Prior: -854.9868\tRegularization: 0.0022\n",
      "Iter: 18320  \tTraining Loss: -744.8615    \n",
      "    Negative Log Likelihood: 108.6132\tSigma2 Prior: -853.4769\tRegularization: 0.0022\n",
      "Iter: 18330  \tTraining Loss: -740.7868    \n",
      "    Negative Log Likelihood: 104.4683\tSigma2 Prior: -845.2574\tRegularization: 0.0022\n",
      "Iter: 18340  \tTraining Loss: -745.1021    \n",
      "    Negative Log Likelihood: 108.8060\tSigma2 Prior: -853.9104\tRegularization: 0.0022\n",
      "Iter: 18350  \tTraining Loss: -727.6039    \n",
      "    Negative Log Likelihood: 103.7261\tSigma2 Prior: -831.3322\tRegularization: 0.0022\n",
      "Iter: 18360  \tTraining Loss: -730.7553    \n",
      "    Negative Log Likelihood: 109.8357\tSigma2 Prior: -840.5933\tRegularization: 0.0022\n",
      "Iter: 18370  \tTraining Loss: -735.6219    \n",
      "    Negative Log Likelihood: 101.7147\tSigma2 Prior: -837.3389\tRegularization: 0.0022\n",
      "Iter: 18380  \tTraining Loss: -741.3522    \n",
      "    Negative Log Likelihood: 101.7791\tSigma2 Prior: -843.1335\tRegularization: 0.0022\n",
      "Iter: 18390  \tTraining Loss: -738.7867    \n",
      "    Negative Log Likelihood: 103.6836\tSigma2 Prior: -842.4727\tRegularization: 0.0022\n",
      "Iter: 18400  \tTraining Loss: -741.9236    \n",
      "    Negative Log Likelihood: 104.1867\tSigma2 Prior: -846.1125\tRegularization: 0.0022\n",
      "Iter: 18410  \tTraining Loss: -743.2551    \n",
      "    Negative Log Likelihood: 102.8820\tSigma2 Prior: -846.1393\tRegularization: 0.0022\n",
      "Iter: 18420  \tTraining Loss: -735.3410    \n",
      "    Negative Log Likelihood: 101.7715\tSigma2 Prior: -837.1147\tRegularization: 0.0022\n",
      "Iter: 18430  \tTraining Loss: -742.9572    \n",
      "    Negative Log Likelihood: 105.7123\tSigma2 Prior: -848.6718\tRegularization: 0.0022\n",
      "Iter: 18440  \tTraining Loss: -737.7011    \n",
      "    Negative Log Likelihood: 109.4272\tSigma2 Prior: -847.1306\tRegularization: 0.0022\n",
      "Iter: 18450  \tTraining Loss: -742.0745    \n",
      "    Negative Log Likelihood: 100.9052\tSigma2 Prior: -842.9820\tRegularization: 0.0022\n",
      "Iter: 18460  \tTraining Loss: -742.5772    \n",
      "    Negative Log Likelihood: 104.7075\tSigma2 Prior: -847.2870\tRegularization: 0.0022\n",
      "Iter: 18470  \tTraining Loss: -744.6188    \n",
      "    Negative Log Likelihood: 104.8418\tSigma2 Prior: -849.4629\tRegularization: 0.0022\n",
      "Iter: 18480  \tTraining Loss: -738.5920    \n",
      "    Negative Log Likelihood: 110.9227\tSigma2 Prior: -849.5170\tRegularization: 0.0022\n",
      "Iter: 18490  \tTraining Loss: -742.4879    \n",
      "    Negative Log Likelihood: 105.0489\tSigma2 Prior: -847.5391\tRegularization: 0.0022\n",
      "Iter: 18500  \tTraining Loss: -743.4588    \n",
      "    Negative Log Likelihood: 104.3951\tSigma2 Prior: -847.8561\tRegularization: 0.0022\n",
      "Iter: 18510  \tTraining Loss: -743.7191    \n",
      "    Negative Log Likelihood: 105.4148\tSigma2 Prior: -849.1362\tRegularization: 0.0022\n",
      "Iter: 18520  \tTraining Loss: -743.7853    \n",
      "    Negative Log Likelihood: 108.1995\tSigma2 Prior: -851.9871\tRegularization: 0.0022\n",
      "Iter: 18530  \tTraining Loss: -745.7797    \n",
      "    Negative Log Likelihood: 107.0240\tSigma2 Prior: -852.8059\tRegularization: 0.0022\n",
      "Iter: 18540  \tTraining Loss: -745.4337    \n",
      "    Negative Log Likelihood: 103.3023\tSigma2 Prior: -848.7382\tRegularization: 0.0022\n",
      "Iter: 18550  \tTraining Loss: -741.7650    \n",
      "    Negative Log Likelihood: 109.1456\tSigma2 Prior: -850.9129\tRegularization: 0.0022\n",
      "Iter: 18560  \tTraining Loss: -745.4944    \n",
      "    Negative Log Likelihood: 107.4606\tSigma2 Prior: -852.9573\tRegularization: 0.0022\n",
      "Iter: 18570  \tTraining Loss: -744.2582    \n",
      "    Negative Log Likelihood: 106.8668\tSigma2 Prior: -851.1273\tRegularization: 0.0022\n",
      "Iter: 18580  \tTraining Loss: -745.2553    \n",
      "    Negative Log Likelihood: 105.7432\tSigma2 Prior: -851.0008\tRegularization: 0.0022\n",
      "Iter: 18590  \tTraining Loss: -751.4192    \n",
      "    Negative Log Likelihood: 108.0036\tSigma2 Prior: -859.4250\tRegularization: 0.0022\n",
      "Iter: 18600  \tTraining Loss: -748.1089    \n",
      "    Negative Log Likelihood: 108.8213\tSigma2 Prior: -856.9324\tRegularization: 0.0022\n",
      "Iter: 18610  \tTraining Loss: -744.6600    \n",
      "    Negative Log Likelihood: 109.4659\tSigma2 Prior: -854.1282\tRegularization: 0.0022\n",
      "Iter: 18620  \tTraining Loss: -746.8293    \n",
      "    Negative Log Likelihood: 111.5389\tSigma2 Prior: -858.3705\tRegularization: 0.0022\n",
      "Iter: 18630  \tTraining Loss: -746.5576    \n",
      "    Negative Log Likelihood: 102.3008\tSigma2 Prior: -848.8607\tRegularization: 0.0022\n",
      "Iter: 18640  \tTraining Loss: -745.3583    \n",
      "    Negative Log Likelihood: 111.3919\tSigma2 Prior: -856.7525\tRegularization: 0.0022\n",
      "Iter: 18650  \tTraining Loss: -746.2679    \n",
      "    Negative Log Likelihood: 111.5764\tSigma2 Prior: -857.8466\tRegularization: 0.0022\n",
      "Iter: 18660  \tTraining Loss: -743.3254    \n",
      "    Negative Log Likelihood: 115.2593\tSigma2 Prior: -858.5869\tRegularization: 0.0022\n",
      "Iter: 18670  \tTraining Loss: -747.7235    \n",
      "    Negative Log Likelihood: 97.8563\tSigma2 Prior: -845.5820\tRegularization: 0.0022\n",
      "Iter: 18680  \tTraining Loss: -747.4265    \n",
      "    Negative Log Likelihood: 106.3231\tSigma2 Prior: -853.7518\tRegularization: 0.0022\n",
      "Iter: 18690  \tTraining Loss: -745.0040    \n",
      "    Negative Log Likelihood: 107.4403\tSigma2 Prior: -852.4465\tRegularization: 0.0022\n",
      "Iter: 18700  \tTraining Loss: -742.3225    \n",
      "    Negative Log Likelihood: 107.3731\tSigma2 Prior: -849.6979\tRegularization: 0.0022\n",
      "Iter: 18710  \tTraining Loss: -746.5858    \n",
      "    Negative Log Likelihood: 101.8699\tSigma2 Prior: -848.4579\tRegularization: 0.0022\n",
      "Iter: 18720  \tTraining Loss: -744.4462    \n",
      "    Negative Log Likelihood: 110.0795\tSigma2 Prior: -854.5280\tRegularization: 0.0022\n",
      "Iter: 18730  \tTraining Loss: -744.7769    \n",
      "    Negative Log Likelihood: 110.5445\tSigma2 Prior: -855.3237\tRegularization: 0.0022\n",
      "Iter: 18740  \tTraining Loss: -746.9518    \n",
      "    Negative Log Likelihood: 107.9184\tSigma2 Prior: -854.8725\tRegularization: 0.0022\n",
      "Iter: 18750  \tTraining Loss: -747.1570    \n",
      "    Negative Log Likelihood: 107.7572\tSigma2 Prior: -854.9164\tRegularization: 0.0022\n",
      "Iter: 18760  \tTraining Loss: -746.6402    \n",
      "    Negative Log Likelihood: 109.3749\tSigma2 Prior: -856.0173\tRegularization: 0.0022\n",
      "Iter: 18770  \tTraining Loss: -746.2328    \n",
      "    Negative Log Likelihood: 110.9985\tSigma2 Prior: -857.2336\tRegularization: 0.0022\n",
      "Iter: 18780  \tTraining Loss: -746.8584    \n",
      "    Negative Log Likelihood: 108.1168\tSigma2 Prior: -854.9774\tRegularization: 0.0022\n",
      "Iter: 18790  \tTraining Loss: -745.9205    \n",
      "    Negative Log Likelihood: 106.6320\tSigma2 Prior: -852.5547\tRegularization: 0.0022\n",
      "Iter: 18800  \tTraining Loss: -745.9938    \n",
      "    Negative Log Likelihood: 107.5146\tSigma2 Prior: -853.5107\tRegularization: 0.0022\n",
      "Iter: 18810  \tTraining Loss: -744.6448    \n",
      "    Negative Log Likelihood: 105.1865\tSigma2 Prior: -849.8336\tRegularization: 0.0022\n",
      "Iter: 18820  \tTraining Loss: -744.1384    \n",
      "    Negative Log Likelihood: 104.3887\tSigma2 Prior: -848.5294\tRegularization: 0.0022\n",
      "Iter: 18830  \tTraining Loss: -747.9183    \n",
      "    Negative Log Likelihood: 102.4765\tSigma2 Prior: -850.3972\tRegularization: 0.0022\n",
      "Iter: 18840  \tTraining Loss: -745.9515    \n",
      "    Negative Log Likelihood: 103.0862\tSigma2 Prior: -849.0399\tRegularization: 0.0022\n",
      "Iter: 18850  \tTraining Loss: -750.4345    \n",
      "    Negative Log Likelihood: 108.1287\tSigma2 Prior: -858.5654\tRegularization: 0.0023\n",
      "Iter: 18860  \tTraining Loss: -752.1587    \n",
      "    Negative Log Likelihood: 110.1149\tSigma2 Prior: -862.2758\tRegularization: 0.0023\n",
      "Iter: 18870  \tTraining Loss: -753.4336    \n",
      "    Negative Log Likelihood: 107.9280\tSigma2 Prior: -861.3638\tRegularization: 0.0023\n",
      "Iter: 18880  \tTraining Loss: -751.1578    \n",
      "    Negative Log Likelihood: 111.9483\tSigma2 Prior: -863.1084\tRegularization: 0.0023\n",
      "Iter: 18890  \tTraining Loss: -755.0981    \n",
      "    Negative Log Likelihood: 109.2571\tSigma2 Prior: -864.3574\tRegularization: 0.0023\n",
      "Iter: 18900  \tTraining Loss: -753.4014    \n",
      "    Negative Log Likelihood: 109.8890\tSigma2 Prior: -863.2927\tRegularization: 0.0023\n",
      "Iter: 18910  \tTraining Loss: -755.8076    \n",
      "    Negative Log Likelihood: 107.9151\tSigma2 Prior: -863.7249\tRegularization: 0.0023\n",
      "Iter: 18920  \tTraining Loss: -747.2103    \n",
      "    Negative Log Likelihood: 116.5821\tSigma2 Prior: -863.7947\tRegularization: 0.0023\n",
      "Iter: 18930  \tTraining Loss: -754.9599    \n",
      "    Negative Log Likelihood: 111.1806\tSigma2 Prior: -866.1428\tRegularization: 0.0023\n",
      "Iter: 18940  \tTraining Loss: -755.0350    \n",
      "    Negative Log Likelihood: 110.1068\tSigma2 Prior: -865.1441\tRegularization: 0.0023\n",
      "Iter: 18950  \tTraining Loss: -756.4853    \n",
      "    Negative Log Likelihood: 109.1088\tSigma2 Prior: -865.5963\tRegularization: 0.0023\n",
      "Iter: 18960  \tTraining Loss: -754.7689    \n",
      "    Negative Log Likelihood: 111.1097\tSigma2 Prior: -865.8809\tRegularization: 0.0023\n",
      "Iter: 18970  \tTraining Loss: -755.6524    \n",
      "    Negative Log Likelihood: 109.9499\tSigma2 Prior: -865.6046\tRegularization: 0.0023\n",
      "Iter: 18980  \tTraining Loss: -756.1917    \n",
      "    Negative Log Likelihood: 107.7858\tSigma2 Prior: -863.9797\tRegularization: 0.0023\n",
      "Iter: 18990  \tTraining Loss: -748.5672    \n",
      "    Negative Log Likelihood: 114.1011\tSigma2 Prior: -862.6705\tRegularization: 0.0023\n",
      "Iter: 19000  \tTraining Loss: -748.9410    \n",
      "    Negative Log Likelihood: 109.1871\tSigma2 Prior: -858.1304\tRegularization: 0.0023\n",
      "Iter: 19010  \tTraining Loss: -752.2201    \n",
      "    Negative Log Likelihood: 104.3032\tSigma2 Prior: -856.5256\tRegularization: 0.0023\n",
      "Iter: 19020  \tTraining Loss: -752.8560    \n",
      "    Negative Log Likelihood: 106.0394\tSigma2 Prior: -858.8976\tRegularization: 0.0023\n",
      "Iter: 19030  \tTraining Loss: -747.6993    \n",
      "    Negative Log Likelihood: 105.1598\tSigma2 Prior: -852.8614\tRegularization: 0.0023\n",
      "Iter: 19040  \tTraining Loss: -739.8098    \n",
      "    Negative Log Likelihood: 118.0995\tSigma2 Prior: -857.9115\tRegularization: 0.0023\n",
      "Iter: 19050  \tTraining Loss: -744.0566    \n",
      "    Negative Log Likelihood: 109.8542\tSigma2 Prior: -853.9131\tRegularization: 0.0023\n",
      "Iter: 19060  \tTraining Loss: -745.2151    \n",
      "    Negative Log Likelihood: 106.2217\tSigma2 Prior: -851.4391\tRegularization: 0.0023\n",
      "Iter: 19070  \tTraining Loss: -745.0809    \n",
      "    Negative Log Likelihood: 109.0968\tSigma2 Prior: -854.1799\tRegularization: 0.0023\n",
      "Iter: 19080  \tTraining Loss: -746.1091    \n",
      "    Negative Log Likelihood: 112.8317\tSigma2 Prior: -858.9431\tRegularization: 0.0023\n",
      "Iter: 19090  \tTraining Loss: -745.8622    \n",
      "    Negative Log Likelihood: 110.7345\tSigma2 Prior: -856.5990\tRegularization: 0.0023\n",
      "Iter: 19100  \tTraining Loss: -744.9521    \n",
      "    Negative Log Likelihood: 114.1689\tSigma2 Prior: -859.1232\tRegularization: 0.0023\n",
      "Iter: 19110  \tTraining Loss: -749.4196    \n",
      "    Negative Log Likelihood: 106.7015\tSigma2 Prior: -856.1234\tRegularization: 0.0023\n",
      "Iter: 19120  \tTraining Loss: -750.3284    \n",
      "    Negative Log Likelihood: 107.5744\tSigma2 Prior: -857.9051\tRegularization: 0.0023\n",
      "Iter: 19130  \tTraining Loss: -749.7113    \n",
      "    Negative Log Likelihood: 110.2843\tSigma2 Prior: -859.9979\tRegularization: 0.0023\n",
      "Iter: 19140  \tTraining Loss: -748.1489    \n",
      "    Negative Log Likelihood: 112.6696\tSigma2 Prior: -860.8207\tRegularization: 0.0023\n",
      "Iter: 19150  \tTraining Loss: -749.4891    \n",
      "    Negative Log Likelihood: 107.9152\tSigma2 Prior: -857.4066\tRegularization: 0.0023\n",
      "Iter: 19160  \tTraining Loss: -745.6408    \n",
      "    Negative Log Likelihood: 107.7080\tSigma2 Prior: -853.3511\tRegularization: 0.0023\n",
      "Iter: 19170  \tTraining Loss: -747.1544    \n",
      "    Negative Log Likelihood: 111.8320\tSigma2 Prior: -858.9886\tRegularization: 0.0023\n",
      "Iter: 19180  \tTraining Loss: -748.4973    \n",
      "    Negative Log Likelihood: 113.2976\tSigma2 Prior: -861.7972\tRegularization: 0.0023\n",
      "Iter: 19190  \tTraining Loss: -748.7911    \n",
      "    Negative Log Likelihood: 110.4757\tSigma2 Prior: -859.2690\tRegularization: 0.0023\n",
      "Iter: 19200  \tTraining Loss: -751.1066    \n",
      "    Negative Log Likelihood: 105.0398\tSigma2 Prior: -856.1487\tRegularization: 0.0023\n",
      "Iter: 19210  \tTraining Loss: -752.1451    \n",
      "    Negative Log Likelihood: 103.6463\tSigma2 Prior: -855.7937\tRegularization: 0.0023\n",
      "Iter: 19220  \tTraining Loss: -750.8770    \n",
      "    Negative Log Likelihood: 113.8485\tSigma2 Prior: -864.7277\tRegularization: 0.0023\n",
      "Iter: 19230  \tTraining Loss: -747.5527    \n",
      "    Negative Log Likelihood: 113.7205\tSigma2 Prior: -861.2754\tRegularization: 0.0023\n",
      "Iter: 19240  \tTraining Loss: -750.1107    \n",
      "    Negative Log Likelihood: 111.5005\tSigma2 Prior: -861.6135\tRegularization: 0.0023\n",
      "Iter: 19250  \tTraining Loss: -750.5613    \n",
      "    Negative Log Likelihood: 105.8578\tSigma2 Prior: -856.4214\tRegularization: 0.0023\n",
      "Iter: 19260  \tTraining Loss: -754.7050    \n",
      "    Negative Log Likelihood: 107.7168\tSigma2 Prior: -862.4241\tRegularization: 0.0023\n",
      "Iter: 19270  \tTraining Loss: -740.0090    \n",
      "    Negative Log Likelihood: 118.3004\tSigma2 Prior: -858.3116\tRegularization: 0.0023\n",
      "Iter: 19280  \tTraining Loss: -747.3732    \n",
      "    Negative Log Likelihood: 106.6524\tSigma2 Prior: -854.0278\tRegularization: 0.0023\n",
      "Iter: 19290  \tTraining Loss: -748.3114    \n",
      "    Negative Log Likelihood: 105.8689\tSigma2 Prior: -854.1825\tRegularization: 0.0023\n",
      "Iter: 19300  \tTraining Loss: -748.2588    \n",
      "    Negative Log Likelihood: 108.7315\tSigma2 Prior: -856.9926\tRegularization: 0.0023\n",
      "Iter: 19310  \tTraining Loss: -748.4241    \n",
      "    Negative Log Likelihood: 112.7769\tSigma2 Prior: -861.2032\tRegularization: 0.0023\n",
      "Iter: 19320  \tTraining Loss: -749.3012    \n",
      "    Negative Log Likelihood: 113.3748\tSigma2 Prior: -862.6782\tRegularization: 0.0023\n",
      "Iter: 19330  \tTraining Loss: -748.1749    \n",
      "    Negative Log Likelihood: 111.2807\tSigma2 Prior: -859.4579\tRegularization: 0.0023\n",
      "Iter: 19340  \tTraining Loss: -750.8943    \n",
      "    Negative Log Likelihood: 106.9096\tSigma2 Prior: -857.8062\tRegularization: 0.0023\n",
      "Iter: 19350  \tTraining Loss: -750.2039    \n",
      "    Negative Log Likelihood: 111.8610\tSigma2 Prior: -862.0671\tRegularization: 0.0023\n",
      "Iter: 19360  \tTraining Loss: -748.9995    \n",
      "    Negative Log Likelihood: 114.0921\tSigma2 Prior: -863.0939\tRegularization: 0.0023\n",
      "Iter: 19370  \tTraining Loss: -750.7609    \n",
      "    Negative Log Likelihood: 110.5361\tSigma2 Prior: -861.2993\tRegularization: 0.0023\n",
      "Iter: 19380  \tTraining Loss: -741.3408    \n",
      "    Negative Log Likelihood: 126.4849\tSigma2 Prior: -867.8279\tRegularization: 0.0023\n",
      "Iter: 19390  \tTraining Loss: -745.6962    \n",
      "    Negative Log Likelihood: 114.5296\tSigma2 Prior: -860.2280\tRegularization: 0.0023\n",
      "Iter: 19400  \tTraining Loss: -748.5220    \n",
      "    Negative Log Likelihood: 107.7426\tSigma2 Prior: -856.2668\tRegularization: 0.0023\n",
      "Iter: 19410  \tTraining Loss: -749.5911    \n",
      "    Negative Log Likelihood: 106.3549\tSigma2 Prior: -855.9482\tRegularization: 0.0023\n",
      "Iter: 19420  \tTraining Loss: -747.8461    \n",
      "    Negative Log Likelihood: 108.5820\tSigma2 Prior: -856.4304\tRegularization: 0.0023\n",
      "Iter: 19430  \tTraining Loss: -748.2641    \n",
      "    Negative Log Likelihood: 109.7663\tSigma2 Prior: -858.0327\tRegularization: 0.0023\n",
      "Iter: 19440  \tTraining Loss: -748.8867    \n",
      "    Negative Log Likelihood: 107.0289\tSigma2 Prior: -855.9178\tRegularization: 0.0023\n",
      "Iter: 19450  \tTraining Loss: -735.6652    \n",
      "    Negative Log Likelihood: 114.0486\tSigma2 Prior: -849.7161\tRegularization: 0.0023\n",
      "Iter: 19460  \tTraining Loss: -745.9205    \n",
      "    Negative Log Likelihood: 104.2949\tSigma2 Prior: -850.2177\tRegularization: 0.0023\n",
      "Iter: 19470  \tTraining Loss: -649.2228    \n",
      "    Negative Log Likelihood: 186.6793\tSigma2 Prior: -835.9044\tRegularization: 0.0023\n",
      "Iter: 19480  \tTraining Loss: -737.7298    \n",
      "    Negative Log Likelihood: 118.7290\tSigma2 Prior: -856.4611\tRegularization: 0.0023\n",
      "Iter: 19490  \tTraining Loss: -742.8713    \n",
      "    Negative Log Likelihood: 113.3924\tSigma2 Prior: -856.2660\tRegularization: 0.0023\n",
      "Iter: 19500  \tTraining Loss: -745.8157    \n",
      "    Negative Log Likelihood: 107.2747\tSigma2 Prior: -853.0926\tRegularization: 0.0023\n",
      "Iter: 19510  \tTraining Loss: -745.9557    \n",
      "    Negative Log Likelihood: 108.5186\tSigma2 Prior: -854.4766\tRegularization: 0.0023\n",
      "Iter: 19520  \tTraining Loss: -744.9814    \n",
      "    Negative Log Likelihood: 113.8267\tSigma2 Prior: -858.8104\tRegularization: 0.0023\n",
      "Iter: 19530  \tTraining Loss: -745.5688    \n",
      "    Negative Log Likelihood: 111.2381\tSigma2 Prior: -856.8091\tRegularization: 0.0023\n",
      "Iter: 19540  \tTraining Loss: -747.2174    \n",
      "    Negative Log Likelihood: 108.4177\tSigma2 Prior: -855.6373\tRegularization: 0.0023\n",
      "Iter: 19550  \tTraining Loss: -747.1215    \n",
      "    Negative Log Likelihood: 107.6212\tSigma2 Prior: -854.7449\tRegularization: 0.0023\n",
      "Iter: 19560  \tTraining Loss: -746.6161    \n",
      "    Negative Log Likelihood: 109.8860\tSigma2 Prior: -856.5045\tRegularization: 0.0023\n",
      "Iter: 19570  \tTraining Loss: -748.2480    \n",
      "    Negative Log Likelihood: 110.1927\tSigma2 Prior: -858.4429\tRegularization: 0.0023\n",
      "Iter: 19580  \tTraining Loss: -746.4722    \n",
      "    Negative Log Likelihood: 111.1034\tSigma2 Prior: -857.5778\tRegularization: 0.0023\n",
      "Iter: 19590  \tTraining Loss: -743.0510    \n",
      "    Negative Log Likelihood: 113.1220\tSigma2 Prior: -856.1752\tRegularization: 0.0023\n",
      "Iter: 19600  \tTraining Loss: -744.7731    \n",
      "    Negative Log Likelihood: 111.3609\tSigma2 Prior: -856.1362\tRegularization: 0.0023\n",
      "Iter: 19610  \tTraining Loss: -747.5618    \n",
      "    Negative Log Likelihood: 105.6121\tSigma2 Prior: -853.1762\tRegularization: 0.0023\n",
      "Iter: 19620  \tTraining Loss: -746.1928    \n",
      "    Negative Log Likelihood: 107.2537\tSigma2 Prior: -853.4487\tRegularization: 0.0023\n",
      "Iter: 19630  \tTraining Loss: -748.2570    \n",
      "    Negative Log Likelihood: 101.5374\tSigma2 Prior: -849.7966\tRegularization: 0.0023\n",
      "Iter: 19640  \tTraining Loss: -749.4738    \n",
      "    Negative Log Likelihood: 103.4166\tSigma2 Prior: -852.8926\tRegularization: 0.0023\n",
      "Iter: 19650  \tTraining Loss: -745.7731    \n",
      "    Negative Log Likelihood: 109.6469\tSigma2 Prior: -855.4223\tRegularization: 0.0023\n",
      "Iter: 19660  \tTraining Loss: -748.6448    \n",
      "    Negative Log Likelihood: 106.3134\tSigma2 Prior: -854.9604\tRegularization: 0.0023\n",
      "Iter: 19670  \tTraining Loss: -747.6290    \n",
      "    Negative Log Likelihood: 108.2326\tSigma2 Prior: -855.8638\tRegularization: 0.0023\n",
      "Iter: 19680  \tTraining Loss: -748.0266    \n",
      "    Negative Log Likelihood: 108.6714\tSigma2 Prior: -856.7003\tRegularization: 0.0023\n",
      "Iter: 19690  \tTraining Loss: -748.5703    \n",
      "    Negative Log Likelihood: 111.1283\tSigma2 Prior: -859.7007\tRegularization: 0.0023\n",
      "Iter: 19700  \tTraining Loss: -752.3500    \n",
      "    Negative Log Likelihood: 109.9214\tSigma2 Prior: -862.2737\tRegularization: 0.0023\n",
      "Iter: 19710  \tTraining Loss: -747.5462    \n",
      "    Negative Log Likelihood: 110.8835\tSigma2 Prior: -858.4320\tRegularization: 0.0023\n",
      "Iter: 19720  \tTraining Loss: -750.1696    \n",
      "    Negative Log Likelihood: 115.0286\tSigma2 Prior: -865.2005\tRegularization: 0.0023\n",
      "Iter: 19730  \tTraining Loss: -754.2694    \n",
      "    Negative Log Likelihood: 110.3472\tSigma2 Prior: -864.6189\tRegularization: 0.0023\n",
      "Iter: 19740  \tTraining Loss: -753.7236    \n",
      "    Negative Log Likelihood: 114.1413\tSigma2 Prior: -867.8672\tRegularization: 0.0023\n",
      "Iter: 19750  \tTraining Loss: -753.9818    \n",
      "    Negative Log Likelihood: 112.5472\tSigma2 Prior: -866.5313\tRegularization: 0.0023\n",
      "Iter: 19760  \tTraining Loss: -754.2197    \n",
      "    Negative Log Likelihood: 110.0829\tSigma2 Prior: -864.3049\tRegularization: 0.0023\n",
      "Iter: 19770  \tTraining Loss: -753.0063    \n",
      "    Negative Log Likelihood: 112.9573\tSigma2 Prior: -865.9659\tRegularization: 0.0023\n",
      "Iter: 19780  \tTraining Loss: -755.4546    \n",
      "    Negative Log Likelihood: 109.9700\tSigma2 Prior: -865.4268\tRegularization: 0.0023\n",
      "Iter: 19790  \tTraining Loss: -754.8668    \n",
      "    Negative Log Likelihood: 108.7997\tSigma2 Prior: -863.6688\tRegularization: 0.0023\n",
      "Iter: 19800  \tTraining Loss: -753.9125    \n",
      "    Negative Log Likelihood: 112.7871\tSigma2 Prior: -866.7019\tRegularization: 0.0023\n",
      "Iter: 19810  \tTraining Loss: -755.9329    \n",
      "    Negative Log Likelihood: 106.7762\tSigma2 Prior: -862.7113\tRegularization: 0.0023\n",
      "Iter: 19820  \tTraining Loss: -754.7484    \n",
      "    Negative Log Likelihood: 111.8903\tSigma2 Prior: -866.6409\tRegularization: 0.0023\n",
      "Iter: 19830  \tTraining Loss: -757.5149    \n",
      "    Negative Log Likelihood: 110.4558\tSigma2 Prior: -867.9730\tRegularization: 0.0023\n",
      "Iter: 19840  \tTraining Loss: -754.7147    \n",
      "    Negative Log Likelihood: 111.3641\tSigma2 Prior: -866.0811\tRegularization: 0.0023\n",
      "Iter: 19850  \tTraining Loss: -756.7037    \n",
      "    Negative Log Likelihood: 110.3590\tSigma2 Prior: -867.0650\tRegularization: 0.0023\n",
      "Iter: 19860  \tTraining Loss: -755.3148    \n",
      "    Negative Log Likelihood: 109.5772\tSigma2 Prior: -864.8942\tRegularization: 0.0023\n",
      "Iter: 19870  \tTraining Loss: -757.7163    \n",
      "    Negative Log Likelihood: 109.6977\tSigma2 Prior: -867.4163\tRegularization: 0.0023\n",
      "Iter: 19880  \tTraining Loss: -750.9664    \n",
      "    Negative Log Likelihood: 112.3879\tSigma2 Prior: -863.3566\tRegularization: 0.0023\n",
      "Iter: 19890  \tTraining Loss: -753.4351    \n",
      "    Negative Log Likelihood: 105.8093\tSigma2 Prior: -859.2466\tRegularization: 0.0023\n",
      "Iter: 19900  \tTraining Loss: -751.2189    \n",
      "    Negative Log Likelihood: 107.5511\tSigma2 Prior: -858.7722\tRegularization: 0.0023\n",
      "Iter: 19910  \tTraining Loss: -753.9211    \n",
      "    Negative Log Likelihood: 109.8244\tSigma2 Prior: -863.7477\tRegularization: 0.0023\n",
      "Iter: 19920  \tTraining Loss: -750.7877    \n",
      "    Negative Log Likelihood: 115.1315\tSigma2 Prior: -865.9214\tRegularization: 0.0023\n",
      "Iter: 19930  \tTraining Loss: -752.5483    \n",
      "    Negative Log Likelihood: 111.9205\tSigma2 Prior: -864.4711\tRegularization: 0.0023\n",
      "Iter: 19940  \tTraining Loss: -750.9338    \n",
      "    Negative Log Likelihood: 109.1261\tSigma2 Prior: -860.0621\tRegularization: 0.0023\n",
      "Iter: 19950  \tTraining Loss: -745.4017    \n",
      "    Negative Log Likelihood: 111.3320\tSigma2 Prior: -856.7359\tRegularization: 0.0023\n",
      "Iter: 19960  \tTraining Loss: -744.4338    \n",
      "    Negative Log Likelihood: 111.4904\tSigma2 Prior: -855.9265\tRegularization: 0.0023\n",
      "Iter: 19970  \tTraining Loss: -747.2556    \n",
      "    Negative Log Likelihood: 106.8069\tSigma2 Prior: -854.0648\tRegularization: 0.0023\n",
      "Iter: 19980  \tTraining Loss: -747.5516    \n",
      "    Negative Log Likelihood: 109.5429\tSigma2 Prior: -857.0968\tRegularization: 0.0023\n",
      "Iter: 19990  \tTraining Loss: -747.4419    \n",
      "    Negative Log Likelihood: 111.3844\tSigma2 Prior: -858.8286\tRegularization: 0.0023\n",
      "Iter: 19999  \tTraining Loss: -742.0652    \n",
      "    Negative Log Likelihood: 113.3969\tSigma2 Prior: -855.4644\tRegularization: 0.0023\n",
      "Done training with 20000 iterations\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_sequence,train_cluer_id,training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5cb30799-7294-418d-b5c6-0e03d083e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"./Diarization_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e61fb8c-f0ec-4db4-8e32-ba3d2bbca41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(\"./Diarization_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf230f5e-b69d-4300-a615-1f903bbf3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence = np.load(\"./test_sequence.npy\")\n",
    "prediction = loaded_model.predict(test_sequence,inference_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0f10d-78db-4e8c-a32f-7414d5f393b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
